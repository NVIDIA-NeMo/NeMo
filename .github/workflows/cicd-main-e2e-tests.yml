name: NeMo E2E Tests
on:
  workflow_call:
    inputs:
      test_to_run:
        required: true
        type: string

jobs:
  # L2: Community llava multimodal Checkpoints tests
  L2_Community_vita_Checkpoints_tests_Llama3:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Community_vita_Checkpoints_tests_Llama3

  # L2: Segmentation Tool
  L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Eng_CitriNet_with_wav:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Eng_CitriNet_with_wav

  L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Ru_QN_with_mp3:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Ru_QN_with_mp3

  # L2: G2P Models
  L2_G2P_Models_G2P_Conformer_training_evaluation_and_inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_G2P_Models_G2P_Conformer_training_evaluation_and_inference

  L2_G2P_Models_HeteronymClassificationModel_training_evaluation_and_inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_G2P_Models_HeteronymClassificationModel_training_evaluation_and_inference

  # TODO: remove +model.optim.capturable=True when Pytorch fix: https://github.com/pytorch/pytorch/pull/81858
  # is in the release container
  # L2: NMT Attention is All You Need Training
  L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Post-LN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Post-LN

  L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Pre-LN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Pre-LN

  L2_NMT_Attention_is_All_You_Need_Training_NMT_Multi-Validation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Training_NMT_Multi-Validation

  # L2: NMT Attention is All You Need Inference
  L2_NMT_Attention_is_All_You_Need_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Inference

  # L2: NMT Attention is All You Need Finetuning
  L2_NMT_Attention_is_All_You_Need_Finetuning:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Finetuning

  # L2: NMT Tarred Dataset Creation
  L2_NMT_Tarred_Dataset_Creation_Auto_Tarred_Dataset_Creation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Tarred_Dataset_Creation_Auto_Tarred_Dataset_Creation

  L2_NMT_Tarred_Dataset_Creation_Script_Tarred_Dataset_Creation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NMT_Tarred_Dataset_Creation_Script_Tarred_Dataset_Creation

  L2_VLM_HF_Transformer_PEFT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_VLM_HF_Transformer_PEFT

  L2_VLM_HF_Transformer_PEFT_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_VLM_HF_Transformer_PEFT_FSDP2

  L2_VLM_HF_Transformer_PEFT_4bit:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_VLM_HF_Transformer_PEFT_4bit

  L2_VLM_HF_Transformer_SFT_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_VLM_HF_Transformer_SFT_FSDP2

  L2_HF_Transformer_PEFT_notebook:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_notebook

  L2_HF_Transformer_PEFT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PEFT

  L2_HF_Transformer_PEFT_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PEFT_nemorun

  L2_HF_Transformer_PEFT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu

  L2_HF_Transformer_PEFT_2gpu_FSDP2_liger:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_FSDP2_liger

  L2_HF_Transformer_PEFT_2gpu_FSDP2_fp8:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: azure-gpu-vm-runner1-h100
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_FSDP2_fp8
      IS_OPTIONAL: true

  L2_HF_Transformer_PEFT_2gpu_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_FSDP2

  L2_HF_Transformer_PEFT_2gpu_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_nemorun

  L2_HF_Transformer_SFT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu

  L2_HF_Transformer_SFT_2gpu_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu_FSDP2

  L2_HF_Transformer_SFT_2gpu_FSDP2_fp8:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: azure-gpu-vm-runner1-h100
      SCRIPT: L2_HF_Transformer_SFT_2gpu_FSDP2_fp8
      IS_OPTIONAL: true

  L2_HF_Transformer_SFT_2gpu_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu_nemorun

  L2_HF_Transformer_SFT_2gpu_nemorun_fsdp2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu_nemorun_fsdp2

  L2_HF_Transformer_SFT_FSDP2_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_FSDP2_2gpu

  L2_HF_Transformer_PT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PT_2gpu

  L2_HF_Transformer_PT_2gpu_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PT_2gpu_nemorun

  L2_HF_Transformer_PT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PT

  L2_HF_Transformer_PT_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PT_nemorun

  L2_HF_Transformer_SFT_notebook:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_notebook

  L2_HF_Transformer_SFT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_SFT

  L2_HF_Transformer_SFT_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_SFT_nemorun

  L2_HF_Transformer_SFT_TE_Acceleration:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_SFT_TE_Acceleration
      IS_OPTIONAL: true

  L2_HF_Transformer_PT_TE_Acceleration:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PT_TE_Acceleration

  # L2: NeRF
  # L2_NeRF_DreamFusion:
  #
  #   runs-on: self-hosted-azure
  #   container:
  #     image: nemoci.azurecr.io/nemo_container:${{ github.run_id }}
  #     options:
  #       # --user 0:128
  #       --device=/dev/nvidia0
  #       --gpus all
  #       --shm-size=8g
  #       --env TRANSFORMERS_OFFLINE=0
  #       --env HYDRA_FULL_ERROR=1
  #       --volume /mnt/datadrive/TestData:/home/TestData
  #   steps:
  #       - name: Checkout repository
  #         uses: actions/checkout@v4
  #       - run: |
  #           python examples/multimodal/text_to_image/nerf/main.py \
  #           trainer.num_nodes=1 \
  #           trainer.devices="[0]" \
  #           trainer.max_steps=1000 \
  #           model.prompt="a DSLR photo of a delicious hamburger" \
  #           exp_manager.exp_dir=examples/multimodal/text_to_image/nerf/dreamfusion_results
  #
  #       - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
  #         if: "failure()"

  L2_Stable_Diffusion_Training:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Stable_Diffusion_Training

  L2_NeMo_2_GPT_Pretraining_no_transformer_engine:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_Pretraining_no_transformer_engine

  L2_NeMo_2_llama3_pretraining_recipe:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_llama3_pretraining_recipe

  L2_NeMo_2_llama3_fault_tolerance_plugin:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_llama3_fault_tolerance_plugin

  L2_NeMo_2_llama3_straggler_detection:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_llama3_straggler_detection

  L2_NeMo_2_GPT_DDP_Param_Parity_check:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_DDP_Param_Parity_check

  L2_NeMo_2_Hyena_Conversion_from_HF:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Hyena_Conversion_from_HF

  L2_NeMo_2_Hyena_DDP_Pretraining_Test:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure # Assume runner has 2 GPUs
      SCRIPT: L2_NeMo_2_Hyena_DDP_Pretraining_Test

  Optional_L2_NeMo_2_SSM_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_SSM_Pretraining
      IS_OPTIONAL: true

  Optional_L2_NeMo_2_SSM_Finetuning:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_SSM_Finetuning
      IS_OPTIONAL: true

  L2_NeMo_2_HF_MODEL_IMPORT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_HF_MODEL_IMPORT

  L2_NeMo_2_jit_callback:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_jit_callback

  L2_NeMo_2_T5_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_Pretraining

  L2_NeMo_2_T5_MockData_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_MockData_Pretraining

  L2_NeMo_2_T5_Finetuning:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_Finetuning

  L2_NeMo_2_T5_Squad:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_Squad

  L2_NeMo_2_T5_LoRA:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_LoRA

  L2_NeMo_2_BERT_Pretraining_Megatron:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_BERT_Pretraining_Megatron

  L2_NeMo_2_BERT_Pretraining_HuggingFace:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_BERT_Pretraining_HuggingFace

  L2_NeMo_2_NEVA_MOCK_PRETRAIN_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_PRETRAIN_TP2

  L2_NeMo_2_NEVA_MOCK_PRETRAIN_PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_PRETRAIN_PP2

  L2_NeMo_2_NEVA_MOCK_PRETRAIN_CP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_PRETRAIN_CP2

  L2_NeMo_2_NEVA_MOCK_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_FINETUNE_TP2

  L2_NeMo_2_NEVA_ENERGON_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_ENERGON_FINETUNE_TP2

  L2_NeMo_2_NEVA_MOCK_FINETUNE_PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_FINETUNE_PP2

  L2_NeMo_2_NEVA_MOCK_FINETUNE_CP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_FINETUNE_CP2

  L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_PAD:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_PAD

  L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_TRUNC:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_TRUNC

  OPTIONAL_L2_NeMo_2_NEVA_LOAD_GENERATE:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_NEVA_LOAD_GENERATE
      IS_OPTIONAL: true

  L2_NeMo_2_LLAVA_IMPORT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_LLAVA_IMPORT

  Optional_L2_NEMO_2_MLLAMA_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NEMO_2_MLLAMA_Inference
      IS_OPTIONAL: true

  Optional_L2_NeMo_2_MLLAMA_MOCK_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_MLLAMA_MOCK_FINETUNE_TP2
      IS_OPTIONAL: true

  L2_NeMo_2_MLLAMA_PRELOADED_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_MLLAMA_PRELOADED_FINETUNE_TP2

  L2_NeMo_2_MLLAMA_ENERGON_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_MLLAMA_ENERGON_FINETUNE_TP2

  L2_NeMo_2_MLLAMA_IMPORT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_MLLAMA_IMPORT

  L2_NeMo_2_Mixtral_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_Pretraining

  L2_NeMo_2_GPT_SFT_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP1_MBS1

  L2_NeMo_2_GPT_SFT_TP1PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP1_MBS2

  L2_NeMo_2_GPT_SFT_TP1PP2_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP2_MBS2

  L2_NeMo_2_GPT_SFT_TP2PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP2PP1_MBS2

  L2_NeMo_2_GPT_SFT_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS2

  L2_NeMo_2_GPT_LoRA_TP1PP2_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP2_MBS2

  L2_NeMo_2_GPT_LoRA_TP2PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP2PP1_MBS2

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_DoRA_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_DoRA_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_CLoRA_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_CLoRA_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_Chat:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_Chat

  L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2_exclude:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2_exclude

  L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2

  L2_NeMo_2_Mixtral_LoRA_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_TP1PP1_MBS1

  L2_NeMo_2_Mixtral_LoRA_TP2PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_TP2PP1_MBS1

  L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1

  L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1_exclude:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1_exclude

  L2_NeMo_2_Mistral_LoRA_TP2PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mistral_LoRA_TP2PP1_MBS1

  L2_NEMO_2_LoRA_MERGE:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NEMO_2_LoRA_MERGE

  L2_NEMO_2_LoRA_Export:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NEMO_2_LoRA_Export

  L2_NEMO_2_LoRA_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NEMO_2_LoRA_Inference

  L2_NeMo_2_NeMo_Mcore_Mixtral_bitexact:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_NeMo_Mcore_Mixtral_bitexact

  L2_NeMo_2_Automodel_PTQ_trtllm:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Automodel_PTQ_trtllm

  L2_NeMo_2_Automodel_PTQ_hf:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Automodel_PTQ_hf

  L2_NeMo_2_PTQ_Llama2_FP8_trtllm:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_PTQ_Llama2_FP8_trtllm

  L2_NeMo_2_PTQ_Llama2_FP8_nemo:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_PTQ_Llama2_FP8_nemo

  L2_NeMo_2_PTQ_Unified_Export:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_PTQ_Unified_Export

  L2_NeMo_2_Distill_Llama3_TP1PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Distill_Llama3_TP1PP2

  L2_NeMo_2_Prune_Llama_TP1PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Prune_Llama_TP1PP2

  L2_NeMo_2_LLAVA_NEXT_MOCK_TRAINING:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_MOCK_TRAINING

  L2_NeMo_2_LLAVA_NEXT_HF_CONVERSION:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_HF_CONVERSION

  L2_NeMo_2_LLAVA_NEXT_ENERGON_TRAIN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_ENERGON_TRAIN

  L2_NeMo_2_LLAVA_NEXT_ENERGON_PACKED_TRAIN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_ENERGON_PACKED_TRAIN

  L2_NeMo_2_CLIP_PRETRAIN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_CLIP_PRETRAIN

  L2_NeMo_2_CLIP_INFER:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_CLIP_INFER

  Optional_L2_NeMo_2_EVAL:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: Optional_L2_NeMo_2_EVAL
      IS_OPTIONAL: true

  L2_NeMo_2_Auto_Configurator_llama_TP1_PP1_MBS124:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_Auto_Configurator_llama_TP1_PP1_MBS124

  L2_NeMo_2_Auto_Configurator_bert_TP1_PP1_MBS124:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_Auto_Configurator_bert_TP1_PP1_MBS124

  L2_NeMo_2_Auto_Configurator_t5_TP1_PP1_MBS124:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_Auto_Configurator_t5_TP1_PP1_MBS124

  L2_NeMo_2_Conversion_Test_Baichuan2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Baichuan2

  L2_NeMo_2_Conversion_Test_ChatGLM:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_ChatGLM

  L2_NeMo_2_Conversion_Test_DeepSeek:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_DeepSeek

  L2_NeMo_2_Conversion_Test_Gemma:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Gemma

  L2_NeMo_2_Conversion_Test_Gemma2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Gemma2

  L2_NeMo_2_Conversion_Test_Mistral:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Mistral

  L2_NeMo_2_Conversion_Test_Llama:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Llama

  L2_NeMo_2_Conversion_Test_Llama_Embedding:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Llama_Embedding

  L2_NeMo_2_Conversion_Test_Nemotron:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Nemotron

  L2_NeMo_2_Conversion_Test_Phi3Mini:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Phi3Mini

  L2_NeMo_2_Conversion_Test_Qwen2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Qwen2

  L2_NeMo_2_Conversion_Test_Starcoder:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Starcoder

  L2_NeMo_2_Conversion_Test_Starcoder2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Starcoder2

  L2_NeMo_2_Conversion_Test_BERT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_BERT

  L2_NeMo_2_Conversion_Test_T5:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_T5
