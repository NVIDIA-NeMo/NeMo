# Copyright (c) 2020-2021, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
name: CICD NeMo
on:
  schedule:
    - cron: 0 0 * * *
  pull_request:
    branches:
      - main
      - r**
      - weekly-bump*
    types: [labeled]
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      test_to_run:
        required: false
        default: all
        type: string
        description: Comma-separated list of tests to run. Use "all" to run the full test suite.

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}-${{ github.event.label.name || 'main' }}-${{ github.event_name }}
  cancel-in-progress: true

jobs:
  pre-flight:
    runs-on: ubuntu-latest
    outputs:
      test_to_run: ${{ steps.test_to_run.outputs.main }}
    env:
      TESTS_TO_RUN: ${{ inputs.test_to_run }}
      EVENT_NAME: ${{ github.event_name }}
      HAS_LABEL: ${{ github.event.label.name == 'Run CICD' }}
    steps:
      - name: Checkout branch
        uses: actions/checkout@v4

      - name: Select tests to run
        id: test_to_run
        run: |
          # For manual dispatch, we replace `all` with the actual job names          
          if [[ "$EVENT_NAME" == "workflow_dispatch" ]]; then
            TESTS_TO_RUN=$TESTS_TO_RUN

          # For correctly labeled PR, we replace `all` with the actual job names          
          elif [[ "$EVENT_NAME" == "pull_request" && "$HAS_LABEL" == "true" ]]; then
            TESTS_TO_RUN=all

          # For incorrectly labeled PR, run no tests
          elif [[ "$EVENT_NAME" == "pull_request" && "$HAS_LABEL" != "true" ]]; then
            TESTS_TO_RUN=""
            
          # For push events, run all tests. This is so that we can generate coverage
          # on branch `main`.
          elif [[ "$EVENT_NAME" == "push" ]]; then
            TESTS_TO_RUN=all

          else
            echo "Unsupported event_name $EVENT_NAME provided".
            exit 1
          fi

          parsed_string=$(echo "$TESTS_TO_RUN" | jq -c --raw-input 'split(",")')
          echo "main=${parsed_string}" | tee -a "$GITHUB_OUTPUT"

  code-linting:
    if: ${{ needs.pre-flight.outputs.test_to_run != '[]' }}
    needs: [pre-flight]
    uses: ./.github/workflows/code-linting.yml

  cicd-test-container-build:
    uses: ./.github/workflows/_build_container.yml
    if: ${{ needs.pre-flight.outputs.test_to_run != '[]' }}
    needs: [pre-flight, code-linting]
    with:
      image-name: nemo_container
      dockerfile: Dockerfile.ci

  cicd-import-tests:
    if: ${{ needs.pre-flight.outputs.test_to_run != '[]' }}
    needs: [cicd-test-container-build, pre-flight]
    runs-on: self-hosted-azure-gpus-1
    steps:
      - name: Create UUID
        id: uuid
        run: |
          echo "id=$(uuidgen)" >> "$GITHUB_OUTPUT"

      - name: Checkout NeMo
        uses: actions/checkout@v2
        with:
          repository: NVIDIA/NeMo
          path: ${{ github.run_id }}/${{steps.uuid.outputs.id }}/NeMo

      - name: Run some checks
        run: |
          docker run \
              --rm \
            --device=/dev/nvidia0 \
            --gpus all \
            --shm-size=8g \
            --volume $(pwd)/${{ github.run_id }}/${{steps.uuid.outputs.id }}/NeMo:/workspace \
            --env TRANSFORMERS_OFFLINE=0 \
            --env HYDRA_FULL_ERROR=1 --env PYTHONUNBUFFERED=1 nemoci.azurecr.io/nemo_container:${{ github.run_id }} bash -c '\
            # PyTorch Lightning version
            python -c "import lightning.pytorch; print(lightning.pytorch.__version__)"

            # PyTorch Lightning DDP Checks
            CUDA_VISIBLE_DEVICES="0,1" python "tests/core_ptl/check_for_ranks.py"

            # Basic Import Checks
            python tests/core_ptl/check_imports.py --domain asr
            python tests/core_ptl/check_imports.py --domain nlp
            python tests/core_ptl/check_imports.py --domain tts
          '

  L0_Setup_Test_Data_And_Models:
    needs: [pre-flight, cicd-test-container-build]
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L0_Setup_Test_Data_And_Models
      TESTS_TO_RUN: '["L0_Setup_Test_Data_And_Models"]'

  cicd-main-unit-tests:
    needs: [pre-flight, cicd-test-container-build]
    uses: ./.github/workflows/cicd-main-unit-tests.yml
    with:
      test_to_run: ${{ needs.pre-flight.outputs.test_to_run }}

  cicd-main-export-deploy:
    needs: [pre-flight, cicd-test-container-build, cicd-main-unit-tests]
    uses: ./.github/workflows/cicd-main-export-deploy.yml
    with:
      test_to_run: ${{ needs.pre-flight.outputs.test_to_run }}

  cicd-main-speech:
    needs: [pre-flight, cicd-test-container-build, cicd-main-unit-tests]
    uses: ./.github/workflows/cicd-main-speech.yml
    with:
      test_to_run: ${{ needs.pre-flight.outputs.test_to_run }}

  cicd-main-automodel:
    needs: [pre-flight, cicd-test-container-build, cicd-main-unit-tests]
    uses: ./.github/workflows/cicd-main-automodel.yml
    with:
      test_to_run: ${{ needs.pre-flight.outputs.test_to_run }}

  cicd-main-e2e-nemo2-tests:
    strategy:
      matrix:
        include:
          - script: L2_Community_vita_Checkpoints_tests_Llama3
            runner: self-hosted-azure-gpus-1
          - script: L2_Stable_Diffusion_Training
            runner: self-hosted-azure-gpus-1
          - script: L2_NeMo_2_GPT_Pretraining_no_transformer_engine
            runner: self-hosted-azure
          - script: L2_NeMo_2_llama3_pretraining_recipe
            runner: self-hosted-azure
          - script: L2_NeMo_2_llama3_fault_tolerance_plugin
            runner: self-hosted-azure
          - script: L2_NeMo_2_llama3_straggler_detection
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_DDP_Param_Parity_check
            runner: self-hosted-azure
          - script: L2_NeMo_2_Hyena_Conversion_from_HF
            runner: self-hosted-azure
          - script: L2_NeMo_2_Hyena_DDP_Pretraining_Test
            runner: self-hosted-azure
          - script: Optional_L2_NeMo_2_SSM_Pretraining
            runner: self-hosted-azure-gpus-1
            is_optional: true
          - script: Optional_L2_NeMo_2_SSM_Finetuning
            runner: self-hosted-azure-gpus-1
            is_optional: true
          - script: L2_NeMo_2_HF_MODEL_IMPORT
            runner: self-hosted-azure
          - script: L2_NeMo_2_jit_callback
            runner: self-hosted-azure
          - script: L2_NeMo_2_T5_Pretraining
            runner: self-hosted-azure
          - script: L2_NeMo_2_T5_MockData_Pretraining
            runner: self-hosted-azure
          - script: L2_NeMo_2_T5_Finetuning
            runner: self-hosted-azure
          - script: L2_NeMo_2_T5_Squad
            runner: self-hosted-azure
          - script: L2_NeMo_2_T5_LoRA
            runner: self-hosted-azure
          - script: L2_NeMo_2_BERT_Pretraining_Megatron
            runner: self-hosted-azure
          - script: L2_NeMo_2_BERT_Pretraining_HuggingFace
            runner: self-hosted-azure
          - script: L2_NeMo_2_NEVA_MOCK_PRETRAIN_TP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_MOCK_PRETRAIN_PP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_MOCK_PRETRAIN_CP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_MOCK_FINETUNE_TP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_ENERGON_FINETUNE_TP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_MOCK_FINETUNE_PP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_MOCK_FINETUNE_CP2
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_PAD
            runner: self-hosted-azure-gpus-2-h100
          - script: L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_TRUNC
            runner: self-hosted-azure-gpus-2-h100
          - script: OPTIONAL_L2_NeMo_2_NEVA_LOAD_GENERATE
            runner: self-hosted-azure-gpus-1
            is_optional: true
          - script: L2_NeMo_2_LLAVA_IMPORT
            runner: self-hosted-azure-gpus-1
          - script: Optional_L2_NEMO_2_MLLAMA_Inference
            runner: self-hosted-azure-gpus-1
            is_optional: true
          - script: Optional_L2_NeMo_2_MLLAMA_MOCK_FINETUNE_TP2
            runner: self-hosted-azure
            is_optional: true
          - script: L2_NeMo_2_MLLAMA_PRELOADED_FINETUNE_TP2
            runner: self-hosted-azure
          - script: L2_NeMo_2_MLLAMA_ENERGON_FINETUNE_TP2
            runner: self-hosted-azure
          - script: L2_NeMo_2_MLLAMA_IMPORT
            runner: self-hosted-azure-gpus-1
          - script: L2_NeMo_2_Mixtral_Pretraining
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_SFT_TP1PP1_MBS1
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_SFT_TP1PP1_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_SFT_TP1PP2_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_SFT_TP2PP1_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_SFT_TP1PP1_MBS1_PACKED
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_LoRA_TP1PP2_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_LoRA_TP2PP1_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_PACKED
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_DoRA_TP1PP1_MBS1_PACKED
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_CLoRA_TP1PP1_MBS1_PACKED
            runner: self-hosted-azure
          - script: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_Chat
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2_exclude
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mixtral_LoRA_TP1PP1_MBS1
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mixtral_LoRA_TP2PP1_MBS1
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1_exclude
            runner: self-hosted-azure
          - script: L2_NeMo_2_Mistral_LoRA_TP2PP1_MBS1
            runner: self-hosted-azure
          - script: L2_NEMO_2_LoRA_MERGE
            runner: self-hosted-azure
          - script: L2_NEMO_2_LoRA_Export
            runner: self-hosted-azure-gpus-1
          - script: L2_NEMO_2_LoRA_Inference
            runner: self-hosted-azure-gpus-1
          - script: L2_NeMo_2_NeMo_Mcore_Mixtral_bitexact
            runner: self-hosted-azure
          - script: L2_NeMo_2_Automodel_PTQ_trtllm
            runner: self-hosted-azure
          - script: L2_NeMo_2_Automodel_PTQ_hf
            runner: self-hosted-azure
          - script: L2_NeMo_2_PTQ_Llama2_FP8_trtllm
            runner: self-hosted-azure
          - script: L2_NeMo_2_PTQ_Llama2_FP8_nemo
            runner: self-hosted-azure
          - script: L2_NeMo_2_PTQ_Unified_Export
            runner: self-hosted-azure
          - script: L2_NeMo_2_Distill_Llama3_TP1PP2
            runner: self-hosted-azure
          - script: L2_NeMo_2_Prune_Llama_TP1PP2
            runner: self-hosted-azure
          - script: L2_NeMo_2_LLAVA_NEXT_MOCK_TRAINING
            runner: self-hosted-azure
          - script: L2_NeMo_2_LLAVA_NEXT_HF_CONVERSION
            runner: self-hosted-azure
          - script: L2_NeMo_2_LLAVA_NEXT_ENERGON_TRAIN
            runner: self-hosted-azure
          - script: L2_NeMo_2_LLAVA_NEXT_ENERGON_PACKED_TRAIN
            runner: self-hosted-azure
          - script: L2_NeMo_2_CLIP_PRETRAIN
            runner: self-hosted-azure
          - script: L2_NeMo_2_CLIP_INFER
            runner: self-hosted-azure
          - script: Optional_L2_NeMo_2_EVAL
            runner: self-hosted-azure-gpus-1
            is_optional: true
          - script: L2_NeMo_2_Auto_Configurator_llama_TP1_PP1_MBS124
            runner: self-hosted-azure-gpus-1
          - script: L2_NeMo_2_Auto_Configurator_bert_TP1_PP1_MBS124
            runner: self-hosted-azure-gpus-1
          - script: L2_NeMo_2_Auto_Configurator_t5_TP1_PP1_MBS124
            runner: self-hosted-azure-gpus-1
          - script: L2_NeMo_2_Conversion_Test_Baichuan2
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_ChatGLM
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_DeepSeek
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Gemma
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Gemma2
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Mistral
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Llama
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Llama_Embedding
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Nemotron
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Phi3Mini
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Qwen2
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Starcoder
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_Starcoder2
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_BERT
            runner: self-hosted-azure
          - script: L2_NeMo_2_Conversion_Test_T5
            runner: self-hosted-azure
    uses: ./.github/workflows/_test_template.yml
    needs: [cicd-main-unit-tests]
    with:
      RUNNER: ${{ matrix.runner }}
      SCRIPT: ${{ matrix.script }}
      IS_OPTIONAL: ${{ matrix.is_optional || false }}

  Nemo_CICD_Test:
    needs:
      - pre-flight
      - cicd-test-container-build
      - cicd-import-tests
      - L0_Setup_Test_Data_And_Models
      - cicd-main-unit-tests
      - cicd-main-e2e-nemo2-tests
      - cicd-main-export-deploy
      - cicd-main-automodel
      - cicd-main-speech
    if: always() && (github.event.label.name == 'Run CICD' || github.event_name == 'workflow_dispatch')
    runs-on: ubuntu-latest
    permissions: write-all
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Get workflow result
        id: result
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID: ${{ github.run_id }}
        run: |
          # Get workflow run details and check job conclusions
          NUM_FAILED=$(gh run view $RUN_ID --json jobs -q '[.jobs[] | select(.conclusion == "failure") | .name] | length')
          NUM_CANCELLED=$(gh run view $RUN_ID --json jobs -q '[.jobs[] | select(.conclusion == "cancelled") | .name] | length')
          NUM_SKIPPED=$(gh run view $RUN_ID --json jobs -q '[.jobs[] | select(.conclusion == "skipped") | .name] | length')
            
          if [[ $NUM_FAILED -eq 0 && $NUM_CANCELLED -eq 0 && $NUM_SKIPPED -eq 0 ]]; then
            RESULT="success"
          elif [[ $NUM_FAILED -eq 0 && $NUM_CANCELLED -gt 0 && $NUM_SKIPPED -eq 0 ]]; then
            RESULT="cancelled"
          else
            RESULT="failure"
          fi

          # Output the final status
          echo "code=$RESULT" | tee -a $GITHUB_OUTPUT

      - name: Checkout for GH CLI
        uses: actions/checkout@v4

      - name: Remove label if not cancelled
        if: ${{ steps.result.outputs.code != 'cancelled' && github.event.label.name == 'Run CICD' && github.event.pull_request.head.repo.full_name == github.repository }}
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ github.event.number }}
        run: gh pr edit "$PR_NUMBER" --remove-label "Run CICD"

      - name: Pipeline successful, add PR comment
        if: ${{ always() && steps.result.outputs.code == 'success' && github.event_name == 'pull_request' && env.SLACK_WEBHOOK != '' }}
        uses: peter-evans/create-or-update-comment@v4
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          REPOSITORY: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
        with:
          issue-number: ${{ github.event.number }}
          body: |
            [🤖]: Hi @${{ github.event.pull_request.user.login }} 👋,

            We wanted to let you know that a [CICD pipeline](https://github.com/${{ env.REPOSITORY }}/actions/runs/${{ env.RUN_ID }}) for this PR just finished successfully

            So it might be time to merge this PR or get some approvals

            I'm just a bot so I'll leave it you what to do next.

            //cc @pablo-garay @ko3n1g

      - name: "Pipeline not successful and not cancelled: Send Slack alert & create step summary"
        if: ${{ always() && steps.result.outputs.code == 'failure' && env.SLACK_WEBHOOK != '' }}
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPOSITORY: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
          PR_NUMBER: ${{ github.event.number }}
          SERVER_URL: ${{ github.server_url }}
        run: |
          set -x
          pip install PyGithub
          python .github/scripts/notify.py

      - name: Exit
        if: ${{ always() }}
        env:
          RESULT: ${{ steps.result.outputs.code }}
        run: |
          if [ $RESULT == "success" ]; then
            exit 0
          else
            exit 1
          fi

  Coverage:
    runs-on: ubuntu-latest
    needs: [Nemo_CICD_Test]
    strategy:
      matrix:
        flag: [unit-test, e2e]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download coverage reports of current branch
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-${{ matrix.flag }}-*

      - name: Get total coverage of current branch
        shell: bash -x -e -u -o pipefail {0}
        if: always()
        run: |
          pip install coverage

          ls -al .
          ls -al coverage-*/
          coverage combine --keep $(ls coverage-*/.coverage)
          coverage report -i
          rm -rf coverage-*
          ls -al

      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          verbose: true
          flags: ${{ matrix.flag }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.flag }}-aggregated
          path: |
            .coverage
          include-hidden-files: true
