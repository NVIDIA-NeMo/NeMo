# Copyright (c) 2020-2021, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
name: "CICD NeMo"

on:
  push:
    branches: [ "main", "pagaray/nemo_cicd" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main", "pagaray/nemo_cicd" ]

jobs:
  gpu-test:
    runs-on: self-hosted-azure
    steps:
    - name: Run nvidia-smi test
      run: |
        whoami
        nvidia-smi

  cicd-test-container-setup:
    runs-on: self-hosted-azure
    # uses: actions/cache@v2
    #container:
#      image: nvcr.io/nvidia/pytorch:23.10-py3
#      options: 
#        # --user 0:128
#        --device=/dev/nvidia0
#        --gpus all
#        --shm-size=8g 
#        --env TRANSFORMERS_OFFLINE=0 
#        --env HYDRA_FULL_ERROR=1
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Container setup
      run: |
        # Pull base PyTorch container
        docker pull nvcr.io/nvidia/pytorch:23.10-py3
        docker run --device=/dev/nvidia0 --gpus all --shm-size=8g --env TRANSFORMERS_OFFLINE=0 --env HYDRA_FULL_ERROR=1 --volume $(pwd):/workspace --volume /home/TestData:/home/TestData nvcr.io/nvidia/pytorch:23.10-py3 /bin/bash -c '
            set -x

            # PyTorch version
            python -c "import torch; print(torch.__version__)"
            python -c "import torchvision; print(torchvision.__version__)"

            # Install test requirements
            apt-get update && apt-get install -y bc && pip install -r requirements/requirements_test.txt && pip install -r requirements/requirements_lightning.txt

            # Code formatting checks
            python setup.py style

            # Copyright Headers check
            python tests/check_copyright_header.py --dir .

            # NeMo Installation
            ./reinstall.sh release

            # Transformer Engine 1.2.0
            # Transformer Engine installation
            git clone https://github.com/NVIDIA/TransformerEngine.git && \
                pushd TransformerEngine && \
                git fetch origin 4f9662fbe621671f5f905e772fc1138953af77f6 && \
                git checkout FETCH_HEAD && \
                git submodule init && git submodule update && \
                NVTE_FRAMEWORK=pytorch NVTE_WITH_USERBUFFERS=1 MPI_HOME=/usr/local/mpi pip install .  && \
                popd

            # Apex bugfix for PyTorch 23.11 container: https://github.com/NVIDIA/apex/pull/1760
            # Apex installation
            git clone https://github.com/NVIDIA/apex.git && \
                pushd apex && \
                git checkout c07a4cf67102b9cd3f97d1ba36690f985bae4227 && \
                cp -R apex /usr/local/lib/python3.10/dist-packages && \
                popd

            # pip package should be working with main, if not we can update the commit here
            # until the pip package is updated
            # Megatron Core installation
            git clone https://github.com/NVIDIA/Megatron-LM.git && \
                pushd Megatron-LM && \
                git checkout bed60a881f4b238b1c14b6c6a64997cc636e77b6 && \
                pip install . && \
                popd

            # PyTorch Lightning version
            python -c "import pytorch_lightning; print(pytorch_lightning.__version__)"

            # PyTorch Lightning DDP Checks
            CUDA_VISIBLE_DEVICES="0,1" python "tests/core_ptl/check_for_ranks.py"

            # Basic Import Checks
            python -c "import nemo.collections.asr as nemo_asr"
            python -c "import nemo.collections.nlp as nemo_nlp"
            python -c "import nemo.collections.tts as nemo_tts"

            '
            ### \'\'


    - name: Push container to registry for future use
      run: |
        # Push container
        echo "Docker: List containers" && docker ps -a
        DOCKER_COMMIT=$(docker ps --latest --quiet)  # latest container
        docker commit $DOCKER_COMMIT nemo_container
        docker tag nemo_container localhost:5000/nemo_container
        docker push localhost:5000/nemo_container


    # - name: Build and push to local registry
    #   uses: docker/build-push-action@v5
    #   with:
    #       context: .
    #       push: true
    #       tags: localhost:5000/name/app:latest

    # - name: Inspect
    #   run: |
    #     docker buildx imagetools inspect localhost:5000/name/app:latest 


  L0_Unit_Tests_GPU:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    - name: "L0: Unit Tests GPU"
      run: |
        NEMO_NUMBA_MINVER=0.53 pytest -m "not pleasefixme" --with_downloads

  L0_Unit_Tests_CPU:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    - name: "L0: Unit Tests CPU"
      run: |
        CUDA_VISIBLE_DEVICES="" NEMO_NUMBA_MINVER=0.53 pytest -m "not pleasefixme" --cpu --with_downloads --relax_numba_compat





##     - name: L2: Multimodal Imagen Train

  # L2: Community LLM Checkpoints tests
  L2_Community_LLM_Checkpoints_tests_Llama:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            CUDA_VISIBLE_DEVICES=0 python scripts/nlp_language_modeling/convert_hf_llama_to_nemo.py \
            --in-file=/home/TestData/nlp/megatron_llama/llama-ci-hf \
            --out-file=/home/TestData/nlp/megatron_llama/ci.nemo \
            --precision=16
            rm -f /home/TestData/nlp/megatron_llama/ci.nemo

  L2_Community_LLM_Checkpoints_tests_StarCoder:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python scripts/nlp_language_modeling/convert_starcoder_hf_to_nemo.py \
            --config examples/nlp/language_modeling/conf/megatron_gpt_config.yaml \
            --input /home/TestData/nlp/megatron_gpt/starcoder-ci-hf \
            --output /home/TestData/nlp/megatron_gpt/starcoder-ci-hf
            rm -f /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/megatron_starcoder_tp1_pp1.nemo

  L2_Community_LLM_Checkpoints_tests_Falcon:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python scripts/nlp_language_modeling/convert_hf_falcon_to_nemo.py \
            --config examples/nlp/language_modeling/conf/megatron_falcon_config.yaml \
            --input /home/TestData/nlp/megatron_gpt/falcon-ci-hf \
            --output /home/TestData/nlp/megatron_gpt/falcon-ci-hf/falcon_ci.nemo
            rm -f /home/TestData/nlp/megatron_gpt/falcon-ci-hf/falcon_ci.nemo


  # L2: ASR dev run
  ASR_dev_run_Speech_to_Text:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc.py \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_results
            rm -rf examples/asr/speech_to_text_results

  ASR_dev_run_Speech_to_Text_WPE_-_CitriNet:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \
            --config-path="../conf/citrinet/" --config-name="config_bpe" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            model.tokenizer.dir="/home/TestData/asr_tokenizers/an4_wpe_128/" \
            model.tokenizer.type="wpe" \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_wpe_results
            rm -rf examples/asr/speech_to_text_wpe_results

  ASR_dev_run_Speech_Pre-training_-_CitriNet:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_pretraining/speech_pre_training.py \
            --config-path="../conf/ssl/citrinet/" --config-name="citrinet_ssl_ci" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_pre_training_results
            rm -rf examples/asr/speech_pre_training_results

  ASR_dev_run_Speech_To_Text_Finetuning:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_to_text_finetune.py \
            --config-path="conf/asr_finetune" --config-name="speech_to_text_finetune" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            init_from_nemo_model=/home/TestData/asr/stt_en_fastconformer_transducer_large.nemo \
            model.tokenizer.update_tokenizer=False \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_finetuning_results
            rm -rf examples/asr/speech_finetuning_results

  ASR_dev_run_Speech_To_Text_HF_Finetuning:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_to_text_finetune.py \
            --config-path="conf/asr_finetune" --config-name="speech_to_text_hf_finetune" \
            ~model.train_ds.hf_data_cfg \
            model.train_ds.num_workers=1 \
            model.train_ds.batch_size=2 model.validation_ds.batch_size=2 \
            model.train_ds.streaming=true \
            +model.train_ds.hf_data_cfg.path="librispeech_asr" \
            +model.train_ds.hf_data_cfg.name=null \
            +model.train_ds.hf_data_cfg.split="test.clean" \
            +model.train_ds.hf_data_cfg.streaming=true \
            ~model.validation_ds.hf_data_cfg \
            model.validation_ds.streaming=true \
            +model.validation_ds.hf_data_cfg.path="librispeech_asr" \
            +model.validation_ds.hf_data_cfg.name=null \
            +model.validation_ds.hf_data_cfg.split="test.clean" \
            +model.validation_ds.hf_data_cfg.streaming=true \
            ~model.test_ds \
            init_from_nemo_model=/home/TestData/asr/stt_en_fastconformer_transducer_large.nemo \
            model.tokenizer.update_tokenizer=False \
            model.optim.sched.warmup_steps=0 \
            +model.optim.sched.max_steps=3 \
            trainer.max_epochs=null \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_finetuning_results
            rm -rf examples/asr/speech_finetuning_results

  ASR_dev_run_Speech_to_Text_WPE_-_Conformer:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \
            --config-path="../conf/conformer" --config-name="conformer_ctc_bpe" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            model.tokenizer.dir="/home/TestData/asr_tokenizers/an4_wpe_128/" \
            model.tokenizer.type="wpe" \
            model.train_ds.batch_size=4 \
            model.validation_ds.batch_size=4 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_wpe_conformer_results
            rm -rf examples/asr/speech_to_text_wpe_conformer_results

  # L2: ASR dev run - part two
  ASR_dev_run-part_two_Speech_to_Text_WPE_-_Squeezeformer:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \
            --config-path="../conf/squeezeformer" --config-name="squeezeformer_ctc_bpe" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            model.tokenizer.dir="/home/TestData/asr_tokenizers/an4_wpe_128/" \
            model.tokenizer.type="wpe" \
            model.encoder.d_model=144 \
            model.train_ds.batch_size=4 \
            model.validation_ds.batch_size=4 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_wpe_squeezeformer_results
            rm -rf examples/asr/speech_to_text_wpe_squeezeformer_results

  L2_Speech_to_Text_EMA:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc.py \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.devices=2 \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            +exp_manager.ema.enable=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_results
            rm -rf examples/asr/speech_to_text_results

  L2_Speech_to_Text_AED:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_multitask/speech_to_text_aed.py \
            model.prompt_format=canary \
            model.model_defaults.asr_enc_hidden=256 \
            model.model_defaults.lm_dec_hidden=256 \
            model.encoder.n_layers=12 \
            model.transf_encoder.num_layers=0 \
            model.transf_decoder.config_dict.num_layers=12 \
            model.train_ds.manifest_filepath=/home/TestData/asr/manifests/canary/an4_canary_train.json \
            ++model.train_ds.is_tarred=false \
            model.train_ds.batch_duration=60 \
            +model.train_ds.text_field="answer" \
            +model.train_ds.lang_field="target_lang" \
            model.validation_ds.manifest_filepath=/home/TestData/asr/manifests/canary/an4_canary_val.json \
            +model.validation_ds.text_field="answer" \
            +model.validation_ds.lang_field="target_lang" \
            model.test_ds.manifest_filepath=/home/TestData/asr/manifests/canary/an4_canary_val.json \
            +model.test_ds.text_field="answer" \
            +model.test_ds.lang_field="target_lang" \
            model.tokenizer.langs.spl_tokens.dir=/home/TestData/asr_tokenizers/canary/canary_spl_tokenizer_v32 \
            model.tokenizer.langs.spl_tokens.type="bpe" \
            model.tokenizer.langs.en.dir=/home/TestData/asr_tokenizers/canary/en/tokenizer_spe_bpe_v1024_max_4 \
            model.tokenizer.langs.en.type=bpe \
            ++model.tokenizer.langs.es.dir=/home/TestData/asr_tokenizers/canary/es/tokenizer_spe_bpe_v1024_max_4 \
            ++model.tokenizer.langs.es.type=bpe \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.use_distributed_sampler=false \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_aed_results
            rm -rf examples/asr/speech_to_text_results


  # L2: Speaker dev run
  L2_Speaker_dev_run_Speaker_Recognition:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/recognition/speaker_reco.py \
            model.train_ds.batch_size=10 \
            model.validation_ds.batch_size=2 \
            model.train_ds.manifest_filepath=/home/TestData/an4_speaker/train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_speaker/dev.json \
            model.decoder.num_classes=2 \
            trainer.max_epochs=10 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/speaker_tasks/recognition/speaker_recognition_results
            rm -rf examples/speaker_tasks/recognition/speaker_recognition_results

  L2_Speaker_dev_run_Speaker_Diarization:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/diarization/neural_diarizer/multiscale_diar_decoder.py \
            model.diarizer.speaker_embeddings.model_path=titanet_large \
            model.train_ds.batch_size=5 \
            model.validation_ds.batch_size=5 \
            model.train_ds.emb_dir=examples/speaker_tasks/diarization/speaker_diarization_results \
            model.validation_ds.emb_dir=examples/speaker_tasks/diarization/speaker_diarization_results \
            model.train_ds.manifest_filepath=/home/TestData/an4_diarizer/simulated_train/msdd_data.50step.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_diarizer/simulated_valid/msdd_data.50step.json \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/speaker_tasks/diarization/speaker_diarization_results
            rm -rf examples/speaker_tasks/diarization/speaker_diarization_results

  L2_Speaker_dev_run_Speech_to_Label:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_classification/speech_to_label.py \
            model.train_ds.manifest_filepath=/home/TestData/speech_commands/train_manifest.json \
            model.validation_ds.manifest_filepath=/home/TestData/speech_commands/test_manifest.json \
            model.test_ds.manifest_filepath=/home/TestData/speech_commands/test_manifest.json \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            model.preprocessor._target_=nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor \
            ~model.preprocessor.window_size \
            ~model.preprocessor.window_stride \
            ~model.preprocessor.window \
            ~model.preprocessor.n_mels \
            ~model.preprocessor.n_mfcc \
            ~model.preprocessor.n_fft \
            exp_manager.exp_dir=examples/asr/speech_to_label_results
            rm -rf examples/asr/speech_to_label_results

  L2_Speaker_dev_run_Speaker_Diarization_with_ASR_Inference:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/diarization/clustering_diarizer/offline_diar_with_asr_infer.py \
            diarizer.manifest_filepath=/home/TestData/an4_diarizer/an4_manifest.json \
            diarizer.speaker_embeddings.model_path=/home/TestData/an4_diarizer/spkr.nemo \
            diarizer.speaker_embeddings.parameters.save_embeddings=True \
            diarizer.speaker_embeddings.parameters.window_length_in_sec=[1.5] \
            diarizer.speaker_embeddings.parameters.shift_length_in_sec=[0.75] \
            diarizer.speaker_embeddings.parameters.multiscale_weights=[1.0] \
            diarizer.asr.model_path=QuartzNet15x5Base-En \
            diarizer.asr.parameters.asr_based_vad=True \
            diarizer.out_dir=examples/speaker_tasks/diarization/speaker_diarization_asr_results
            rm -rf examples/speaker_tasks/diarization/speaker_diarization_asr_results




