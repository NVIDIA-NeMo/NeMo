# Copyright (c) 2020-2021, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
name: "CICD NeMo"

on:
  push:
    branches: [ "main", "pagaray/nemo_cicd" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main", "pagaray/nemo_cicd" ]

jobs:
  gpu-test:
    runs-on: self-hosted-azure
    steps:
    - name: Run nvidia-smi test
      run: |
        whoami
        nvidia-smi

  cicd-test-container-setup:
    runs-on: self-hosted-azure
    # uses: actions/cache@v2
    #container:
#      image: nvcr.io/nvidia/pytorch:23.10-py3
#      options: 
#        # --user 0:128
#        --device=/dev/nvidia0
#        --gpus all
#        --shm-size=8g 
#        --env TRANSFORMERS_OFFLINE=0 
#        --env HYDRA_FULL_ERROR=1
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Container setup
      run: |
        # Pull base PyTorch container
        docker pull nvcr.io/nvidia/pytorch:23.10-py3
        docker run --device=/dev/nvidia0 --gpus all --shm-size=8g --env TRANSFORMERS_OFFLINE=0 --env HYDRA_FULL_ERROR=1 --volume $(pwd):/workspace --volume /home/TestData:/home/TestData nvcr.io/nvidia/pytorch:23.10-py3 /bin/bash -c '
            set -x

            # PyTorch version
            python -c "import torch; print(torch.__version__)"
            python -c "import torchvision; print(torchvision.__version__)"

            # Install test requirements
            apt-get update && apt-get install -y bc && pip install -r requirements/requirements_test.txt && pip install -r requirements/requirements_lightning.txt

            # Code formatting checks
            python setup.py style

            # Copyright Headers check
            python tests/check_copyright_header.py --dir .

            # NeMo Installation
            ./reinstall.sh release

            # Transformer Engine 1.2.0
            # Transformer Engine installation
            git clone https://github.com/NVIDIA/TransformerEngine.git && \
                pushd TransformerEngine && \
                git fetch origin 4f9662fbe621671f5f905e772fc1138953af77f6 && \
                git checkout FETCH_HEAD && \
                git submodule init && git submodule update && \
                NVTE_FRAMEWORK=pytorch NVTE_WITH_USERBUFFERS=1 MPI_HOME=/usr/local/mpi pip install .  && \
                popd

            # Apex bugfix for PyTorch 23.11 container: https://github.com/NVIDIA/apex/pull/1760
            # Apex installation
            git clone https://github.com/NVIDIA/apex.git && \
                pushd apex && \
                git checkout c07a4cf67102b9cd3f97d1ba36690f985bae4227 && \
                cp -R apex /usr/local/lib/python3.10/dist-packages && \
                popd

            # pip package should be working with main, if not we can update the commit here
            # until the pip package is updated
            # Megatron Core installation
            git clone https://github.com/NVIDIA/Megatron-LM.git && \
                pushd Megatron-LM && \
                git checkout ad53b1e38689a0ceed75ade7821f4e6c7554abb4 && \
                pip install . && \
                popd

            # PyTorch Lightning version
            python -c "import pytorch_lightning; print(pytorch_lightning.__version__)"

            # PyTorch Lightning DDP Checks
            CUDA_VISIBLE_DEVICES="0,1" python "tests/core_ptl/check_for_ranks.py"

            # Basic Import Checks
            python -c "import nemo.collections.asr as nemo_asr"
            python -c "import nemo.collections.nlp as nemo_nlp"
            python -c "import nemo.collections.tts as nemo_tts"

            '
            ### \'\'


    - name: Push container to registry for future use
      run: |
        # Push container
        echo "Docker: List containers" && docker ps -a
        DOCKER_COMMIT=$(docker ps --latest --quiet)  # latest container
        docker commit $DOCKER_COMMIT nemo_container
        docker tag nemo_container localhost:5000/nemo_container
        docker push localhost:5000/nemo_container


    # - name: Build and push to local registry
    #   uses: docker/build-push-action@v5
    #   with:
    #       context: .
    #       push: true
    #       tags: localhost:5000/name/app:latest

    # - name: Inspect
    #   run: |
    #     docker buildx imagetools inspect localhost:5000/name/app:latest 


  L0_Unit_Tests_GPU:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    - name: "L0: Unit Tests GPU"
      run: |
        NEMO_NUMBA_MINVER=0.53 pytest -m "not pleasefixme" --with_downloads

  L0_Unit_Tests_CPU:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    - name: "L0: Unit Tests CPU"
      run: |
        CUDA_VISIBLE_DEVICES="" NEMO_NUMBA_MINVER=0.53 pytest -m "not pleasefixme" --cpu --with_downloads --relax_numba_compat





##     - name: L2: Multimodal Imagen Train

  # L2: Community LLM Checkpoints tests
  L2_Community_LLM_Checkpoints_tests_Llama:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            CUDA_VISIBLE_DEVICES=0 python scripts/nlp_language_modeling/convert_hf_llama_to_nemo.py \
            --in-file=/home/TestData/nlp/megatron_llama/llama-ci-hf \
            --out-file=/home/TestData/nlp/megatron_llama/ci.nemo \
            --precision=16
            rm -f /home/TestData/nlp/megatron_llama/ci.nemo

  L2_Community_LLM_Checkpoints_tests_StarCoder:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python scripts/nlp_language_modeling/convert_starcoder_hf_to_nemo.py \
            --config examples/nlp/language_modeling/conf/megatron_gpt_config.yaml \
            --input /home/TestData/nlp/megatron_gpt/starcoder-ci-hf \
            --output /home/TestData/nlp/megatron_gpt/starcoder-ci-hf
            rm -f /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/megatron_starcoder_tp1_pp1.nemo

  L2_Community_LLM_Checkpoints_tests_Falcon:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python scripts/nlp_language_modeling/convert_hf_falcon_to_nemo.py \
            --config examples/nlp/language_modeling/conf/megatron_falcon_config.yaml \
            --input /home/TestData/nlp/megatron_gpt/falcon-ci-hf \
            --output /home/TestData/nlp/megatron_gpt/falcon-ci-hf/falcon_ci.nemo
            rm -f /home/TestData/nlp/megatron_gpt/falcon-ci-hf/falcon_ci.nemo


  # L2: ASR dev run
  ASR_dev_run_Speech_to_Text:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc.py \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_results
            rm -rf examples/asr/speech_to_text_results

  ASR_dev_run_Speech_to_Text_WPE_-_CitriNet:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \
            --config-path="../conf/citrinet/" --config-name="config_bpe" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            model.tokenizer.dir="/home/TestData/asr_tokenizers/an4_wpe_128/" \
            model.tokenizer.type="wpe" \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_wpe_results
            rm -rf examples/asr/speech_to_text_wpe_results

  ASR_dev_run_Speech_Pre-training_-_CitriNet:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_pretraining/speech_pre_training.py \
            --config-path="../conf/ssl/citrinet/" --config-name="citrinet_ssl_ci" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_pre_training_results
            rm -rf examples/asr/speech_pre_training_results

  ASR_dev_run_Speech_To_Text_Finetuning:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_to_text_finetune.py \
            --config-path="conf/asr_finetune" --config-name="speech_to_text_finetune" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            init_from_nemo_model=/home/TestData/asr/stt_en_fastconformer_transducer_large.nemo \
            model.tokenizer.update_tokenizer=False \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_finetuning_results
            rm -rf examples/asr/speech_finetuning_results

  ASR_dev_run_Speech_To_Text_HF_Finetuning:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_to_text_finetune.py \
            --config-path="conf/asr_finetune" --config-name="speech_to_text_hf_finetune" \
            ~model.train_ds.hf_data_cfg \
            model.train_ds.num_workers=1 \
            model.train_ds.batch_size=2 model.validation_ds.batch_size=2 \
            model.train_ds.streaming=true \
            +model.train_ds.hf_data_cfg.path="librispeech_asr" \
            +model.train_ds.hf_data_cfg.name=null \
            +model.train_ds.hf_data_cfg.split="test.clean" \
            +model.train_ds.hf_data_cfg.streaming=true \
            ~model.validation_ds.hf_data_cfg \
            model.validation_ds.streaming=true \
            +model.validation_ds.hf_data_cfg.path="librispeech_asr" \
            +model.validation_ds.hf_data_cfg.name=null \
            +model.validation_ds.hf_data_cfg.split="test.clean" \
            +model.validation_ds.hf_data_cfg.streaming=true \
            ~model.test_ds \
            init_from_nemo_model=/home/TestData/asr/stt_en_fastconformer_transducer_large.nemo \
            model.tokenizer.update_tokenizer=False \
            model.optim.sched.warmup_steps=0 \
            +model.optim.sched.max_steps=3 \
            trainer.max_epochs=null \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_finetuning_results
            rm -rf examples/asr/speech_finetuning_results

  ASR_dev_run_Speech_to_Text_WPE_-_Conformer:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \
            --config-path="../conf/conformer" --config-name="conformer_ctc_bpe" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            model.tokenizer.dir="/home/TestData/asr_tokenizers/an4_wpe_128/" \
            model.tokenizer.type="wpe" \
            model.train_ds.batch_size=4 \
            model.validation_ds.batch_size=4 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_wpe_conformer_results
            rm -rf examples/asr/speech_to_text_wpe_conformer_results

  # L2: ASR dev run - part two
  ASR_dev_run-part_two_Speech_to_Text_WPE_-_Squeezeformer:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \
            --config-path="../conf/squeezeformer" --config-name="squeezeformer_ctc_bpe" \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            model.tokenizer.dir="/home/TestData/asr_tokenizers/an4_wpe_128/" \
            model.tokenizer.type="wpe" \
            model.encoder.d_model=144 \
            model.train_ds.batch_size=4 \
            model.validation_ds.batch_size=4 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_wpe_squeezeformer_results
            rm -rf examples/asr/speech_to_text_wpe_squeezeformer_results

  L2_Speech_to_Text_EMA:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc.py \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.devices=2 \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            +exp_manager.ema.enable=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_results
            rm -rf examples/asr/speech_to_text_results

  L2_Speech_to_Text_AED:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_multitask/speech_to_text_aed.py \
            model.prompt_format=canary \
            model.model_defaults.asr_enc_hidden=256 \
            model.model_defaults.lm_dec_hidden=256 \
            model.encoder.n_layers=12 \
            model.transf_encoder.num_layers=0 \
            model.transf_decoder.config_dict.num_layers=12 \
            model.train_ds.manifest_filepath=/home/TestData/asr/manifests/canary/an4_canary_train.json \
            ++model.train_ds.is_tarred=false \
            model.train_ds.batch_duration=60 \
            +model.train_ds.text_field="answer" \
            +model.train_ds.lang_field="target_lang" \
            model.validation_ds.manifest_filepath=/home/TestData/asr/manifests/canary/an4_canary_val.json \
            +model.validation_ds.text_field="answer" \
            +model.validation_ds.lang_field="target_lang" \
            model.test_ds.manifest_filepath=/home/TestData/asr/manifests/canary/an4_canary_val.json \
            +model.test_ds.text_field="answer" \
            +model.test_ds.lang_field="target_lang" \
            model.tokenizer.langs.spl_tokens.dir=/home/TestData/asr_tokenizers/canary/canary_spl_tokenizer_v32 \
            model.tokenizer.langs.spl_tokens.type="bpe" \
            model.tokenizer.langs.en.dir=/home/TestData/asr_tokenizers/canary/en/tokenizer_spe_bpe_v1024_max_4 \
            model.tokenizer.langs.en.type=bpe \
            ++model.tokenizer.langs.es.dir=/home/TestData/asr_tokenizers/canary/es/tokenizer_spe_bpe_v1024_max_4 \
            ++model.tokenizer.langs.es.type=bpe \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.use_distributed_sampler=false \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_aed_results
            rm -rf examples/asr/speech_to_text_results


  # L2: Speaker dev run
  L2_Speaker_dev_run_Speaker_Recognition:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/recognition/speaker_reco.py \
            model.train_ds.batch_size=10 \
            model.validation_ds.batch_size=2 \
            model.train_ds.manifest_filepath=/home/TestData/an4_speaker/train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_speaker/dev.json \
            model.decoder.num_classes=2 \
            trainer.max_epochs=10 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/speaker_tasks/recognition/speaker_recognition_results
            rm -rf examples/speaker_tasks/recognition/speaker_recognition_results

  L2_Speaker_dev_run_Speaker_Diarization:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/diarization/neural_diarizer/multiscale_diar_decoder.py \
            model.diarizer.speaker_embeddings.model_path=titanet_large \
            model.train_ds.batch_size=5 \
            model.validation_ds.batch_size=5 \
            model.train_ds.emb_dir=examples/speaker_tasks/diarization/speaker_diarization_results \
            model.validation_ds.emb_dir=examples/speaker_tasks/diarization/speaker_diarization_results \
            model.train_ds.manifest_filepath=/home/TestData/an4_diarizer/simulated_train/msdd_data.50step.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_diarizer/simulated_valid/msdd_data.50step.json \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/speaker_tasks/diarization/speaker_diarization_results
            rm -rf examples/speaker_tasks/diarization/speaker_diarization_results

  L2_Speaker_dev_run_Speech_to_Label:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_classification/speech_to_label.py \
            model.train_ds.manifest_filepath=/home/TestData/speech_commands/train_manifest.json \
            model.validation_ds.manifest_filepath=/home/TestData/speech_commands/test_manifest.json \
            model.test_ds.manifest_filepath=/home/TestData/speech_commands/test_manifest.json \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            model.preprocessor._target_=nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor \
            ~model.preprocessor.window_size \
            ~model.preprocessor.window_stride \
            ~model.preprocessor.window \
            ~model.preprocessor.n_mels \
            ~model.preprocessor.n_mfcc \
            ~model.preprocessor.n_fft \
            exp_manager.exp_dir=examples/asr/speech_to_label_results
            rm -rf examples/asr/speech_to_label_results

  L2_Speaker_dev_run_Speaker_Diarization_with_ASR_Inference:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/diarization/clustering_diarizer/offline_diar_with_asr_infer.py \
            diarizer.manifest_filepath=/home/TestData/an4_diarizer/an4_manifest.json \
            diarizer.speaker_embeddings.model_path=/home/TestData/an4_diarizer/spkr.nemo \
            diarizer.speaker_embeddings.parameters.save_embeddings=True \
            diarizer.speaker_embeddings.parameters.window_length_in_sec=[1.5] \
            diarizer.speaker_embeddings.parameters.shift_length_in_sec=[0.75] \
            diarizer.speaker_embeddings.parameters.multiscale_weights=[1.0] \
            diarizer.asr.model_path=QuartzNet15x5Base-En \
            diarizer.asr.parameters.asr_based_vad=True \
            diarizer.out_dir=examples/speaker_tasks/diarization/speaker_diarization_asr_results
            rm -rf examples/speaker_tasks/diarization/speaker_diarization_asr_results
  L2_Speaker_dev_run_Clustering_Diarizer_Inference:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |  
            python examples/speaker_tasks/diarization/clustering_diarizer/offline_diar_infer.py \
            diarizer.manifest_filepath=/home/TestData/an4_diarizer/an4_manifest.json \
            diarizer.speaker_embeddings.model_path=/home/TestData/an4_diarizer/spkr.nemo \
            diarizer.speaker_embeddings.parameters.save_embeddings=True \
            diarizer.speaker_embeddings.parameters.window_length_in_sec=1.5 \
            diarizer.speaker_embeddings.parameters.shift_length_in_sec=0.75 \
            diarizer.speaker_embeddings.parameters.multiscale_weights=null \
            diarizer.vad.model_path=/home/TestData/an4_diarizer/MatchboxNet_VAD_3x2.nemo \
            diarizer.out_dir=examples/speaker_tasks/diarization/clustering_diarizer_results
            rm -rf examples/speaker_tasks/diarization/clustering_diarizer_results

  L2_Speaker_dev_run_Neural_Diarizer_Inference:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/speaker_tasks/diarization/neural_diarizer/multiscale_diar_decoder_infer.py \
            diarizer.manifest_filepath=/home/TestData/an4_diarizer/an4_manifest.json \
            diarizer.msdd_model.model_path=/home/TestData/an4_diarizer/diar_msdd_telephonic.nemo \
            diarizer.speaker_embeddings.parameters.save_embeddings=True \
            diarizer.vad.model_path=/home/TestData/an4_diarizer/MatchboxNet_VAD_3x2.nemo \
            diarizer.out_dir=examples/speaker_tasks/diarization/neural_diarizer_results
            rm -rf examples/speaker_tasks/diarization/neural_diarizer_results

  L2_Speaker_dev_run_Multispeaker_ASR_Data_Simulation:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python tools/speech_data_simulator/multispeaker_simulator.py \
            --config-path=conf --config-name=data_simulator.yaml \
            data_simulator.random_seed=42 \
            data_simulator.manifest_filepath=/home/TestData/LibriSpeechShort/dev-clean-align-short.json \
            data_simulator.outputs.output_dir=./test_simulator \
            data_simulator.session_config.num_sessions=2 \
            data_simulator.session_config.session_length=60
            rm -rf ./test_simulator


  # L2: ASR Multi-dataloader dev run
  L2_ASR_Multi-dataloader_dev_run_Speech_to_Text_multi-dataloader:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_ctc/speech_to_text_ctc.py \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=[/home/TestData/an4_dataset/an4_val.json,/home/TestData/an4_dataset/an4_val.json] \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            +trainer.num_sanity_val_steps=1 \
            exp_manager.exp_dir=examples/asr/speech_to_text_results
            rm -rf examples/asr/speech_to_text_results

  L2_ASR_Multi-dataloader_dev_run_Speech_to_Label_multi-dataloader:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/speech_classification/speech_to_label.py \
            model.train_ds.manifest_filepath=/home/TestData/speech_commands/train_manifest.json \
            model.validation_ds.manifest_filepath=[/home/TestData/speech_commands/test_manifest.json,/home/TestData/speech_commands/test_manifest.json] \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            +trainer.num_sanity_val_steps=1 \
            model.preprocessor._target_=nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor \
            ~model.preprocessor.window_size \
            ~model.preprocessor.window_stride \
            ~model.preprocessor.window \
            ~model.preprocessor.n_mels \
            ~model.preprocessor.n_mfcc \
            ~model.preprocessor.n_fft \
            exp_manager.exp_dir=examples/asr/speech_to_label_results
            rm -rf examples/asr/speech_to_label_results


  # L2: ASR Adapters
  L2_ASR_Adapters_Linear_Adapters:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_adapters/train_asr_adapter.py \
            model.pretrained_model="stt_en_conformer_ctc_small" \
            model.adapter.adapter_name="an4" \
            model.adapter.linear.in_features=176 \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.max_steps=5 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_adapters_results
            rm -rf examples/asr/speech_to_text_adapters_results

  L2_ASR_Adapters_RelPos_MHA_Adapters:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/asr_adapters/train_asr_adapter.py \
            model.pretrained_model="stt_en_conformer_ctc_small" \
            model.adapter.adapter_name="encoder:an4" \
            model.adapter.adapter_type="tiny_attn" \
            model.adapter.tiny_attn.n_feat=176 \
            model.train_ds.manifest_filepath=/home/TestData/an4_dataset/an4_train.json \
            model.validation_ds.manifest_filepath=/home/TestData/an4_dataset/an4_val.json \
            trainer.max_steps=5 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=True \
            exp_manager.exp_dir=examples/asr/speech_to_text_adapters_mha_results
            rm -rf examples/asr/speech_to_text_adapters_mha_results


  # L2: Speech Transcription
  L2_Speech_Transcription_Speech_to_Text_Transcribe:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/asr/transcribe_speech.py \
            pretrained_name="QuartzNet15x5Base-En" \
            audio_dir="/home/TestData/an4_transcribe/test_subset/" \
            output_filename="stt_test_res.json" \
            amp=true
            rm -rf stt_test_res.json

  # L2: Transducer alignment
  L2_Transducer_alignment_Running_pytest:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            pytest tests/collections/asr/decoding/rnnt_alignments_check.py --durations=-1


  # L2: Segmentation Tool
  L2_Segmentation_Tool_Install_ctc_segmentation_requirements:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd tools/ctc_segmentation && \
            pip install -r requirements.txt && \
            apt-get update && apt-get install libsox-fmt-all -y

  L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Eng_CitriNet_with_wav:
    needs: [L2_Segmentation_Tool_Install_ctc_segmentation_requirements]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd tools/ctc_segmentation && \
            TIME=`date +"%Y-%m-%d-%T"` && \
            /bin/bash run_segmentation.sh \
            --MODEL_NAME_OR_PATH="stt_en_citrinet_512_gamma_0_25" \
            --DATA_DIR=/home/TestData/ctc_segmentation/eng \
            --OUTPUT_DIR=/home/TestData/ctc_segmentation/eng/output${TIME} \
            --LANGUAGE=en \
            --USE_NEMO_NORMALIZATION="TRUE" && \
            python /home/TestData/ctc_segmentation/verify_alignment.py \
            -r /home/TestData/ctc_segmentation/eng/eng_valid_segments_1.7.txt \
            -g /home/TestData/ctc_segmentation/eng/output${TIME}/verified_segments/nv_test_segments.txt && \
            rm -rf /home/TestData/ctc_segmentation/eng/output${TIME}

  L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Ru_QN_with_mp3:
    needs: [L2_Segmentation_Tool_Install_ctc_segmentation_requirements]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd tools/ctc_segmentation && \
            TIME=`date +"%Y-%m-%d-%T"` && \
            /bin/bash run_segmentation.sh \
            --MODEL_NAME_OR_PATH=/home/TestData/ctc_segmentation/QuartzNet15x5-Ru-e512-wer14.45.nemo \
            --DATA_DIR=/home/TestData/ctc_segmentation/ru \
            --OUTPUT_DIR=/home/TestData/ctc_segmentation/ru/output${TIME} \
            --LANGUAGE=ru \
            --ADDITIONAL_SPLIT_SYMBOLS=";" && \
            python /home/TestData/ctc_segmentation/verify_alignment.py \
            -r /home/TestData/ctc_segmentation/ru/valid_ru_segments_1.7.txt \
            -g /home/TestData/ctc_segmentation/ru/output${TIME}/verified_segments/ru_segments.txt && \
            rm -rf /home/TestData/ctc_segmentation/ru/output${TIME}


  # L2: G2P Models
  L2_G2P_Models_G2P_Conformer_training_evaluation_and_inference:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/tts/g2p && \
                TIME=`date +"%Y-%m-%d-%T"` && OUTPUT_DIR_CONFORMER=output_ctc_${TIME} && \
                python g2p_train_and_evaluate.py \
                    train_manifest=/home/TestData/g2p/g2p.json \
                    validation_manifest=/home/TestData/g2p/g2p.json \
                    model.test_ds.manifest_filepath=/home/TestData/g2p/g2p.json \
                    model.tokenizer.dir=/home/TestData/g2p/tokenizer_spe_unigram_v512 \
                    trainer.max_epochs=1 \
                    model.max_source_len=64 \
                    trainer.devices=[0] \
                    do_training=True \
                    do_testing=True \
                    exp_manager.exp_dir=${OUTPUT_DIR_CONFORMER} \
                    +exp_manager.use_datetime_version=False\
                    +exp_manager.version=test \
                    --config-name=g2p_conformer_ctc && \
                python g2p_inference.py \
                    pretrained_model=${OUTPUT_DIR_CONFORMER}/G2P-Conformer-CTC/test/checkpoints/G2P-Conformer-CTC.nemo \
                    manifest_filepath=/home/TestData/g2p/g2p.json \
                    phoneme_field=text

    # TODO: pleasefixme @redoctopus
    # - name: ByT5G2P training, evaluation and inference
    #   run: |
    #     cd examples/tts/g2p && \
    #         TIME=`date +"%Y-%m-%d-%T"` && OUTPUT_DIR_T5=output_byt5_${TIME} && \
    #         python g2p_train_and_evaluate.py \
    #             train_manifest=/home/TestData/g2p/g2p.json \
    #             validation_manifest=/home/TestData/g2p/g2p.json \
    #             model.test_ds.manifest_filepath=/home/TestData/g2p/g2p.json \
    #             trainer.max_epochs=1 \
    #             model.max_source_len=64 \
    #             trainer.devices=[1] \
    #             do_training=True \
    #             do_testing=True \
    #             exp_manager.exp_dir=${OUTPUT_DIR_T5} \
    #             +exp_manager.use_datetime_version=False\
    #             +exp_manager.version=test && \
    #         python g2p_inference.py \
    #             pretrained_model=${OUTPUT_DIR_T5}/T5G2P/test/checkpoints/T5G2P.nemo \
    #             manifest_filepath=/home/TestData/g2p/g2p.json \
    #             phoneme_field=text
    #   }
    # }

  L2_G2P_Models_HeteronymClassificationModel_training_evaluation_and_inference:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/tts/g2p && \
                TIME=`date +"%Y-%m-%d-%T"` && OUTPUT_DIR=output_${TIME} && \
                python g2p_heteronym_classification_train_and_evaluate.py \
                    train_manifest=/home/TestData/g2p/manifest.json \
                    validation_manifest=/home/TestData/g2p/manifest.json \
                    test_manifest=/home/TestData/g2p/manifest.json \
                    model.wordids=/home/TestData/g2p/wordids.tsv \
                    trainer.max_epochs=1 \
                    model.max_seq_length=64 \
                    do_training=True \
                    do_testing=True \
                    exp_manager.exp_dir=${OUTPUT_DIR} \
                    +exp_manager.use_datetime_version=False\
                    +exp_manager.version=test && \
                python g2p_heteronym_classification_inference.py \
                    manifest=/home/TestData/g2p/manifest.json \
                    pretrained_model=${OUTPUT_DIR}/HeteronymClassification/test/checkpoints/HeteronymClassification.nemo \
                    output_manifest=preds.json


  # L2: Dialogue Classification
  L2_Dialogue_Classification_Dialogue_Intent_and_slot_classification_using_GPT:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            model.dataset.data_dir=/home/TestData/nlp/sgd_small \
            model.language_model.lm_checkpoint=/home/TestData/nlp/gpt2/pytorch_model.bin\
            model.tokenizer.vocab_file=/home/TestData/nlp/gpt2/vocab.json\
            model.dataset.dialogues_example_dir=sgd_gen_outputs \
            model.dataset.task_name=debug_sample \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[0] \
            model.dataset.use_cache=false \
            model.tokenizer.special_tokens={pad_token:"endoftext"} \
            model.tokenizer.tokenizer_name=gpt2 \
            model.tokenizer.vocab_file=/home/TestData/nlp/gpt2/vocab.json\
            model.language_model.pretrained_model_name=/home/TestData/nlp/gpt2 \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf sgd_gen_outputs

  L2_Dialogue_Classification_Intent_and_slot_classification_using_SGDQA:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            model.dataset.data_dir=/home/TestData/nlp/sgd_small \
            model.dataset.dialogues_example_dir=sgd_gen_bert_outputs \
            model.dataset.task_name=debug_sample \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.dataset.num_tasks=6 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[0] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=bert-base-cased \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf sgd_gen_bert_outputs

  L2_Dialogue_Classification_Intent_and_slot_classification_using_IntentSlotClassificationModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            model.dataset.data_dir=/home/TestData/nlp/processed_assistant \
            model.dataset.dialogues_example_dir=sgd_gen_bert_intent_classification_outputs \
            model.dataset.task=assistant \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[0] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=bert-base-uncased \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf sgd_gen_bert_intent_classification_outputs

  L2_Dialogue_Classification_Intent_classification_using_ZeroShotIntentModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/drive_thru_revised \
            model.original_nemo_checkpoint=/home/TestData/nlp/drive_thru_revised/zeroshotintent_en_bert_base_uncased.nemo \
            model.dataset.dialogues_example_dir=sgd_gen_zero_shot_intent_classification_outputs \
            model.dataset.task=zero_shot \
            model.dataset.prompt_template="This example is" \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[1] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=bert-base-uncased \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf sgd_gen_zero_shot_intent_classification_outputs

  L2_Dialogue_Classification_Design_Intent_classification_using_ZeroShotIntentModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/design_dataset \
            model.original_nemo_checkpoint=/home/TestData/nlp/drive_thru_revised/zeroshotintent_en_bert_base_uncased.nemo \
            model.dataset.dialogues_example_dir=design_zero_shot_intent_classification_outputs \
            model.dataset.task=design \
            model.dataset.prompt_template="This example is related to" \
            model.library=megatron \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[1] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=bert-base-uncased \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf design_zero_shot_intent_classification_outputs

  L2_Dialogue_Classification_Design_Intent_classification_using_ZeroShotIntentModel_BART_Classifier:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/design_dataset \
            model.original_nemo_checkpoint=/home/TestData/nlp/drive_thru_revised/zeroshotintent_en_bert_base_uncased.nemo \
            model.dataset.dialogues_example_dir=design_zero_shot_intent_classification_bart_outputs \
            model.dataset.task=design \
            model.dataset.prompt_template="This example is related to" \
            model.library=huggingface \
            trainer.devices=[1] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=bert-base-uncased \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf design_zero_shot_intent_classification_bart_outputs

  L2_Dialogue_Classification_Design_Intent_classification_using_DialogueNearestNeighbourModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/design_dataset \
            model.dataset.dialogues_example_dir=design_dialogue_nearest_neighbour_classification_outputs \
            model.dataset.task=design \
            model.dataset.prompt_template="" \
            model.library=huggingface \
            trainer.devices=[0] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=sentence-transformers/all-MiniLM-L6-v2 \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf design_dialogue_nearest_neighbour_classification_outputs

  # L2: Dialogue Generation
  L2_Dialogue_Generation_Dialogue_Answer_Extender_using_DialogueS2SGenerationModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/ms-marco-qa \
            model.dataset.dialogues_example_dir=answer_extender_s2s \
            model.dataset.task=ms_marco \
            model.library=huggingface \
            model.dataset.debug_mode=True \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[1] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=facebook/bart-large \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf answer_extender_s2s

  L2_Dialogue_Generation_Dialogue_SGD_Based_Answer_Extender_using_DialogueS2SGenerationModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/sgd_small \
            model.dataset.dialogues_example_dir=sgd_answer_extender_s2s \
            model.dataset.task_name=debug_sample \
            model.dataset.task=sgd_generation \
            model.dataset.input_field=utterance+system_actions \
            model.dataset.output_field=system_utterance \
            model.dataset.use_cache=false \
            model.dataset.system_utterance=next_turn \
            model.dataset.debug_mode=True \
            model.dataset.prompt_template=slots_values \
            model.library=huggingface \
            trainer.max_steps=1 \
            trainer.max_epochs=1 \
            model.train_ds.batch_size=2 \
            model.validation_ds.batch_size=2 \
            model.test_ds.batch_size=2 \
            model.nemo_path=null \
            trainer.val_check_interval=0.0 \
            trainer.devices=[0] \
            model.language_model.pretrained_model_name=facebook/bart-large \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf sgd_answer_extender_s2s

#     - name: L2: Dialogue Generation Part 2
#       when {
#         anyOf {
#           branch main
#           changeRequest target: main
#         }
#       }
#       failFast true
#       parallel {
#         - name: Dialogue: Answer Extender using DialogueGPTGenerationModel
#           - run: |
#             cd examples/nlp/dialogue && \
#             python dialogue.py \
#             do_training=False \
#             model.dataset.data_dir=/home/TestData/nlp/ms-marco-qa \
#             model.dataset.dialogues_example_dir=answer_extender \
#             model.library=huggingface \
#             model.dataset.task=ms_marco \
#             model.dataset.debug_mode=True \
#             trainer.val_check_interval=0.0 \
#             trainer.devices=[0] \
#             model.dataset.use_cache=false \
#             model.language_model.pretrained_model_name=gpt2 \
#             trainer.accelerator=gpu \
#             exp_manager=null  && \
#             rm -rf answer_extender
#           }
#         }
#       }
#     }

  # L2: COPY
  L2_COPY_Dialogue_Answer_Extender_using_DialogueGPTGenerationModel:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/dialogue && \
            python dialogue.py \
            do_training=False \
            model.dataset.data_dir=/home/TestData/nlp/ms-marco-qa \
            model.dataset.dialogues_example_dir=answer_extender \
            model.library=huggingface \
            model.dataset.task=ms_marco \
            model.dataset.debug_mode=True \
            trainer.val_check_interval=0.0 \
            trainer.devices=[0] \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name=gpt2 \
            trainer.accelerator=gpu \
            exp_manager=null  && \
            rm -rf answer_extender

  # L2: Duplex Text Normalization
  L2_Duplex_Text_Normalization_with_Tarred_dataset:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/duplex_text_normalization && \
            python duplex_text_normalization_train.py \
            data.validation_ds.data_path=/home/TestData/nlp/duplex_text_norm/small_test.tsv \
            mode=tn \
            lang=en \
            tagger_model.do_training=false \
            decoder_model.transformer=t5-small \
            data.validation_ds.batch_size=2 \
            data.train_ds.use_cache=false \
            data.validation_ds.use_cache=false \
            data.test_ds.batch_size=2 \
            data.train_ds.decoder_data_augmentation=false \
            data.train_ds.num_workers=2 \
            decoder_trainer.devices=[0,1] \
            decoder_trainer.accelerator="gpu" \
            data.train_ds.use_tarred_dataset=true \
            +decoder_trainer.fast_dev_run=true \
            decoder_exp_manager.create_checkpoint_callback=false \
            data.train_ds.tar_metadata_file=/home/TestData/nlp/duplex_text_norm/tarred_small/metadata.json \
            data.test_ds.use_cache=false \
            data.test_ds.data_path=/home/TestData/nlp/duplex_text_norm/small_test.tsv

# Runs out of memory on the 12G TITAN V (GPU 0 on main CI)
# TODO: add when megatron bert is supported again in NeMo
# - name: L2: MegaBERT Token Classification
#   when {
#     anyOf {
#       branch main
#       changeRequest target: main
#     }
#   }
#   failFast true
#   - run: |
#     cd examples/nlp/token_classification && \
#     python token_classification_train.py \
#     model.dataset.data_dir=/home/TestData/nlp/token_classification_punctuation/ \
#     model.language_model.pretrained_model_name=megatron-bert-345m-uncased \
#     model.train_ds.batch_size=10 \
#     model.dataset.max_seq_length=50 \
#     model.dataset.use_cache=false \
#     trainer.accelerator=gpu \
#     trainer.strategy=ddp \
#     trainer.precision=16 \
#     trainer.devices=[1] \
#     trainer.accelerator="gpu" \
#     +trainer.fast_dev_run=true \
#     exp_manager=null
#   }
# }

  # L2: BERT Text Classification
  L2_BERT_Text_Classification_with_BERT_Test:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/text_classification && \
            python text_classification_with_bert.py \
            model.dataset.num_classes=6 \
            model.train_ds.file_path=/home/TestData/nlp/retail_text_classification/train.tsv \
            model.validation_ds.file_path=/home/TestData/nlp/retail_text_classification/dev.tsv \
            model.language_model.pretrained_model_name=distilbert-base-uncased \
            model.train_ds.batch_size=10 \
            model.dataset.max_seq_length=50 \
            model.dataset.use_cache=false \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=true \
            exp_manager=null

  # L2: Parallel BERT Question-Answering SQUAD v1.1 & v2.0
  L2_Parallel_BERT_Question-Answering_SQUAD_v1_1:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            # Cannot do fast_dev_run because squad needs whole dev dataset
            cd examples/nlp/question_answering && \
            python question_answering.py \
            model.train_ds.file=/home/TestData/nlp/squad_mini/v1.1/train-v1.1.json \
            model.dataset.use_cache=false \
            model.validation_ds.file=/home/TestData/nlp/squad_mini/v1.1/dev-v1.1.json \
            model.test_ds.file=/home/TestData/nlp/squad_mini/v1.1/dev-v1.1.json \
            model.train_ds.batch_size=2 \
            model.train_ds.num_samples=2 \
            model.validation_ds.batch_size=2 \
            model.validation_ds.num_samples=2 \
            model.test_ds.num_samples=2 \
            model.test_ds.batch_size=2 \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            model.language_model.pretrained_model_name=bert-base-uncased \
            model.dataset.version_2_with_negative=false \
            trainer.precision=16 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            exp_manager=null

  L2_Parallel_BERT_Question-Answering_SQUAD_v2_0:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            # Cannot do fast_dev_run because squad needs whole dev dataset
            cd examples/nlp/question_answering && \
            python question_answering.py \
            model.train_ds.file=/home/TestData/nlp/squad_mini/v2.0/train-v2.0.json \
            model.dataset.use_cache=false \
            model.train_ds.batch_size=2 \
            model.train_ds.num_samples=2 \
            model.validation_ds.batch_size=2 \
            model.validation_ds.num_samples=2 \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            model.validation_ds.file=/home/TestData/nlp/squad_mini/v2.0/dev-v2.0.json \
            model.language_model.pretrained_model_name=bert-base-uncased \
            model.dataset.version_2_with_negative=true \
            trainer.precision=16 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            exp_manager=null

  # L2: Parallel BART Question-Answering SQUAD v1.1 & v2.0
  L2_Parallel_BART_Question-Answering_SQUAD_v1_1:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/question_answering && \
            python question_answering.py \
            model.train_ds.file=/home/TestData/nlp/squad_mini/v1.1/train-v1.1.json \
            model.dataset.use_cache=false \
            model.dataset.check_if_answer_in_context=false \
            model.validation_ds.file=/home/TestData/nlp/squad_mini/v1.1/dev-v1.1.json \
            model.test_ds.file=/home/TestData/nlp/squad_mini/v1.1/dev-v1.1.json \
            model.train_ds.batch_size=2 \
            model.train_ds.num_samples=2 \
            model.validation_ds.batch_size=2 \
            model.validation_ds.num_samples=2 \
            model.test_ds.num_samples=2 \
            model.test_ds.batch_size=2 \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            model.language_model.pretrained_model_name=facebook/bart-base \
            model.dataset.version_2_with_negative=false \
            trainer.precision=16 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            exp_manager=null

  L2_Parallel_BART_Question-Answering_SQUAD_v2_0:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/question_answering && \
            python question_answering.py \
            model.train_ds.file=/home/TestData/nlp/squad_mini/v2.0/train-v2.0.json \
            model.dataset.use_cache=false \
            model.dataset.check_if_answer_in_context=false \
            model.train_ds.batch_size=2 \
            model.train_ds.num_samples=2 \
            model.validation_ds.batch_size=2 \
            model.validation_ds.num_samples=2 \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            model.validation_ds.file=/home/TestData/nlp/squad_mini/v2.0/dev-v2.0.json \
            model.language_model.pretrained_model_name=facebook/bart-base \
            model.dataset.version_2_with_negative=true \
            trainer.precision=16 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            exp_manager=null

  # L2: Parallel GPT2 Question-Answering SQUAD v1.1 & v2.0
  L2_Parallel_GPT2_Question-Answering_SQUAD_v1_1:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/question_answering && \
            python question_answering.py \
            model.train_ds.file=/home/TestData/nlp/squad_mini/v1.1/train-v1.1.json \
            model.dataset.use_cache=false \
            model.dataset.check_if_answer_in_context=false \
            model.validation_ds.file=/home/TestData/nlp/squad_mini/v1.1/dev-v1.1.json \
            model.test_ds.file=/home/TestData/nlp/squad_mini/v1.1/dev-v1.1.json \
            model.train_ds.batch_size=2 \
            model.train_ds.num_samples=2 \
            model.validation_ds.batch_size=2 \
            model.validation_ds.num_samples=2 \
            model.test_ds.num_samples=2 \
            model.test_ds.batch_size=2 \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            model.language_model.pretrained_model_name=gpt2 \
            model.dataset.version_2_with_negative=false \
            trainer.precision=16 \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            exp_manager=null

  L2_Parallel_GPT2_Question-Answering_SQUAD_v2_0:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/question_answering && \
            python question_answering.py \
            model.train_ds.file=/home/TestData/nlp/squad_mini/v2.0/train-v2.0.json \
            model.dataset.use_cache=false \
            model.dataset.check_if_answer_in_context=false \
            model.train_ds.batch_size=2 \
            model.train_ds.num_samples=2 \
            model.validation_ds.batch_size=2 \
            model.validation_ds.num_samples=2 \
            trainer.max_epochs=1 \
            trainer.max_steps=1 \
            model.validation_ds.file=/home/TestData/nlp/squad_mini/v2.0/dev-v2.0.json \
            model.language_model.pretrained_model_name=gpt2 \
            model.dataset.version_2_with_negative=true \
            trainer.precision=16 \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            exp_manager=null

  # L2: Intent and Slot Classification Tasks
  L2_Intent_and_Slot_Classification_Tasks_Intent_and_Slot_Classification:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/intent_slot_classification && \
            python intent_slot_classification.py \
            model.data_dir=/home/TestData/nlp/retail \
            model.validation_ds.prefix=dev \
            model.test_ds.prefix=dev \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=true \
            exp_manager.exp_dir=checkpoints
            sh rm -rf checkpoints

  L2_Intent_and_Slot_Classification_Tasks_Multi-Label_Intent_and_Slot_Classification:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/intent_slot_classification && \
            python multi_label_intent_slot_classification.py \
            model.data_dir=/home/TestData/nlp/new_multiatis \
            model.validation_ds.prefix=dev \
            model.test_ds.prefix=dev \
            trainer.devices=[0] \
            +trainer.fast_dev_run=true \
            exp_manager.exp_dir=checkpoints2
            sh rm -rf checkpoints2

    # TODO: add when megatron-bert is supported again
    # stage('L2: Model Parallel Size 2 Megatron Text Classification') {
    #   when {
    #     anyOf{
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   steps{
    #     sh 'cd examples/nlp/text_classification && \
    #     python text_classification_with_bert.py \
    #     trainer.devices=[0,1] \
    #     trainer.accelerator="gpu" \
    #     trainer.num_nodes=1 \
    #     trainer.precision=16 \
    #     trainer.gradient_clip_val=1.0 \
    #     +trainer.fast_dev_run=true \
    #     model.dataset.num_classes=6 \
    #     model.train_ds.file_path=/home/TestData/nlp/retail_text_classification/train.tsv \
    #     model.train_ds.batch_size=4 \
    #     model.language_model.pretrained_model_name=megatron-bert-uncased \
    #     model.language_model.config_file=/home/TestData/nlp/mp_2_bert_toy/config.json \
    #     model.language_model.lm_checkpoint=/home/TestData/nlp/mp_2_bert_toy/iter_2000000 \
    #     model.nemo_path=null \
    #     ~model.infer_samples \
    #     exp_manager=null'
    #   }
    # }

    # stage('L2: Model Parallel Size 2 Megatron Autoresume') {
    #   when {
    #     anyOf{
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   steps{
    #     sh 'cd examples/nlp/text_classification && \
    #     python text_classification_with_bert.py \
    #     trainer.devices=[0,1] \
    #     trainer.accelerator="gpu" \
    #     trainer.num_nodes=1 \
    #     trainer.precision=16 \
    #     trainer.gradient_clip_val=1.0 \
    #     trainer.max_epochs=1 \
    #     +trainer.fast_dev_run=true \
    #     model.dataset.num_classes=6 \
    #     model.train_ds.file_path=/home/TestData/nlp/retail_text_classification/train.tsv \
    #     model.train_ds.batch_size=4 \
    #     model.language_model.pretrained_model_name=megatron-bert-uncased \
    #     model.language_model.config_file=/home/TestData/nlp/mp_2_bert_toy/config.json \
    #     model.language_model.lm_checkpoint=/home/TestData/nlp/mp_2_bert_toy/iter_2000000 \
    #     model.nemo_path=null \
    #     ~model.infer_samples \
    #     +exp_manager.explicit_log_dir=/home/TestData/nlp/mp_autoresume \
    #     +exp_manager.resume_if_exists=true'
    #   }
    # }

    # stage('L2: Model Parallel Size 2 Megatron Evaluation from .nemo') {
    #   when {
    #     anyOf{
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   steps{
    #     sh 'cd examples/nlp/text_classification && \
    #     python model_parallel_text_classification_evaluation.py \
    #     trainer.devices=[0,1] \
    #     trainer.accelerator="gpu" \
    #     trainer.num_nodes=1 \
    #     model.dataset.num_classes=6 \
    #     model.test_ds.file_path=/home/TestData/nlp/retail_text_classification/dev.tsv \
    #     model.nemo_path=/home/TestData/nlp/mp_2_nemo/retail_text_class_350M.nemo \
    #     exp_manager=null'
    #   }
    # }

    # stage('L2: Model Parallel Size 2 Megatron Train from .nemo') {
    #   when {
    #     anyOf{
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   steps{
    #     sh 'cd examples/nlp/token_classification && \
    #     python token_classification_train.py \
    #     pretrained_model=/home/TestData/nlp/mp_2_nemo/ner_350M.nemo \
    #     model.dataset.data_dir=/home/TestData/nlp/ner/ \
    #     model.train_ds.batch_size=2 \
    #     model.dataset.use_cache=false \
    #     trainer.devices=[0,1] \
    #     trainer.accelerator="gpu" \
    #     +trainer.fast_dev_run=true \
    #     model.dataset.class_balancing="weighted_loss" \
    #     exp_manager=null'
    #   }
    # }


  # L2: Parallel NLP Examples 2
  L2_Parallel_NLP_Examples2_NER_finetuning_from_pretrained_Test:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/token_classification && \
            python token_classification_train.py \
            pretrained_model=ner_en_bert \
            model.dataset.data_dir=/home/TestData/nlp/ner/ \
            model.train_ds.batch_size=2 \
            model.dataset.use_cache=false \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=true \
            model.dataset.class_balancing="weighted_loss" \
            exp_manager.exp_dir=null
 
  L2_Parallel_NLP_Examples2_Punctuation_and_capitalization_finetuning_from_pretrained_test:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/token_classification && \
            data_dir="$(mktemp -d -p "$(pwd)")" && \
            cp /home/TestData/nlp/token_classification_punctuation/*.txt "${data_dir}"/ && \
            python punctuation_capitalization_train_evaluate.py \
              pretrained_model=punctuation_en_bert \
              model.train_ds.ds_item="${data_dir}" \
              model.validation_ds.ds_item="${data_dir}" \
              model.test_ds.ds_item="${data_dir}" \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[1] \
              trainer.accelerator="gpu" \
              +trainer.fast_dev_run=true \
              exp_manager.exp_dir=null && \
            rm -rf "${data_dir}"

  L2_Parallel_NLP_Examples2_NER_with_TurkuNLP__bert-base-finnish-cased-v1:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/token_classification && \
            python token_classification_train.py \
            model.dataset.data_dir=/home/TestData/nlp/token_classification_punctuation/ \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=true \
            model.dataset.use_cache=false \
            model.language_model.pretrained_model_name="TurkuNLP/bert-base-finnish-cased-v1" \
            exp_manager.exp_dir=null
        
  L2_Parallel_NLP_Examples2_Evaluation_script_for_Token_Classification:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            sh python examples/nlp/token_classification/token_classification_evaluate.py \
            model.dataset.data_dir=/home/TestData/nlp/ner/ \
            model.dataset.use_cache=false \
            pretrained_model=/home/TestData/nlp/pretrained_models/NER_Model_with_BERT_base_uncased.nemo

  L2_Parallel_NLP_Examples2_Evaluation_script_for_Punctuation:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            sh data_dir="$(mktemp -d -p "$(pwd)")" && \
            cp /home/TestData/nlp/token_classification_punctuation/*.txt "${data_dir}"/ && \
            python examples/nlp/token_classification/punctuation_capitalization_train_evaluate.py \
              +do_training=false \
              +do_testing=true \
              model.test_ds.ds_item="${data_dir}" \
              ~model.train_ds \
              ~model.validation_ds \
              +model.test_ds.use_cache=false \
              pretrained_model=/home/TestData/nlp/pretrained_models/Punctuation_Capitalization_with_DistilBERT_base_uncased.nemo && \
            rm -rf "${data_dir}"

  L2_Parallel_NLP_Examples2_Punctuation_Capitalization_2GPUs_with_DistilBERT_Finetuning_on_other_data:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/token_classification && \
            output_dir="$(mktemp -d -p "$(pwd)")" && \
            tmp_data_dir="$(mktemp -d -p "$(pwd)")" && \
            cp /home/TestData/nlp/token_classification_punctuation/*.txt "${tmp_data_dir}"/ && \
            python punctuation_capitalization_train_evaluate.py \
              model.train_ds.use_tarred_dataset=false \
              model.train_ds.ds_item="${tmp_data_dir}" \
              model.validation_ds.ds_item="${tmp_data_dir}" \
              model.test_ds.ds_item="${tmp_data_dir}" \
              model.language_model.pretrained_model_name=distilbert-base-uncased \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.accelerator="gpu" \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              +exp_manager.explicit_log_dir="${output_dir}" \
              +do_testing=true && \
            tmp_data_dir_2="$(mktemp -d -p "$(pwd)")" && \
            mv "${tmp_data_dir}"/* "${tmp_data_dir_2}" && \
            rm -rf "${tmp_data_dir}" && \
            python punctuation_capitalization_train_evaluate.py \
              model.train_ds.use_tarred_dataset=false \
              model.train_ds.ds_item="${tmp_data_dir_2}" \
              model.validation_ds.ds_item="${tmp_data_dir_2}" \
              model.test_ds.ds_item="${tmp_data_dir_2}" \
              pretrained_model="${output_dir}/checkpoints/Punctuation_and_Capitalization.nemo" \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.accelerator="gpu" \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              exp_manager=null && \
            rm -rf /workspace/NeMo/examples/nlp/token_classification/nemo_experiments \
              "${tmp_data_dir_2}" \
              "${output_dir}"

  # Punctuation & Capitalization tarred dataset:
  Punctuation_Capitalization_tarred_dataset_create_and_use_tarred_dataset:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            sh data_dir="$(mktemp -d -p "$(pwd)")" && \
            cp -r /home/TestData/nlp/token_classification_punctuation/*.txt \
              /home/TestData/nlp/token_classification_punctuation/wmt_wiki_10000 \
              "${data_dir}"/ && \
            usual_data=${data_dir}/wmt_wiki_10000 && \
            output_dir="$(mktemp -d -p "$(pwd)")" && \
            tarred_data=${output_dir}/train_tarred && \
            tokens_in_batch=2000 && \
            max_seq_length=512 && \
            lm_model=distilbert-base-uncased && \
            python examples/nlp/token_classification/data/create_punctuation_capitalization_tarred_dataset.py \
              --text ${usual_data}/input.txt \
              --labels ${usual_data}/labels.txt \
              --output_dir ${tarred_data} \
              --tokens_in_batch ${tokens_in_batch} \
              --max_seq_length 512 \
              --lines_per_dataset_fragment 2000 \
              --num_batches_per_tarfile 5 \
              --tar_file_prefix punctuation_capitalization \
              --tokenizer_name ${lm_model} \
              --use_fast_tokenizer \
              --pad_label O \
              --n_jobs 3 && \
            echo "Number of tarred files in dataset:" && \
            ls ${tarred_data}/*.tar | wc -l && \
            echo "Label id files in dataset:" && \
            ls ${tarred_data}/*.csv && \
            metadata_file=${tarred_data}/metadata.punctuation_capitalization.tokens${tokens_in_batch}.max_seq_length${max_seq_length}.${lm_model}.json && \
            python examples/nlp/token_classification/punctuation_capitalization_train_evaluate.py \
              model.validation_ds.ds_item="${data_dir}" \
              model.test_ds.ds_item="${data_dir}" \
              model.train_ds.ds_item=${tarred_data} \
              model.language_model.pretrained_model_name=${lm_model} \
              model.train_ds.use_tarred_dataset=true \
              model.train_ds.tar_metadata_file=${metadata_file} \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.accelerator="gpu" \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              +exp_manager.explicit_log_dir=${output_dir}/output && \
            rm -rf "${output_dir}" "${data_dir}"

  # Punctuation_Capitalization_Different_ways_of_passing_labels_to_model
  Punctuation_Capitalization_Using_model-common_datasets_parameters-label_vocab_dir:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/token_classification && \
            work_dir="$(mktemp -d -p "$(pwd)")" && \
            label_vocab_dir="${work_dir}/labels" && \
            mkdir -p ${label_vocab_dir} && \
            data_dir="${work_dir}/data" && \
            mkdir -p "${data_dir}" && \
            cp /home/TestData/nlp/token_classification_punctuation/*.txt "${data_dir}" && \
            output_dir="${work_dir}/output" && \
            mkdir -p "${output_dir}" && \
            punct_label_vocab="${label_vocab_dir}/punct_label_vocab.csv" && \
            capit_label_vocab="${label_vocab_dir}/capit_label_vocab.csv" && \
            printf "O\n,\n.\n?\n" > "${punct_label_vocab}" && \
            printf "O\nU\n" > "${capit_label_vocab}" && \
            python punctuation_capitalization_train_evaluate.py \
              model.train_ds.use_tarred_dataset=false \
              model.train_ds.ds_item="${data_dir}" \
              model.validation_ds.ds_item="${data_dir}" \
              model.test_ds.ds_item="${data_dir}" \
              model.language_model.pretrained_model_name=distilbert-base-uncased \
              model.common_dataset_parameters.label_vocab_dir="${label_vocab_dir}" \
              model.class_labels.punct_labels_file="$(basename "${punct_label_vocab}")" \
              model.class_labels.capit_labels_file="$(basename "${capit_label_vocab}")" \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              +exp_manager.explicit_log_dir="${output_dir}" \
              +do_testing=false && \
            python punctuation_capitalization_train_evaluate.py \
              +do_training=false \
              +do_testing=true \
              ~model.train_ds \
              ~model.validation_ds \
              model.test_ds.ds_item="${data_dir}" \
              pretrained_model="${output_dir}/checkpoints/Punctuation_and_Capitalization.nemo" \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              exp_manager=null && \
            rm -rf "${work_dir}"
        
  Punctuation_Capitalization_Using_model-common_datasets_parameters-punct-capit-_label_ids:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/token_classification && \
            work_dir="$(mktemp -d -p "$(pwd)")" && \
            output_dir="${work_dir}/output" && \
            mkdir -p "${output_dir}" && \
            data_dir="${work_dir}/data" && \
            mkdir -p "${data_dir}" && \
            cp /home/TestData/nlp/token_classification_punctuation/*.txt "${data_dir}" && \
            conf_name=punctuation_capitalization_config_with_ids && \
            cp conf/punctuation_capitalization_config.yaml "${work_dir}/${conf_name}.yaml" && \
            sed -i $\s/punct_label_ids: null/punct_label_ids: {O: 0, \\\,\\\: 1, .: 2, \\\?\\\: 3}/\ \
              "${work_dir}/${conf_name}.yaml" && \
            sed -i $\s/capit_label_ids: null/capit_label_ids: {O: 0, U: 1}/\ \
              "${work_dir}/${conf_name}.yaml" && \
            python punctuation_capitalization_train_evaluate.py \
              --config-path "${work_dir}" \
              --config-name "${conf_name}" \
              model.train_ds.use_tarred_dataset=false \
              model.train_ds.ds_item="${data_dir}" \
              model.validation_ds.ds_item="${data_dir}" \
              model.test_ds.ds_item="${data_dir}" \
              model.language_model.pretrained_model_name=distilbert-base-uncased \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              +exp_manager.explicit_log_dir="${output_dir}" \
              +do_testing=false && \
            python punctuation_capitalization_train_evaluate.py \
              +do_training=false \
              +do_testing=true \
              ~model.train_ds \
              ~model.validation_ds \
              model.test_ds.ds_item="${data_dir}" \
              pretrained_model="${output_dir}/checkpoints/Punctuation_and_Capitalization.nemo" \
              +model.train_ds.use_cache=false \
              +model.validation_ds.use_cache=false \
              +model.test_ds.use_cache=false \
              trainer.devices=[0,1] \
              trainer.strategy=ddp \
              trainer.max_epochs=1 \
              exp_manager=null && \
            rm -rf "${work_dir}"

  # Punctuation & Capitalization inference      
  Punctuation_Capitalization_inference_Restore_punctuation_and_capitalization_in_long_text:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            sh output_dir="$(mktemp -d -p "$(pwd)")" && \
            python examples/nlp/token_classification/punctuate_capitalize_infer.py \
              --input_manifest /home/TestData/nlp/token_classification_punctuation/iwslt_tst2019.manifest \
              --output_text "${output_dir}/iwslt_inference_result.txt" \
              --max_seq_length 92 \
              --step 8 \
              --margin 16 \
              --pretrained_name punctuation_en_bert \
              --batch_size 32 && \
            rm -rf "${output_dir}"
  
  # L2: Parallel Pretraining BERT pretraining from Text/Preprocessed
  L2_Pretraining_BERT_pretraining_from_Text:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/language_modeling && \
            python bert_pretraining.py \
            --config-name=bert_pretraining_from_text_config.yaml \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            trainer.precision=16 \
            +trainer.fast_dev_run=true \
            model.train_ds.data_file=/home/TestData/nlp/wikitext-2/train.txt  \
            model.train_ds.batch_size=32 \
            model.validation_ds.data_file=/home/TestData/nlp/wikitext-2/valid.txt  \
            model.validation_ds.batch_size=32 \
            model.language_model.config_file=/home/TestData/nlp/bert_configs/bert_3200.json \
            model.optim.lr=0.01 \
            model.optim.sched.warmup_ratio=0.1 \
            model.tokenizer.tokenizer_name=sentencepiece \
            model.tokenizer.tokenizer_model=/home/TestData/nlp/wikitext-2/tokenizer_bpe_v3193/tokenizer.model \
            model.mask_prob=0.15 \
            model.short_seq_prob=0.1 \
            exp_manager.exp_dir=PretrainingBERTFromText \
              
            rm -f /home/TestData/nlp/wikitext-2/*.pkl
            rm -rf examples/nlp/language_modeling/PretrainingBERTFromText
            ls -lha examples/nlp/language_modeling
        
  TL2_Pretraining_BERT_from_Preprocessed:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/language_modeling && \
            python bert_pretraining.py \
            --config-name=bert_pretraining_from_preprocessed_config.yaml \
            trainer.devices=[1] \
            trainer.accelerator="gpu" \
            trainer.precision=16 \
            +trainer.fast_dev_run=false \
            +trainer.max_epochs=1 \
            +trainer.limit_val_batches=0 \
            +trainer.limit_train_batches=1 \
            model.train_ds.data_file=/home/TestData/nlp/wiki_book_mini/training \
            model.train_ds.batch_size=8 \
            model.language_model.lm_checkpoint=/home/TestData/nlp/bert_ckpts/nemo1.0/bert_base_uncased_mlm_final_1074591_nemo1.0.pt \
            model.language_model.config_file=/home/TestData/nlp/bert_configs/uncased_L-12_H-768_A-12.json \
            model.optim.lr=0.875e-4 \
            model.optim.weight_decay=0.01 \
            model.optim.sched.warmup_ratio=0.01 \
            exp_manager.exp_dir=PretrainingBERTFromPreprocessed \
            exp_manager.create_checkpoint_callback=False \
              
            rm -rf examples/nlp/language_modeling/PretrainingBERTFromPreprocessed
            ls -lha examples/nlp/language_modeling

  # L2: Entity Linking        
  L2_Entity_Linking_Self_Alignment_Pretraining_BERT:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/entity_linking && \
            python self_alignment_pretraining.py \
            project_dir=. \
            trainer.val_check_interval=3 \
            model.raw_data=None \
            model.train_ds.data_file=/home/TestData/nlp/entity_linking/tiny_example_train_pairs.tsv \
            model.validation_ds.data_file=/home/TestData/nlp/entity_linking/tiny_example_validation_pairs.tsv \
            model.train_ds.batch_size=8 \
            model.validation_ds.batch_size=8 \
            exp_manager.exp_dir=null


  # TODO: remove +model.optim.capturable=True when Pytorch fix: https://github.com/pytorch/pytorch/pull/81858
  # is in the release container
  # L2: NMT Attention is All You Need Training
  L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Post-LN:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            sh python examples/nlp/machine_translation/enc_dec_nmt.py \
            --config-path=conf \
            --config-name=aayn_base \
            do_testing=false \
            model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
            model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
            model.encoder.num_layers=1 \
            model.encoder.hidden_size=64 \
            model.encoder.inner_size=256 \
            model.decoder.num_layers=1 \
            model.decoder.hidden_size=64 \
            model.decoder.inner_size=256 \
            +model.optim.capturable=True \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.val_check_interval=2 \
            +trainer.limit_val_batches=1 \
            +trainer.max_steps=2 \
            trainer.precision=16 \
            +exp_manager.explicit_log_dir=examples/nlp/machine_translation/nmt_results \
            +exp_manager.create_checkpoint_callback=true \
              
            sh python examples/nlp/machine_translation/enc_dec_nmt.py \
            --config-path=conf \
            --config-name=aayn_base \
            do_testing=true \
            model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
            model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
            model.encoder.num_layers=1 \
            model.encoder.hidden_size=64 \
            model.encoder.inner_size=256 \
            model.decoder.num_layers=1 \
            model.decoder.hidden_size=64 \
            model.decoder.inner_size=256 \
            +model.optim.capturable=True \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.val_check_interval=10 \
            +trainer.limit_val_batches=1 \
            +trainer.limit_test_batches=1 \
            +trainer.max_steps=10 \
            +exp_manager.explicit_log_dir=examples/nlp/machine_translation/nmt_results \
            +exp_manager.create_checkpoint_callback=true \
            +exp_manager.resume_if_exists=True \
              
            rm -rf examples/nlp/machine_translation/nmt_results
        
  L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Pre-LN:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
              cd examples/nlp/machine_translation && \
              python enc_dec_nmt.py \
              --config-path=conf \
              --config-name=aayn_base \
              do_testing=true \
              model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
              model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
              model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
              model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
              model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
              model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
              model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
              model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
              model.encoder.pre_ln=true \
              model.decoder.pre_ln=true \
              trainer.devices=[1] \
              trainer.accelerator="gpu" \
              +trainer.fast_dev_run=true \
              +trainer.limit_test_batches=2 \
              exp_manager=null \
        
  L2_NMT_Attention_is_All_You_Need_Training_NMT_Multi-Validation:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
              cd examples/nlp/machine_translation && \
              python enc_dec_nmt.py \
              --config-path=conf \
              --config-name=aayn_base \
              do_testing=true \
              model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-en-de.src \
              model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-en-de.ref \
              model.validation_ds.src_file_name=[/home/TestData/nlp/nmt/toy_data/wmt13-en-de.src,/home/TestData/nlp/nmt/toy_data/wmt14-en-de.src] \
              model.validation_ds.tgt_file_name=[/home/TestData/nlp/nmt/toy_data/wmt13-en-de.ref,/home/TestData/nlp/nmt/toy_data/wmt14-en-de.ref] \
              model.test_ds.src_file_name=[/home/TestData/nlp/nmt/toy_data/wmt13-en-de.src,/home/TestData/nlp/nmt/toy_data/wmt14-en-de.src] \
              model.test_ds.tgt_file_name=[/home/TestData/nlp/nmt/toy_data/wmt13-en-de.ref,/home/TestData/nlp/nmt/toy_data/wmt14-en-de.ref] \
              model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
              model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
              trainer.devices=[0] \
              trainer.accelerator="gpu" \
              +trainer.fast_dev_run=true \
              +trainer.limit_test_batches=2 \
              exp_manager=null \

  # L2: NMT Attention is All You Need Inference
  L2_NMT_Attention_is_All_You_Need_Inference_NMT_Inference_-_PostLN:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/machine_translation && \
            python nmt_transformer_infer.py \
            --model=/home/TestData/nlp/nmt/toy_data/TransformerLargeDe-En.nemo \
            --srctext=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.test.src \
            --tgtout=/home/TestData/nlp/nmt/toy_data/out.txt \
            --target_lang en \
            --source_lang de \

  L2_NMT_Attention_is_All_You_Need_Inference_NMT_Inference_-_Pre-LN:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/machine_translation && \
            python nmt_transformer_infer.py \
            --model=/home/TestData/nlp/nmt/toy_data/en_de_24x6_preln.nemo \
            --srctext=/home/TestData/nlp/nmt/toy_data/wmt14-en-de.test.src \
            --tgtout=/home/TestData/nlp/nmt/toy_data/out.txt \
            --target_lang de \
            --source_lang en \

  # L2: NMT Attention is All You Need Finetuning
  L2_NMT_Attention_is_All_You_Need_Finetuning:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/machine_translation && \
            python enc_dec_nmt_finetune.py \
            model_path=/home/TestData/nlp/nmt/toy_data/en_de_24x6_preln.nemo \
            trainer.devices=[0] \
            ~trainer.max_epochs \
            model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            +trainer.val_check_interval=10 \
            +trainer.limit_val_batches=1 \
            +trainer.limit_test_batches=1 \
            +trainer.max_steps=10 \
            +exp_manager.exp_dir=examples/nlp/machine_translation/nmt_finetune \
            +exp_manager.create_checkpoint_callback=True \
            +exp_manager.checkpoint_callback_params.monitor=val_sacreBLEU \
            +exp_manager.checkpoint_callback_params.mode=max \
            +exp_manager.checkpoint_callback_params.save_best_model=true \
        
            rm -rf examples/nlp/machine_translation/nmt_finetune
  
  # L2: NMT Tarred Dataset Creation
  L2_NMT_Tarred_Dataset_Creation_Auto_Tarred_Dataset_Creation:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/machine_translation && \
            python enc_dec_nmt.py \
            --config-path=conf \
            --config-name=aayn_base \
            do_training=false \
            model.preproc_out_dir=$PWD/preproc_out_dir \
            model.train_ds.use_tarred_dataset=true \
            model.train_ds.n_preproc_jobs=2 \
            model.train_ds.lines_per_dataset_fragment=500 \
            model.train_ds.num_batches_per_tarfile=10 \
            model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.encoder_tokenizer.vocab_size=2000 \
            model.decoder_tokenizer.vocab_size=2000 \
            ~model.test_ds \
            trainer.devices=[0] \
            trainer.accelerator="gpu" \
            +trainer.fast_dev_run=true \
            exp_manager=null \

  L2_NMT_Tarred_Dataset_Creation_Script_Tarred_Dataset_Creation:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            cd examples/nlp/machine_translation && \
            python create_tarred_parallel_dataset.py \
            --src_fname /home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            --tgt_fname /home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            --out_dir $PWD/out_dir \
            --encoder_tokenizer_vocab_size=2000 \
            --decoder_tokenizer_vocab_size=2000 \
            --tokens_in_batch=1000 \
            --lines_per_dataset_fragment=500 \
            --num_batches_per_tarfile=10 \
            --n_preproc_jobs=2 \
        
  L2_Megatron_NMT_Training_TP2:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/nlp/machine_translation/megatron_nmt_training.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            +trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/machine_translation/megatron_nmt_results \
            model.tensor_model_parallel_size=2 \
            model.seq_length=128 \
            model.encoder.num_layers=4 \
            model.encoder.hidden_size=64 \
            model.encoder.num_attention_heads=8 \
            model.encoder.activation=swiglu \
            model.encoder.masked_softmax_fusion=False \
            model.encoder.bias_activation_fusion=False \
            model.encoder.activations_checkpoint_method=block \
            model.encoder.activations_checkpoint_num_layers=1 \
            model.decoder.num_layers=2 \
            model.decoder.hidden_size=64 \
            model.decoder.num_attention_heads=8 \
            model.decoder.activation=swiglu \
            model.decoder.masked_softmax_fusion=False \
            model.decoder.bias_activation_fusion=False \
            model.decoder.activations_checkpoint_method=block \
            model.decoder.activations_checkpoint_num_layers=1 \
            model.micro_batch_size=2 \
            model.global_batch_size=4 \
            model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.train_ds.num_workers=1 \
            model.validation_ds.num_workers=1 \
            ~model.test_ds \
            model.train_ds.dataset_type=text_memmap \
            model.encoder_tokenizer.library=sentencepiece \
            model.encoder_tokenizer.model=/home/TestData/nlp/nmt/toy_data/spm_64k_all_langs_plus_en.model \
            model.decoder_tokenizer.library=sentencepiece \
            model.decoder_tokenizer.model=/home/TestData/nlp/nmt/toy_data/spm_64k_all_langs_plus_en.model"
            # Change val_check_interval to 1 for resume as the len(dataloder) is 1 due to max_steps being the same as that of training and Lightning 2.0 raises an error
            # if val_check_interval > len(dataloder: https://github.com/Lightning-AI/lightning/blob/2.0.6/src/lightning/pytorch/loops/fit_loop.py#L259 at the beginning of fit_loop.run()
            python examples/nlp/machine_translation/megatron_nmt_training.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=1 \
            +trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/machine_translation/megatron_nmt_results \
            model.tensor_model_parallel_size=2 \
            model.seq_length=128 \
            model.encoder.num_layers=4 \
            model.encoder.hidden_size=64 \
            model.encoder.num_attention_heads=8 \
            model.encoder.activation=swiglu \
            model.encoder.masked_softmax_fusion=False \
            model.encoder.bias_activation_fusion=False \
            model.encoder.activations_checkpoint_method=block \
            model.encoder.activations_checkpoint_num_layers=1 \
            model.decoder.num_layers=2 \
            model.decoder.hidden_size=64 \
            model.decoder.num_attention_heads=8 \
            model.decoder.activation=swiglu \
            model.decoder.masked_softmax_fusion=False \
            model.decoder.bias_activation_fusion=False \
            model.decoder.activations_checkpoint_method=block \
            model.decoder.activations_checkpoint_num_layers=1 \
            model.micro_batch_size=2 \
            model.global_batch_size=4 \
            model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
            model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
            model.train_ds.num_workers=1 \
            model.validation_ds.num_workers=1 \
            ~model.test_ds \
            model.train_ds.dataset_type=text_memmap \
            model.encoder_tokenizer.library=sentencepiece \
            model.encoder_tokenizer.model=/home/TestData/nlp/nmt/toy_data/spm_64k_all_langs_plus_en.model \
            model.decoder_tokenizer.library=sentencepiece \
            model.decoder_tokenizer.model=/home/TestData/nlp/nmt/toy_data/spm_64k_all_langs_plus_en.model"
            rm -rf examples/nlp/machine_translation/megatron_nmt_results
        
  L2_Megatron_BART_Perceiver_MIM_Training_TP2:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/nlp/language_modeling/megatron_bart_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/megatron_mim_results \
            model.tensor_model_parallel_size=2 \
            model.seq_length=128 \
            model.encoder.num_layers=4 \
            model.encoder.hidden_size=64 \
            model.encoder.arch=perceiver \
            model.encoder.num_attention_heads=8 \
            model.encoder.activation=swiglu \
            model.encoder.masked_softmax_fusion=False \
            model.encoder.bias_activation_fusion=False \
            model.encoder.activations_checkpoint_method=block \
            model.encoder.activations_checkpoint_num_layers=1 \
            model.decoder.num_layers=2 \
            model.decoder.hidden_size=64 \
            model.decoder.num_attention_heads=8 \
            model.decoder.activation=swiglu \
            model.decoder.masked_softmax_fusion=False \
            model.decoder.bias_activation_fusion=False \
            model.decoder.activations_checkpoint_method=block \
            model.decoder.activations_checkpoint_num_layers=1 \
            model.micro_batch_size=2 \
            model.global_batch_size=4 \
            model.data.data_impl=text_mmap \
            model.data.data_prefix=[1.0,/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src] \
            model.data.splits_string=\\"800,100,100\"\ \
            model.data.whole_word_masking=False \
            model.tokenizer.library=sentencepiece \
            model.tokenizer.model=/home/TestData/nlp/nmt/toy_data/spm_64k_all_langs_plus_en.model \
            ++model.hiddens.enc_output_name=z \
            ++model.hiddens.transform.q_z_given_x.cls_name=cond_gaussian \
            ++model.hiddens.transform.q_z_given_x.hidden_size=64 \
            ++model.hiddens.loss.mim.cls_name=a_mim \
            ++model.hiddens.loss.mim.loss_weight=0.5"
            # Change val_check_interval to 1 for resume as the len(dataloder) is 1 due to max_steps being the same as that of training and Lightning 2.0 raises an error
            # if val_check_interval > len(dataloder: https://github.com/Lightning-AI/lightning/blob/2.0.6/src/lightning/pytorch/loops/fit_loop.py#L259 at the beginning of fit_loop.run()
            python examples/nlp/language_modeling/megatron_bart_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=1 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/megatron_mim_results \
            model.tensor_model_parallel_size=2 \
            model.seq_length=128 \
            model.encoder.num_layers=4 \
            model.encoder.hidden_size=64 \
            model.encoder.arch=perceiver \
            model.encoder.num_attention_heads=8 \
            model.encoder.activation=swiglu \
            model.encoder.masked_softmax_fusion=False \
            model.encoder.bias_activation_fusion=False \
            model.encoder.activations_checkpoint_method=block \
            model.encoder.activations_checkpoint_num_layers=1 \
            model.decoder.num_layers=2 \
            model.decoder.hidden_size=64 \
            model.decoder.num_attention_heads=8 \
            model.decoder.activation=swiglu \
            model.decoder.masked_softmax_fusion=False \
            model.decoder.bias_activation_fusion=False \
            model.decoder.activations_checkpoint_method=block \
            model.decoder.activations_checkpoint_num_layers=1 \
            model.micro_batch_size=2 \
            model.global_batch_size=4 \
            model.data.data_impl=text_mmap \
            model.data.data_prefix=[1.0,/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src] \
            model.data.splits_string=\\"800,100,100\"\ \
            model.data.whole_word_masking=False \
            model.tokenizer.library=sentencepiece \
            model.tokenizer.model=/home/TestData/nlp/nmt/toy_data/spm_64k_all_langs_plus_en.model \
            ++model.hiddens.enc_output_name=z \
            ++model.hiddens.transform.q_z_given_x.cls_name=cond_gaussian \
            ++model.hiddens.transform.q_z_given_x.hidden_size=64 \
            ++model.hiddens.loss.mim.cls_name=a_mim \
            ++model.hiddens.loss.mim.loss_weight=0.5"
            rm -rf examples/nlp/language_modeling/megatron_mim_results

    # stage('L2: NMT Bottleneck Fallback') {
    #   when {
    #     anyOf {
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   parallel {
    #     stage('L2: seq2seq (no bottleneck)') {
    #         steps {
    #           sh 'cd examples/nlp/machine_translation && \
    #           enc_dec_nmt-bottleneck.py \
    #           --config-path=conf \
    #           --config-name=aayn_bottleneck \
    #           do_testing=true \
    #           model.model_type=nll \
    #           model.encoder.arch=seq2seq \
    #           model.encoder.hidden_steps=1 \
    #           model.encoder.hidden_blocks=1 \
    #           model.encoder.hidden_init_method=params \
    #           model.encoder.hidden_size=64 \
    #           model.encoder.inner_size=128 \
    #           model.encoder.num_attention_heads=2 \
    #           model.encoder.num_layers=2 \
    #           model.decoder.hidden_size=64 \
    #           model.decoder.inner_size=128 \
    #           model.decoder.num_attention_heads=2 \
    #           model.decoder.num_layers=2 \
    #           model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-en-de.src \
    #           model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-en-de.ref \
    #           model.validation_ds.src_file_name=[/home/TestData/nlp/nmt/toy_data/wmt13-en-de.src,/home/TestData/nlp/nmt/toy_data/wmt14-en-de.src] \
    #           model.validation_ds.tgt_file_name=[/home/TestData/nlp/nmt/toy_data/wmt13-en-de.ref,/home/TestData/nlp/nmt/toy_data/wmt14-en-de.ref] \
    #           model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt13-en-de.src \
    #           model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt13-en-de.ref \
    #           model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           trainer.devices=[1] \
    #           trainer.accelerator="gpu" \
    #           +trainer.fast_dev_run=true \
    #           +trainer.limit_test_batches=2 \
    #           exp_manager=null \
    #           '
    #         }
    #     }
    #   }
    # }
    # stage('L2: NMT Bottleneck Architecture') {
    #   when {
    #     anyOf {
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   parallel {
    #     stage('Bridge Encoder (identity)') {
    #         steps {
    #           sh 'cd examples/nlp/machine_translation && \
    #           enc_dec_nmt-bottleneck.py \
    #           --config-path=conf \
    #           --config-name=aayn_bottleneck \
    #           do_testing=true \
    #           model.model_type=nll \
    #           model.encoder.arch=bridge \
    #           model.encoder.hidden_steps=1 \
    #           model.encoder.hidden_blocks=1 \
    #           model.encoder.hidden_init_method=identity \
    #           model.encoder.hidden_size=64 \
    #           model.encoder.inner_size=128 \
    #           model.encoder.num_attention_heads=2 \
    #           model.encoder.num_layers=2 \
    #           model.decoder.hidden_size=64 \
    #           model.decoder.inner_size=128 \
    #           model.decoder.num_attention_heads=2 \
    #           model.decoder.num_layers=2 \
    #           model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
    #           model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #		 trainer.devices=[0] \
    # 		 trainer.accelerator="gpu" \
    #           +trainer.fast_dev_run=true \
    #           +trainer.limit_test_batches=2 \
    #           exp_manager=null \
    #           '
    #         }
    #     }
    #     stage('Perceiver Encoder (params)') {
    #         steps {
    #           sh 'cd examples/nlp/machine_translation && \
    #           enc_dec_nmt-bottleneck.py \
    #           --config-path=conf \
    #           --config-name=aayn_bottleneck \
    #           do_testing=true \
    #           model.model_type=nll \
    #           model.encoder.arch=perceiver \
    #           model.encoder.hidden_steps=1 \
    #           model.encoder.hidden_blocks=1 \
    #           model.encoder.hidden_init_method=params \
    #           model.encoder.hidden_size=64 \
    #           model.encoder.inner_size=128 \
    #           model.encoder.num_attention_heads=2 \
    #           model.encoder.num_layers=2 \
    #           model.decoder.hidden_size=64 \
    #           model.decoder.inner_size=128 \
    #           model.decoder.num_attention_heads=2 \
    #           model.decoder.num_layers=2 \
    #           model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
    #           model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           trainer.devices=[1] \
    #           trainer.accelerator="gpu" \
    #           +trainer.fast_dev_run=true \
    #           +trainer.limit_test_batches=2 \
    #           exp_manager=null \
    #           '
    #         }
    #     }
    #   }
    # }
    # stage('L2: NMT Bottleneck LVM') {
    #   when {
    #     anyOf {
    #       branch 'main'
    #       changeRequest target: 'main'
    #     }
    #   }
    #   failFast true
    #   parallel {
    #     stage('VAE') {
    #         steps {
    #           sh 'cd examples/nlp/machine_translation && \
    #           enc_dec_nmt-bottleneck.py \
    #           --config-path=conf \
    #           --config-name=aayn_bottleneck \
    #           do_testing=true \
    #           model.model_type=vae \
    #           model.encoder.arch=perceiver \
    #           model.encoder.hidden_steps=1 \
    #           model.encoder.hidden_blocks=1 \
    #           model.encoder.hidden_init_method=params \
    #           model.encoder.hidden_size=64 \
    #           model.encoder.inner_size=128 \
    #           model.encoder.num_attention_heads=2 \
    #           model.encoder.num_layers=2 \
    #           model.decoder.hidden_size=64 \
    #           model.decoder.inner_size=128 \
    #           model.decoder.num_attention_heads=2 \
    #           model.decoder.num_layers=2 \
    #           model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
    #           model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           trainer.devices=[0] \
    #           trainer.accelerator="gpu" \
    #           +trainer.fast_dev_run=true \
    #           +trainer.limit_test_batches=2 \
    #           exp_manager=null \
    #           '
    #         }
    #     }
    #     stage('MIM') {
    #         steps {
    #           sh 'cd examples/nlp/machine_translation && \
    #           enc_dec_nmt-bottleneck.py \
    #           --config-path=conf \
    #           --config-name=aayn_bottleneck \
    #           do_testing=true \
    #           model.model_type=mim \
    #           model.encoder.arch=perceiver \
    #           model.encoder.hidden_steps=1 \
    #           model.encoder.hidden_blocks=1 \
    #           model.encoder.hidden_init_method=params \
    #           model.encoder.hidden_size=64 \
    #           model.encoder.inner_size=128 \
    #           model.encoder.num_attention_heads=2 \
    #           model.encoder.num_layers=2 \
    #           model.decoder.hidden_size=64 \
    #           model.decoder.inner_size=128 \
    #           model.decoder.num_attention_heads=2 \
    #           model.decoder.num_layers=2 \
    #           model.train_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.train_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.ref \
    #           model.validation_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.validation_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.src_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.test_ds.tgt_file_name=/home/TestData/nlp/nmt/toy_data/wmt14-de-en.src \
    #           model.encoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           model.decoder_tokenizer.tokenizer_model=/home/TestData/nlp/nmt/toy_data/tt_tokenizer.BPE.4096.model \
    #           trainer.devices=[1] \
    #           trainer.accelerator="gpu" \
    #           +trainer.fast_dev_run=true \
    #           +trainer.limit_test_batches=2 \
    #           exp_manager=null \
    #           '
    #         }
    #     }
    #   }
    # }
        
  L2_Megatron_Bert_Pretraining_and_Resume_Training_with_Pipeline_Parallelism:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/nlp/language_modeling/megatron_bert_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/bert_pretrain_results \
            model.pipeline_model_parallel_size=2 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.data.seq_length=128 \
            model.tokenizer.vocab_file=/home/TestData/nlp/megatron_bert/data/bert/vocab.txt \
            model.num_layers=8 \
            model.hidden_size=256 \
            model.num_attention_heads=8 \
            model.activations_checkpoint_method=block \
            model.activations_checkpoint_num_layers=1 \
            model.data.data_prefix=[.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence,.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence] \
            model.data.index_mapping_dir=examples/nlp/language_modeling/bert_index_mappings

            python examples/nlp/language_modeling/megatron_bert_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=20 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/bert_pretrain_results \
            exp_manager.resume_if_exists=True \
            model.pipeline_model_parallel_size=2 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.data.seq_length=128 \
            model.tokenizer.vocab_file=/home/TestData/nlp/megatron_bert/data/bert/vocab.txt \
            model.num_layers=8 \
            model.hidden_size=256 \
            model.num_attention_heads=8 \
            model.activations_checkpoint_method=block \
            model.activations_checkpoint_num_layers=1 \
            model.data.data_prefix=[.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence,.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence] \
            model.data.index_mapping_dir=examples/nlp/language_modeling/bert_index_mappings

            rm -rf examples/nlp/language_modeling/bert_pretrain_results
            rm -rf examples/nlp/language_modeling/bert_index_mappings
        
  L2_Megatron_Bert_Pretraining_and_Resume_Training:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/nlp/language_modeling/megatron_bert_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/bert_pretrain_results \
            model.tensor_model_parallel_size=2 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.sequence_parallel=True \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.data.seq_length=128 \
            model.tokenizer.vocab_file=/home/TestData/nlp/megatron_bert/data/bert/vocab.txt \
            model.num_layers=8 \
            model.hidden_size=256 \
            model.num_attention_heads=8 \
            model.activations_checkpoint_method=block \
            model.activations_checkpoint_num_layers=1 \
            model.data.data_prefix=[.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence,.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence] \
            model.data.index_mapping_dir=examples/nlp/language_modeling/bert_index_mappings

            python examples/nlp/language_modeling/megatron_bert_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=20 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/bert_pretrain_results \
            exp_manager.resume_if_exists=True \
            model.tensor_model_parallel_size=2 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.data.seq_length=128 \
            model.tokenizer.vocab_file=/home/TestData/nlp/megatron_bert/data/bert/vocab.txt \
            model.num_layers=8 \
            model.hidden_size=256 \
            model.num_attention_heads=8 \
            model.activations_checkpoint_method=block \
            model.activations_checkpoint_num_layers=1 \
            model.data.data_prefix=[.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence,.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence] \
            model.data.index_mapping_dir=examples/nlp/language_modeling/bert_index_mappings

            rm -rf examples/nlp/language_modeling/bert_pretrain_results
            rm -rf examples/nlp/language_modeling/bert_index_mappings

  L2_Megatron_Core_Bert_Pretraining_and_Resume_Training:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/nlp/language_modeling/megatron_bert_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=10 \
            trainer.precision=32 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/bert_pretrain_results \
            model.mcore_bert=True \
            model.tensor_model_parallel_size=2 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.sequence_parallel=True \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.data.seq_length=128 \
            model.tokenizer.vocab_file=/home/TestData/nlp/megatron_bert/data/bert/vocab.txt \
            model.num_layers=8 \
            model.hidden_size=256 \
            model.num_attention_heads=8 \
            model.activations_checkpoint_method=block \
            model.activations_checkpoint_num_layers=1 \
            model.data.data_prefix=[.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence,.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence] \
            model.data.index_mapping_dir=examples/nlp/language_modeling/bert_index_mappings

            python examples/nlp/language_modeling/megatron_bert_pretraining.py \
            trainer.devices=2 \
            trainer.accelerator=gpu \
            trainer.log_every_n_steps=1 \
            trainer.val_check_interval=10 \
            trainer.limit_val_batches=2 \
            trainer.accumulate_grad_batches=1 \
            trainer.max_steps=20 \
            trainer.precision=32 \
            trainer.gradient_clip_val=1.0 \
            exp_manager.exp_dir=examples/nlp/language_modeling/bert_pretrain_results \
            exp_manager.resume_if_exists=True \
            model.mcore_bert=True \
            model.tensor_model_parallel_size=2 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.data.seq_length=128 \
            model.tokenizer.vocab_file=/home/TestData/nlp/megatron_bert/data/bert/vocab.txt \
            model.num_layers=8 \
            model.hidden_size=256 \
            model.num_attention_heads=8 \
            model.activations_checkpoint_method=block \
            model.activations_checkpoint_num_layers=1 \
            model.data.data_prefix=[.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence,.5,/home/TestData/nlp/megatron_bert/data/bert/simple_wiki_bert_preproc_text_sentence] \
            model.data.index_mapping_dir=examples/nlp/language_modeling/bert_index_mappings

            rm -rf examples/nlp/language_modeling/bert_pretrain_results
            rm -rf examples/nlp/language_modeling/bert_index_mappings

  L2_Megatron_RETRO_Pretraining_and_Resume_Training:
    needs: [cicd-test-container-setup]
    runs-on: self-hosted-azure
    container:
      image: localhost:5000/nemo_container
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        --gpus all
        --shm-size=8g 
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /home/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v3
        - run: |
            python examples/nlp/language_modeling/megatron_retro_pretraining.py \
            trainer.devices=2 \
            trainer.num_nodes=1 \
            trainer.accelerator=gpu \
            trainer.accumulate_grad_batches=1 \
            trainer.limit_val_batches=2 \
            exp_manager.resume_if_exists=True \
            trainer.max_steps=10 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            trainer.val_check_interval=10 \
            exp_manager.exp_dir=examples/nlp/language_modeling/retro_results \
            model.data.data_prefix= \
            model.data.knn_index= \
            model.data.retrieval_prefix= \
            model.tensor_model_parallel_size=2 \
            model.micro_batch_size=4 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.chunk_size=32 \
            model.enc_num_layers=2 \
            model.dec_num_layers=2 \
            model.enc_cross_attention=[1] \
            model.dec_cross_attention=[1] \
            +model.data.mock=True

            python examples/nlp/language_modeling/megatron_retro_pretraining.py \
            trainer.devices=2 \
            trainer.num_nodes=1 \
            trainer.accelerator=gpu \
            trainer.accumulate_grad_batches=1 \
            trainer.limit_val_batches=2 \
            exp_manager.resume_if_exists=True \
            trainer.max_steps=20 \
            trainer.precision=16 \
            trainer.gradient_clip_val=1.0 \
            trainer.val_check_interval=10 \
            exp_manager.exp_dir=examples/nlp/language_modeling/retro_results \
            model.data.data_prefix= \
            model.data.knn_index= \
            model.data.retrieval_prefix= \
            model.tensor_model_parallel_size=2 \
            model.micro_batch_size=4 \
            model.optim.name=fused_adam \
            model.optim.lr=2e-4 \
            model.optim.sched.warmup_steps=2 \
            model.optim.sched.constant_steps=2 \
            model.optim.sched.min_lr=8e-5 \
            model.max_position_embeddings=128 \
            model.encoder_seq_length=128 \
            model.chunk_size=32 \
            model.enc_num_layers=2 \
            model.dec_num_layers=2 \
            model.enc_cross_attention=[1] \
            model.dec_cross_attention=[1] \
            +model.data.mock=True

            rm -rf examples/nlp/language_modeling/retro_results
