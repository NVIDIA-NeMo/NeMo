# Copyright (c) 2020-2021, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
name: "CICD NeMo"

on:
  pull_request:
    branches:
      - 'main'
      - 'r**'
    types: [ labeled ]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  gpu-test:
    runs-on: test-runner
    if: ${{ github.event.label.name == 'Run CICD' }}
    steps:
    - name: Run nvidia-smi test
      run: |
        whoami
        nvidia-smi

  cicd-cluster-clean:
    runs-on: self-hosted-azure-builder
    if: ${{ github.event.label.name == 'Run CICD' }}
    steps:
    - name: Clean server from old files
      run: |
        docker container prune --filter "until=24h" --force
        docker image prune -a --filter "until=24h" --force

#  checkout-repository:
#    runs-on: test-runner
#    container:
#      image: nvcr.io/nvidia/pytorch:24.02-py3
#      volumes:
#        - ${{ github.workspace }}:/workspace
#    steps:
#    - name: Checkout repository
#      uses: actions/checkout@v4
#      with:
#        path: ${{ github.run_id }}


  cicd-test-container-setup:
    needs: [cicd-cluster-clean]
    runs-on: self-hosted-azure-builder
    if: ${{ github.event.label.name == 'Run CICD' }}
    # uses: actions/cache@v2
    #container:
#      image: nvcr.io/nvidia/pytorch:24.02-py3
#      options: 
#        # --user 0:128
#        --device=/dev/nvidia0
#        --gpus all
#        --shm-size=8g 
#        --env TRANSFORMERS_OFFLINE=0
#        --env HYDRA_FULL_ERROR=1
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        path: ${{ github.run_id }}
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with: 
        # We use `docker` driver as this speeds things up for 
        # trivial (non-multi-stage) builds.
        driver: docker

    - name: Build and push
      uses: docker/build-push-action@v5
      with:
        file: Dockerfile.ci
        push: true
        cache-from: nemoci.azurecr.io/nemo_container:latest
        cache-to: type=inline
        tags: |
          nemoci.azurecr.io/nemo_container_${{ github.run_id }}
          nemoci.azurecr.io/nemo_container:latest

    - name: Run some checks
      run: |
        docker run --rm --device=/dev/nvidia0 --gpus all --shm-size=8g --env TRANSFORMERS_OFFLINE=0 --env HYDRA_FULL_ERROR=1 --env PYTHONUNBUFFERED=1 nemoci.azurecr.io/nemo_container_${{ github.run_id }} bash -c '\
          # PyTorch Lightning version
          python -c "import pytorch_lightning; print(pytorch_lightning.__version__)"

          # PyTorch Lightning DDP Checks
          CUDA_VISIBLE_DEVICES="0,1" python "tests/core_ptl/check_for_ranks.py"

          # Basic Import Checks
          python -c "import nemo.collections.asr as nemo_asr"
          python -c "import nemo.collections.nlp as nemo_nlp"
          python -c "import nemo.collections.tts as nemo_tts"

          python setup.py style
          python tests/check_copyright_header.py --dir .

          # These checks are not crucial
          exit 0
        '

    # - name: Build and push to local registry
    #   uses: docker/build-push-action@v5
    #   with:
    #       context: .
    #       push: true
    #       tags: nemoci.azurecr.io/name/app:latest

    # - name: Inspect
    #   run: |
    #     docker buildx imagetools inspect nemoci.azurecr.io/name/app:latest

    #- name: Post-workflow execution
    #  uses: gacts/run-and-post-run@v1
    #  with:
    #    post: |
    #      chmod -R 777 .


  L0_Unit_Tests_GPU:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options:
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    - name: "L0: Unit Tests GPU"
      run: |
        NEMO_NUMBA_MINVER=0.53 pytest -m "not pleasefixme" --with_downloads
    - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
      if: "failure()"
      
  L0_Setup_Test_Data_And_Models:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    timeout-minutes: 10
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options:
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v4
        - run: |
            python -m tests.setup --save_dir /home/TestData/nlp
        - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
          if: "failure()"

##     - name: L2: Multimodal Imagen Train

  # L2: Community LLM Checkpoints tests
  L2_Community_LLM_Checkpoints_tests_Llama:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    timeout-minutes: 10
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v4
        - run: |
            CUDA_VISIBLE_DEVICES=0 python scripts/checkpoint_converters/convert_llama_hf_to_nemo.py \
            --input_name_or_path=/home/TestData/nlp/megatron_llama/llama-ci-hf-tiny \
            --output_path=/home/TestData/nlp/megatron_llama/llama_ci.nemo \
            --precision=16
        - name: Cleanup
          if: "always()"
          run: |
            rm -rf /home/TestData/nlp/megatron_llama/model_weights
        - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
          if: "failure()"

  L2_Community_LLM_Checkpoints_tests_Llama3:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    timeout-minutes: 10
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v2
        - run: |
            CUDA_VISIBLE_DEVICES=0 python scripts/checkpoint_converters/convert_llama_hf_to_nemo.py \
            --input_name_or_path=/home/TestData/nlp/megatron_llama/llama3-ci-hf \
            --output_path=/home/TestData/nlp/megatron_llama/llama3-ci-hf/llama3_ci.nemo \
            --precision=16
            rm -f /home/TestData/nlp/megatron_llama/llama3-ci-hf/llama3_ci.nemo
        - name: Cleanup
          if: "always()"
          run: |
            rm -rf /home/TestData/nlp/megatron_llama/llama3-ci-hf/model_weights
        - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
          if: "failure()"

  L2_Community_LLM_Checkpoints_tests_StarCoder:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    timeout-minutes: 10
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v4
        - run: |
            mkdir -p /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/${{ github.run_id }};
            python scripts/checkpoint_converters/convert_starcoder_hf_to_nemo.py \
            --input_name_or_path /home/TestData/nlp/megatron_gpt/starcoder-ci-hf \
            --output_path /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/${{ github.run_id }}
        - name: Cleanup
          if: "always()"
          run: |
            rm -rf /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/megatron_starcoder_tp1_pp1.nemo; 
            rm -rf /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/${{ github.run_id }}/
            rm -rf /home/TestData/nlp/megatron_gpt/starcoder-ci-hf/model_weights
        - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
          if: "failure()"

  L2_Community_LLM_Checkpoints_tests_Falcon:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    timeout-minutes: 10
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options: 
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0 
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v4
        - run: |
            python scripts/checkpoint_converters/convert_falcon_hf_to_nemo.py \
            --input_name_or_path /home/TestData/nlp/megatron_gpt/falcon-ci-hf \
            --output_path /home/TestData/nlp/megatron_gpt/falcon-ci-hf/falcon_ci.nemo
            rm -f /home/TestData/nlp/megatron_gpt/falcon-ci-hf/falcon_ci.nemo
        - name: Cleanup
          if: "always()"
          run: |
            rm -rf /home/TestData/nlp/megatron_gpt/falcon-ci-hf/model_weights
        - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
          if: "failure()"

  L2_PTQ_Llama2_Export_Only:
    needs: [cicd-test-container-setup]
    runs-on: test-runner
    timeout-minutes: 10
    container:
      image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
      options:
        # --user 0:128
        --device=/dev/nvidia0
        -e NVIDIA_VISIBLE_DEVICES
        --shm-size=8g
        --env TRANSFORMERS_OFFLINE=0
        --env HYDRA_FULL_ERROR=1
        --volume /mnt/datadrive/TestData:/home/TestData
    steps:
        - name: Checkout repository
          uses: actions/checkout@v4
        - run: |
            python examples/nlp/language_modeling/megatron_quantization.py \
            model_file=/home/TestData/nlp/megatron_llama/llama_ci.nemo \
            quantization.algorithm=null \
            model_save=/home/TestData/nlp/megatron_llama/ci_baseline

            rm -rf /home/TestData/nlp/megatron_llama/ci_baseline
        - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
          if: "failure()"

  L2_PTQ_Llama2_FP8:
     needs: [cicd-test-container-setup]
     runs-on: test-runner
     timeout-minutes: 10
     container:
       image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
       options:
         # --user 0:128
         --runtime=nvidia
         -e NVIDIA_VISIBLE_DEVICES
         --shm-size=8g
         --env TRANSFORMERS_OFFLINE=0
         --env HYDRA_FULL_ERROR=1
         --volume /mnt/datadrive/TestData:/home/TestData
     steps:
         - name: Checkout repository
           uses: actions/checkout@v4
         - run: |
             python examples/nlp/language_modeling/megatron_quantization.py \
             model_file=/home/TestData/nlp/megatron_llama/llama_ci.nemo \
             tensor_model_parallel_size=2 \
             trainer.devices=2 \
             quantization.calib_dataset=/home/TestData/nlp/test_quantization/test.json \
             quantization.algorithm=fp8 \
             quantization.num_calib_size=8 \
             inference.batch_size=2 \
             export.inference_tensor_parallel=2 \
             model_save=/home/TestData/nlp/megatron_llama/ci_fp8.qnemo

             rm -rf /home/TestData/nlp/megatron_llama/ci_fp8.qnemo
         - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
           if: "failure()"

  L2_PTQ_Llama2_INT8_SQ:
     needs: [cicd-test-container-setup]
     runs-on: test-runner
     timeout-minutes: 10
     container:
       image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
       options:
         # --user 0:128
         --device=/dev/nvidia0
         -e NVIDIA_VISIBLE_DEVICES
         --shm-size=8g
         --env TRANSFORMERS_OFFLINE=0
         --env HYDRA_FULL_ERROR=1
         --volume /mnt/datadrive/TestData:/home/TestData
     steps:
         - name: Checkout repository
           uses: actions/checkout@v4
         - run: |
             python examples/nlp/language_modeling/megatron_quantization.py \
             model_file=/home/TestData/nlp/megatron_llama/llama_ci.nemo \
             quantization.calib_dataset=/home/TestData/nlp/test_quantization/test.json \
             quantization.algorithm=int8_sq \
             quantization.num_calib_size=8 \
             inference.batch_size=2 \
             model_save=/home/TestData/nlp/megatron_llama/ci_int8_sq.qnemo

             rm -rf /home/TestData/nlp/megatron_llama/ci_int8_sq.qnemo
         - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
           if: "failure()"

  # TODO: investigate int4_awq stuck issues and restore the test
  #L2_PTQ_Llama2_INT4_AWQ:
  #  needs: [cicd-test-container-setup]
  #  runs-on: test-runner
  #  timeout-minutes: 10
  #  container:
  #    image: nemoci.azurecr.io/nemo_container_${{ github.run_id }}
  #    options:
  #      # --user 0:128
  #      --device=/dev/nvidia0
  #      -e NVIDIA_VISIBLE_DEVICES
  #      --shm-size=8g
  #      --env TRANSFORMERS_OFFLINE=0
  #      --env HYDRA_FULL_ERROR=1
  #      --volume /mnt/datadrive/TestData:/home/TestData
  #  steps:
  #      - name: Checkout repository
  #        uses: actions/checkout@v4
  #      - run: |
  #          python examples/nlp/language_modeling/megatron_quantization.py \
  #          model_file=/home/TestData/nlp/megatron_llama/llama_ci.nemo \
  #          tensor_model_parallel_size=1 \
  #          trainer.devices=1 \
  #          quantization.calib_dataset=/home/TestData/nlp/test_quantization/test.json \
  #          quantization.algorithm=int4_awq \
  #          quantization.num_calib_size=8 \
  #          inference.batch_size=2 \
  #          model_save=/home/TestData/nlp/megatron_llama/ci_int4_awq.qnemo
  #
  #          rm -rf /home/TestData/nlp/megatron_llama/ci_int4_awq.qnemo
        #- uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
        #  if: "failure()"
