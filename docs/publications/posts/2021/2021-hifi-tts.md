---
title: "Hi-Fi Multi-Speaker English TTS Dataset"
author: [Evelina Bakhturina, Vitaly Lavrukhin, Boris Ginsburg, Yang Zhang]
author_gh_user: []
readtime: 30
date: 2021-08-30

# Optional: Categories
categories: [Text to Speech]
continue_url: https://www.isca-speech.org/archive/pdfs/interspeech_2021/bakhturina21_interspeech.pdf

# Optional: OpenGraph metadata
# og_title: Title of the blog post for Rich URL previews
# og_image: Image for Rich URL previews (absolute URL)
# og_image_type: Image type (e.g. image/png). Defaults to image/png.
# page_path: Relative path to the image from the website root (e.g. /assets/images/). If specified, the image at this path will be used for the link preview. It is unlikely you will need this parameter - you can probably use og_image instead.
# description: Description of the post for Rich URL previews
---

# [Hi-Fi Multi-Speaker English TTS Dataset](https://www.isca-speech.org/archive/pdfs/interspeech_2021/bakhturina21_interspeech.pdf)

This paper introduces a new multi-speaker English dataset for training text-to-speech models. The dataset is based on LibriVox audiobooks and Project Gutenberg texts, both in the public domain. The new dataset contains about 292 hours of speech from 10 speakers with at least 17 hours per speaker sampled at 44.1 kHz. To select speech samples with high quality, we considered audio recordings with a signal bandwidth of at least 13 kHz and a signal-to-noise ratio (SNR) of at least 32 dB. The dataset is publicly released at “http://www.openslr.org/109/”.

<!-- more -->

