{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "\"\"\"\n",
    "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "\n",
    "Instructions for setting up Colab are as follows:\n",
    "1. Open a new Python 3 notebook.\n",
    "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
    "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
    "4. Run this cell to set up dependencies.\n",
    "\"\"\"\n",
    "# If you're using Google Colab and not running locally, run this cell.\n",
    "!pip install wget\n",
    "!pip install git+https://github.com/NVIDIA/apex.git\n",
    "!pip install nemo-toolkit\n",
    "!pip install nemo-asr\n",
    "!pip install unidecode\n",
    "\n",
    "!mkdir configs\n",
    "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/master/examples/asr/configs/quartznet_speech_commands_3x1_v1.yaml\n",
    "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/master/examples/asr/configs/quartznet_speech_commands_3x1_v2.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some necessary libraries\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from ruamel.yaml import YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This Speech Command recognition tutorial is based on the QuartzNet model from the paper \"[QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions](https://arxiv.org/pdf/1910.10261.pdf)\" with a modified decoder head to suit classification tasks.\n",
    "\n",
    "The notebook will follow the steps below:\n",
    "\n",
    " - Dataset preparation: Preparing Google Speech Commands dataset\n",
    "\n",
    " - Audio preprocessing (feature extraction): signal normalization, windowing, (log) spectrogram (or mel scale spectrogram, or MFCC)\n",
    "\n",
    " - Data augmentation using SpecAugment \"[SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition](https://arxiv.org/abs/1904.08779)\" to increase number of data samples.\n",
    " \n",
    " - Develop a small Neural classification model which can be trained efficiently.\n",
    " \n",
    " - Model training on the Google Speech Commands dataset in NeMo.\n",
    " \n",
    " - Evaluation of error cases of the model by audibly hearing the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where the Google Speech Commands directory will be placed.\n",
    "# Change this if you don't want the data to be extracted in the current directory.\n",
    "# Select the version of the dataset required as well (can be 1 or 2)\n",
    "DATASET_VER = 2\n",
    "data_dir = './google_dataset_v{0}/'.format(DATASET_VER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/fjia/data/freesound_resampled'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "We will be using the open source Google Speech Commands Dataset (we will use V1 of the dataset for the tutorial, but require very minor changes to support V2 dataset). These scripts below will download the dataset and convert it to a format suitable for use with nemo_asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "The dataset must be prepared using the scripts provided under the `{NeMo root directory}/scripts` sub-directory. \n",
    "\n",
    "Run the following command below to download the training script and execute it.\n",
    "\n",
    "**NOTE**: You should have at least 4GB of disk space available if youâ€™ve used --data_version=1; and at least 6GB if you used --data_version=2. Also, it will take some time to download and process, so go grab a coffee.\n",
    "\n",
    "**NOTE**: You may additionally pass a `--rebalance` flag at the end of the `process_speech_commands_data.py` script to rebalance the class samples in the manifest."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# !wget https://raw.githubusercontent.com/NVIDIA/NeMo/master/scripts/process_speech_commands_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!mkdir {data_dir}\n",
    "!python process_speech_commands_data.py --data_root={data_dir} --data_version={DATASET_VER}\n",
    "print(\"Dataset ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the path to manifest files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtaset_path = 'google_speech_recognition_v{0}'.format(DATASET_VER)\n",
    "dataset_basedir = os.path.join(data_dir, dtaset_path)\n",
    "\n",
    "train_dataset = os.path.join(dataset_basedir, 'train_manifest.json')\n",
    "val_dataset = os.path.join(dataset_basedir, 'validation_manifest.json')\n",
    "test_dataset = os.path.join(dataset_basedir, 'validation_manifest.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBO 2 \n",
    "## Background + Speech Command 57k, 7k, 7k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_basedir = data_dir\n",
    "\n",
    "\n",
    "train_dataset = './old_manifest/background_training_manifest.json,./old_manifest/2balanced_sc_train_manifest.json'\n",
    "# test_dataset  = './manifest/background_testing_manifest.json,./manifest/2balanced_sc_test_manifest.json'\n",
    "test_dataset  = './old_manifest/all_test.json'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 100ms audio window\n",
    "dataset_basedir = data_dir\n",
    "\n",
    "train_dataset = './manifest/2balanced_100ms_background_training_manifest.json,./manifest/2balanced_100ms_sc_training_manifest.json'\n",
    "# test_dataset  = './manifest/background_testing_manifest.json,./manifest/2balanced_sc_test_manifest.json'\n",
    "test_dataset  = './manifest/100ms_all_test.json'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "dataset_basedir = data_dir\n",
    "\n",
    "train_dataset = './manifest/3balanced_background_training_manifest.json,./manifest/3balanced_sc_train_manifest.json,./manifest/speech_training_manifest.json'\n",
    "val_dataset   = './manifest/3balanced_background_validation_manifest.json,./manifest/3balanced_sc_validation_manifest.json,./manifest/speech_validation_manifest.json'\n",
    "test_dataset  = './manifest/3balanced_background_testing_manifest.json,./manifest/3balanced_sc_test_manifest.json,./manifest/speech_testing_manifest.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a few rows of the manifest file \n",
    "\n",
    "Manifest files are the data structure used by NeMo to declare a few important details about the data :\n",
    "\n",
    "1) `audio_filepath`: Refers to the path to the raw audio file <br>\n",
    "2) `command`: The class label (or speech command) of this sample <br>\n",
    "3) `duration`: The length of the audio file, in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/bfd26d6b_nohash_2.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/b83c1acf_nohash_3.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/2fa39636_nohash_2.wav\", \"duration\": 0.8359375, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/b83c1acf_nohash_2.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/bfd26d6b_nohash_3.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/e0c782d5_nohash_1.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/ea356919_nohash_1.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/85d2ac4b_nohash_0.wav\", \"duration\": 0.682625, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/63f7a489_nohash_3.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n",
      "{\"audio_filepath\": \"/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/up/d0faf7e4_nohash_0.wav\", \"duration\": 1.0, \"label\": \"commands\", \"text\": \"_\", \"offset\": 0.0}\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 10 {test_dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Preparation\n",
    "\n",
    "We will be training a QuartzNet model from the paper \"[QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions](https://arxiv.org/pdf/1910.10261.pdf)\". The benefit of QuartzNet over JASPER models is that they use Separable Convolutions, which greatly reduce the number of parameters required to get good model accuracy.\n",
    "\n",
    "QuartzNet models generally follow the model definition pattern QuartzNet-[BxR], where B is the number of blocks and R is the number of convolutional sub-blocks. Each sub-block contains a 1-D masked convolution, batch normalization, ReLU, and dropout:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_VERSION ='v1'\n",
    "COMBO_VERSION = 'combo_balanced_all_Mfcc_prob0.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load the config file for the QuartzNet 3x1 model\n",
    "# Here we will be using separable convolutions\n",
    "# with 3 blocks (k=3 repeated once r=1 from the picture above)\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(\"configs/quartznet_vad_3x1_{0}.yaml\".format(FEAT_VERSION)) as f:\n",
    "    jasper_params = yaml.load(f)\n",
    "\n",
    "# Pre-define a set of labels that this model must learn to predict\n",
    "labels = jasper_params['labels']\n",
    "\n",
    "# Get the sampling rate of the data\n",
    "sample_rate = jasper_params['sample_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "# Import NeMo core functionality\n",
    "# NeMo's \"core\" package\n",
    "import nemo\n",
    "# NeMo's ASR collection\n",
    "import nemo.collections.asr as nemo_asr\n",
    "# NeMo's learning rate policy\n",
    "from nemo.utils.lr_policies import CosineAnnealing\n",
    "from nemo.collections.asr.helpers import (\n",
    "    monitor_classification_training_progress,\n",
    "    process_classification_evaluation_batch,\n",
    "    process_classification_evaluation_epoch,\n",
    ")\n",
    "from nemo.collections.asr.metrics import classification_accuracy\n",
    "\n",
    "logging = nemo.logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some model hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define some hyper parameters\n",
    "lr = 0.05\n",
    "num_epochs = 5 #5\n",
    "batch_size = 128\n",
    "weight_decay = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the NeMo components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Neural Factory\n",
    "# It creates log files and tensorboard writers for us among other functions\n",
    "neural_factory = nemo.core.NeuralModuleFactory(\n",
    "    log_dir='./{0}/quartznet-3x1-{1}{2}'.format(dataset_basedir, FEAT_VERSION, COMBO_VERSION),\n",
    "    create_tb_writer=True)\n",
    "tb_writer = neural_factory.tb_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-08 17:41:26 collections:222] Filtered duration for loading collection is 7.351812.\n",
      "[NeMo I 2020-05-08 17:41:27 collections:222] Filtered duration for loading collection is 1.173313.\n",
      "[NeMo I 2020-05-08 17:41:27 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-08 17:41:27 features:152] STFT using conv\n",
      "[NeMo I 2020-05-08 17:41:29 <ipython-input-10-09d345f4e405>:40] Steps per epoch : 894\n",
      "[NeMo I 2020-05-08 17:41:29 <ipython-input-10-09d345f4e405>:41] Have 114200 examples to train on.\n"
     ]
    }
   ],
   "source": [
    "# Check if data augmentation such as white noise and time shift augmentation should be used\n",
    "audio_augmentor = jasper_params.get('AudioAugmentor', None)\n",
    "\n",
    "# Build the input data layer and the preprocessing layers for the train set\n",
    "train_data_layer = nemo_asr.AudioToSpeechLabelDataLayer(\n",
    "    manifest_filepath=train_dataset,\n",
    "    labels=labels,\n",
    "    sample_rate=sample_rate,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=os.cpu_count(),\n",
    "    augmentor=audio_augmentor,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    " # Build the input data layer and the preprocessing layers for the test set\n",
    "eval_data_layer = nemo_asr.AudioToSpeechLabelDataLayer(\n",
    "    manifest_filepath=test_dataset,\n",
    "    sample_rate=sample_rate,\n",
    "    labels=labels,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=os.cpu_count(),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# # We will convert the raw audio data into MelSpectrogram Features to feed as input to our model\n",
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n",
    "    sample_rate=sample_rate, **jasper_params[\"AudioToMelSpectrogramPreprocessor\"],\n",
    ")\n",
    "\n",
    "# data_preprocessor = nemo_asr.AudioToMFCCPreprocessor(\n",
    "#     sample_rate=sample_rate, **jasper_params[\"AudioToMFCCPreprocessor\"],\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# Compute the total number of samples and the number of training steps per epoch\n",
    "N = len(train_data_layer)\n",
    "steps_per_epoch = math.ceil(N / float(batch_size) + 1)\n",
    "\n",
    "logging.info(\"Steps per epoch : {0}\".format(steps_per_epoch))\n",
    "logging.info('Have {0} examples to train on.'.format(N))\n",
    "\n",
    "# Here we begin defining all of the augmentations we want\n",
    "# We will pad the preprocessed spectrogram image to have a certain number of timesteps\n",
    "# This centers the generated spectrogram and adds black boundaries to either side\n",
    "# of the padded image.\n",
    "crop_pad_augmentation = nemo_asr.CropOrPadSpectrogramAugmentation(audio_length=128)\n",
    "\n",
    "# We also optionally add `SpecAugment` augmentations based on the config file\n",
    "# SpecAugment has various possible augmentations to the generated spectrogram\n",
    "# 1) Frequency band masking\n",
    "# 2) Time band masking\n",
    "# 3) Rectangular cutout\n",
    "spectr_augment_config = jasper_params.get('SpectrogramAugmentation', None)\n",
    "\n",
    "if spectr_augment_config:\n",
    "    data_spectr_augmentation = nemo_asr.SpectrogramAugmentation(**spectr_augment_config)\n",
    "\n",
    "# Build the QuartzNet Encoder model\n",
    "# The config defines the layers as a list of dictionaries\n",
    "# The first and last two blocks are not considered when we say QuartzNet-[BxR]\n",
    "# B is counted as the number of blocks after the first layer and before the penultimate layer.\n",
    "# R is defined as the number of repetitions of each block in B.\n",
    "# Note: We can scale the convolution kernels size by the float parameter `kernel_size_factor`\n",
    "jasper_encoder = nemo_asr.JasperEncoder(**jasper_params[\"JasperEncoder\"])\n",
    "\n",
    "# We then define the QuartzNet decoder.\n",
    "# This decoder head is specialized for the task for classification, such that it\n",
    "# accepts a set of `N-feat` per timestep of the model, and averages these features\n",
    "# over all the timesteps, before passing a Linear classification layer on those features.\n",
    "jasper_decoder = nemo_asr.JasperDecoderForClassification(\n",
    "    feat_in=jasper_params[\"JasperEncoder\"][\"jasper\"][-1][\"filters\"],\n",
    "    num_classes=len(labels),\n",
    "    **jasper_params['JasperDecoderForClassification'],\n",
    ")\n",
    "\n",
    "# We can easily apply cross entropy loss to train this model\n",
    "ce_loss = nemo_asr.CrossEntropyLossNM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-08 17:41:33 <ipython-input-11-6805b5462cf6>:2] ================================\n",
      "[NeMo I 2020-05-08 17:41:33 <ipython-input-11-6805b5462cf6>:3] Number of parameters in encoder: 73344\n",
      "[NeMo I 2020-05-08 17:41:33 <ipython-input-11-6805b5462cf6>:4] Number of parameters in decoder: 258\n",
      "[NeMo I 2020-05-08 17:41:33 <ipython-input-11-6805b5462cf6>:6] Total number of parameters in model: 73602\n",
      "[NeMo I 2020-05-08 17:41:33 <ipython-input-11-6805b5462cf6>:8] ================================\n"
     ]
    }
   ],
   "source": [
    "# Lets print out the number of parameters of this model\n",
    "logging.info('================================')\n",
    "logging.info(f\"Number of parameters in encoder: {jasper_encoder.num_weights}\")\n",
    "logging.info(f\"Number of parameters in decoder: {jasper_decoder.num_weights}\")\n",
    "logging.info(\n",
    "    f\"Total number of parameters in model: \" f\"{jasper_decoder.num_weights + jasper_encoder.num_weights}\"\n",
    ")\n",
    "logging.info('================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Training Graph for NeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have all of the components that are required to build the NeMo execution graph!\n",
    "## Build the training data loaders and preprocessors first\n",
    "audio_signal, audio_signal_len, labels, label_len = train_data_layer()\n",
    "processed_signal, processed_signal_len = data_preprocessor(input_signal=audio_signal, length=audio_signal_len)\n",
    "processed_signal, processed_signal_len = crop_pad_augmentation(\n",
    "    input_signal=processed_signal,\n",
    "    length=audio_signal_len\n",
    ")\n",
    "\n",
    "## Augment the dataset for training\n",
    "if spectr_augment_config:\n",
    "    processed_signal = data_spectr_augmentation(input_spec=processed_signal)\n",
    "\n",
    "## Define the model\n",
    "encoded, encoded_len = jasper_encoder(audio_signal=processed_signal, length=processed_signal_len)\n",
    "decoded = jasper_decoder(encoder_output=encoded)\n",
    "\n",
    "## Obtain the train loss\n",
    "train_loss = ce_loss(logits=decoded, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Test Graph for NeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the test graph in a similar way, reusing the above components\n",
    "## Build the test data loader and preprocess same way as train graph\n",
    "## But note, we do not add the spectrogram augmentation to the test graph !\n",
    "test_audio_signal, test_audio_signal_len, test_labels, test_label_len = eval_data_layer()\n",
    "test_processed_signal, test_processed_signal_len = data_preprocessor(\n",
    "    input_signal=test_audio_signal, length=test_audio_signal_len\n",
    ")\n",
    "test_processed_signal, test_processed_signal_len = crop_pad_augmentation(\n",
    "    input_signal=test_processed_signal, length=test_processed_signal_len\n",
    ")\n",
    "\n",
    "# Pass the test data through the model encoder and decoder\n",
    "test_encoded, test_encoded_len = jasper_encoder(\n",
    "    audio_signal=test_processed_signal, length=test_processed_signal_len\n",
    ")\n",
    "test_decoded = jasper_decoder(encoder_output=test_encoded)\n",
    "\n",
    "# Compute test loss for visualization\n",
    "test_loss = ce_loss(logits=test_decoded, labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up callbacks for training and test set evaluation, and checkpoint saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now that we have our training and evaluation graphs built,\n",
    "# we can focus on a few callbacks to help us save the model checkpoints\n",
    "# during training, as well as display train and test metrics\n",
    "\n",
    "# Callbacks needed to print train info to console and Tensorboard\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    # Notice that we pass in loss, predictions, and the labels.\n",
    "    # Of course we would like to see our training loss, but we need the\n",
    "    # other arguments to calculate the accuracy.\n",
    "    tensors=[train_loss, decoded, labels],\n",
    "    # The print_func defines what gets printed.\n",
    "    print_func=partial(monitor_classification_training_progress, eval_metric=None),\n",
    "    get_tb_values=lambda x: [(\"loss\", x[0])],\n",
    "    tb_writer=neural_factory.tb_writer,\n",
    ")\n",
    "\n",
    "# Callbacks needed to print test info to console and Tensorboard\n",
    "tagname = 'TestSet'\n",
    "eval_callback = nemo.core.EvaluatorCallback(\n",
    "    eval_tensors=[test_loss, test_decoded, test_labels],\n",
    "    user_iter_callback=partial(process_classification_evaluation_batch, top_k=1),\n",
    "    user_epochs_done_callback=partial(process_classification_evaluation_epoch, eval_metric=1, tag=tagname),\n",
    "    eval_step=200,  # How often we evaluate the model on the test set #200\n",
    "    tb_writer=neural_factory.tb_writer,\n",
    ")\n",
    "\n",
    "# Callback to save model checkpoints\n",
    "chpt_callback = nemo.core.CheckpointCallback(\n",
    "    folder=neural_factory.checkpoint_dir,\n",
    "    step_freq=1000,\n",
    ")\n",
    "\n",
    "# Prepare a list of checkpoints to pass to the engine\n",
    "callbacks = [train_callback, eval_callback, chpt_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "Even with such a small model (77k parameters), and just 5 epochs (should take just a few minutes to train), you should be able to get a test set accuracy score in the range 85 - 90%. Not bad for a 30 (v1) or 35 (v2) way classification problem !\n",
    "\n",
    "Experiment with increasing the number of epochs or with batch size to see how much you can improve the score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:13:54 <ipython-input-22-689768946717>:13] Using `<nemo.utils.lr_policies.CosineAnnealing object at 0x7f29045a0b50>` Learning Rate Scheduler\n",
      "[NeMo I 2020-05-07 15:13:54 callbacks:187] Starting .....\n",
      "[NeMo I 2020-05-07 15:13:54 callbacks:359] Found 2 modules with weights:\n",
      "[NeMo I 2020-05-07 15:13:54 callbacks:361] JasperEncoder\n",
      "[NeMo I 2020-05-07 15:13:54 callbacks:361] JasperDecoderForClassification\n",
      "[NeMo I 2020-05-07 15:13:54 callbacks:362] Total model parameters: 73602\n",
      "[NeMo I 2020-05-07 15:13:54 callbacks:311] Found checkpoint folder .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints. Will attempt to restore checkpoints from it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-07 15:13:54 callbacks:328] For module JasperDecoderForClassification, no file matches  in .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints\n",
      "[NeMo W 2020-05-07 15:13:54 callbacks:330] Checkpoint folder .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints was present but nothing was restored. Continuing training from random initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:13:54 callbacks:199] Starting epoch 0\n",
      "[NeMo I 2020-05-07 15:13:55 callbacks:224] Step: 0\n",
      "[NeMo I 2020-05-07 15:13:55 helpers:104] Loss: 0.7503116726875305\n",
      "[NeMo I 2020-05-07 15:13:55 helpers:110] training_batch_top@1:  46.0938\n",
      "[NeMo I 2020-05-07 15:13:55 callbacks:239] Step time: 0.20498371124267578 seconds\n",
      "[NeMo I 2020-05-07 15:13:55 callbacks:445] Doing Evaluation ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:13:57 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.6917204856872559\n",
      "[NeMo I 2020-05-07 15:13:57 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 58.9496\n",
      "[NeMo I 2020-05-07 15:13:57 callbacks:450] Evaluation time: 1.4857428073883057 seconds\n",
      "[NeMo I 2020-05-07 15:13:58 callbacks:224] Step: 25\n",
      "[NeMo I 2020-05-07 15:13:58 helpers:104] Loss: 0.3551883101463318\n",
      "[NeMo I 2020-05-07 15:13:58 helpers:110] training_batch_top@1:  86.7188\n",
      "[NeMo I 2020-05-07 15:13:58 callbacks:239] Step time: 0.04430961608886719 seconds\n",
      "[NeMo I 2020-05-07 15:13:59 callbacks:224] Step: 50\n",
      "[NeMo I 2020-05-07 15:13:59 helpers:104] Loss: 0.2272559553384781\n",
      "[NeMo I 2020-05-07 15:13:59 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:13:59 callbacks:239] Step time: 0.04366898536682129 seconds\n",
      "[NeMo I 2020-05-07 15:14:00 callbacks:224] Step: 75\n",
      "[NeMo I 2020-05-07 15:14:00 helpers:104] Loss: 0.25523388385772705\n",
      "[NeMo I 2020-05-07 15:14:00 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:14:00 callbacks:239] Step time: 0.04039311408996582 seconds\n",
      "[NeMo I 2020-05-07 15:14:01 callbacks:224] Step: 100\n",
      "[NeMo I 2020-05-07 15:14:01 helpers:104] Loss: 0.28336960077285767\n",
      "[NeMo I 2020-05-07 15:14:01 helpers:110] training_batch_top@1:  89.8438\n",
      "[NeMo I 2020-05-07 15:14:01 callbacks:239] Step time: 0.040453433990478516 seconds\n",
      "[NeMo I 2020-05-07 15:14:02 callbacks:224] Step: 125\n",
      "[NeMo I 2020-05-07 15:14:02 helpers:104] Loss: 0.20299403369426727\n",
      "[NeMo I 2020-05-07 15:14:02 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:02 callbacks:239] Step time: 0.04120349884033203 seconds\n",
      "[NeMo I 2020-05-07 15:14:03 callbacks:224] Step: 150\n",
      "[NeMo I 2020-05-07 15:14:03 helpers:104] Loss: 0.21795493364334106\n",
      "[NeMo I 2020-05-07 15:14:03 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:14:03 callbacks:239] Step time: 0.04047513008117676 seconds\n",
      "[NeMo I 2020-05-07 15:14:04 callbacks:224] Step: 175\n",
      "[NeMo I 2020-05-07 15:14:04 helpers:104] Loss: 0.1801374852657318\n",
      "[NeMo I 2020-05-07 15:14:04 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:04 callbacks:239] Step time: 0.040821075439453125 seconds\n",
      "[NeMo I 2020-05-07 15:14:05 callbacks:224] Step: 200\n",
      "[NeMo I 2020-05-07 15:14:05 helpers:104] Loss: 0.17530110478401184\n",
      "[NeMo I 2020-05-07 15:14:05 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:05 callbacks:239] Step time: 0.040433645248413086 seconds\n",
      "[NeMo I 2020-05-07 15:14:05 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:14:07 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.3396841585636139\n",
      "[NeMo I 2020-05-07 15:14:07 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 91.4436\n",
      "[NeMo I 2020-05-07 15:14:07 callbacks:450] Evaluation time: 1.4387445449829102 seconds\n",
      "[NeMo I 2020-05-07 15:14:08 callbacks:224] Step: 225\n",
      "[NeMo I 2020-05-07 15:14:08 helpers:104] Loss: 0.24363024532794952\n",
      "[NeMo I 2020-05-07 15:14:08 helpers:110] training_batch_top@1:  89.8438\n",
      "[NeMo I 2020-05-07 15:14:08 callbacks:239] Step time: 0.04080390930175781 seconds\n",
      "[NeMo I 2020-05-07 15:14:09 callbacks:224] Step: 250\n",
      "[NeMo I 2020-05-07 15:14:09 helpers:104] Loss: 0.16411899030208588\n",
      "[NeMo I 2020-05-07 15:14:09 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:14:09 callbacks:239] Step time: 0.042613983154296875 seconds\n",
      "[NeMo I 2020-05-07 15:14:10 callbacks:224] Step: 275\n",
      "[NeMo I 2020-05-07 15:14:10 helpers:104] Loss: 0.24062497913837433\n",
      "[NeMo I 2020-05-07 15:14:10 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:14:10 callbacks:239] Step time: 0.043729305267333984 seconds\n",
      "[NeMo I 2020-05-07 15:14:11 callbacks:224] Step: 300\n",
      "[NeMo I 2020-05-07 15:14:11 helpers:104] Loss: 0.129764124751091\n",
      "[NeMo I 2020-05-07 15:14:11 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:14:11 callbacks:239] Step time: 0.0449521541595459 seconds\n",
      "[NeMo I 2020-05-07 15:14:12 callbacks:224] Step: 325\n",
      "[NeMo I 2020-05-07 15:14:12 helpers:104] Loss: 0.14905652403831482\n",
      "[NeMo I 2020-05-07 15:14:12 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:14:12 callbacks:239] Step time: 0.044362783432006836 seconds\n",
      "[NeMo I 2020-05-07 15:14:13 callbacks:224] Step: 350\n",
      "[NeMo I 2020-05-07 15:14:13 helpers:104] Loss: 0.14075356721878052\n",
      "[NeMo I 2020-05-07 15:14:13 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:14:13 callbacks:239] Step time: 0.041486501693725586 seconds\n",
      "[NeMo I 2020-05-07 15:14:14 callbacks:224] Step: 375\n",
      "[NeMo I 2020-05-07 15:14:14 helpers:104] Loss: 0.15036319196224213\n",
      "[NeMo I 2020-05-07 15:14:14 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:14 callbacks:239] Step time: 0.04478883743286133 seconds\n",
      "[NeMo I 2020-05-07 15:14:15 callbacks:224] Step: 400\n",
      "[NeMo I 2020-05-07 15:14:15 helpers:104] Loss: 0.32184022665023804\n",
      "[NeMo I 2020-05-07 15:14:15 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:14:15 callbacks:239] Step time: 0.04258394241333008 seconds\n",
      "[NeMo I 2020-05-07 15:14:15 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:14:17 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.13169200718402863\n",
      "[NeMo I 2020-05-07 15:14:17 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 96.6236\n",
      "[NeMo I 2020-05-07 15:14:17 callbacks:450] Evaluation time: 1.4589059352874756 seconds\n",
      "[NeMo I 2020-05-07 15:14:18 callbacks:224] Step: 425\n",
      "[NeMo I 2020-05-07 15:14:18 helpers:104] Loss: 0.19300444424152374\n",
      "[NeMo I 2020-05-07 15:14:18 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:18 callbacks:239] Step time: 0.04032325744628906 seconds\n",
      "[NeMo I 2020-05-07 15:14:19 callbacks:224] Step: 450\n",
      "[NeMo I 2020-05-07 15:14:19 helpers:104] Loss: 0.19336757063865662\n",
      "[NeMo I 2020-05-07 15:14:19 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:19 callbacks:239] Step time: 0.04071664810180664 seconds\n",
      "[NeMo I 2020-05-07 15:14:20 callbacks:224] Step: 475\n",
      "[NeMo I 2020-05-07 15:14:20 helpers:104] Loss: 0.24909590184688568\n",
      "[NeMo I 2020-05-07 15:14:20 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:20 callbacks:239] Step time: 0.0444483757019043 seconds\n",
      "[NeMo I 2020-05-07 15:14:21 callbacks:224] Step: 500\n",
      "[NeMo I 2020-05-07 15:14:21 helpers:104] Loss: 0.18578729033470154\n",
      "[NeMo I 2020-05-07 15:14:21 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:21 callbacks:239] Step time: 0.0436098575592041 seconds\n",
      "[NeMo I 2020-05-07 15:14:22 callbacks:224] Step: 525\n",
      "[NeMo I 2020-05-07 15:14:22 helpers:104] Loss: 0.31176137924194336\n",
      "[NeMo I 2020-05-07 15:14:22 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:14:22 callbacks:239] Step time: 0.04254341125488281 seconds\n",
      "[NeMo I 2020-05-07 15:14:23 callbacks:224] Step: 550\n",
      "[NeMo I 2020-05-07 15:14:23 helpers:104] Loss: 0.21549926698207855\n",
      "[NeMo I 2020-05-07 15:14:23 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:14:23 callbacks:239] Step time: 0.041246652603149414 seconds\n",
      "[NeMo I 2020-05-07 15:14:24 callbacks:224] Step: 575\n",
      "[NeMo I 2020-05-07 15:14:24 helpers:104] Loss: 0.19925826787948608\n",
      "[NeMo I 2020-05-07 15:14:24 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:14:24 callbacks:239] Step time: 0.04384565353393555 seconds\n",
      "[NeMo I 2020-05-07 15:14:25 callbacks:224] Step: 600\n",
      "[NeMo I 2020-05-07 15:14:25 helpers:104] Loss: 0.19340158998966217\n",
      "[NeMo I 2020-05-07 15:14:25 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:25 callbacks:239] Step time: 0.04069828987121582 seconds\n",
      "[NeMo I 2020-05-07 15:14:25 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:14:27 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.08644884079694748\n",
      "[NeMo I 2020-05-07 15:14:27 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 97.0132\n",
      "[NeMo I 2020-05-07 15:14:27 callbacks:450] Evaluation time: 1.5189704895019531 seconds\n",
      "[NeMo I 2020-05-07 15:14:28 callbacks:224] Step: 625\n",
      "[NeMo I 2020-05-07 15:14:28 helpers:104] Loss: 0.3744400143623352\n",
      "[NeMo I 2020-05-07 15:14:28 helpers:110] training_batch_top@1:  85.9375\n",
      "[NeMo I 2020-05-07 15:14:28 callbacks:239] Step time: 0.04029512405395508 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:14:29 callbacks:224] Step: 650\n",
      "[NeMo I 2020-05-07 15:14:29 helpers:104] Loss: 0.1436813473701477\n",
      "[NeMo I 2020-05-07 15:14:29 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:14:29 callbacks:239] Step time: 0.04389381408691406 seconds\n",
      "[NeMo I 2020-05-07 15:14:30 callbacks:224] Step: 675\n",
      "[NeMo I 2020-05-07 15:14:30 helpers:104] Loss: 0.2161560356616974\n",
      "[NeMo I 2020-05-07 15:14:30 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:14:30 callbacks:239] Step time: 0.04391002655029297 seconds\n",
      "[NeMo I 2020-05-07 15:14:31 callbacks:224] Step: 700\n",
      "[NeMo I 2020-05-07 15:14:31 helpers:104] Loss: 0.22580504417419434\n",
      "[NeMo I 2020-05-07 15:14:31 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:31 callbacks:239] Step time: 0.040617942810058594 seconds\n",
      "[NeMo I 2020-05-07 15:14:32 callbacks:224] Step: 725\n",
      "[NeMo I 2020-05-07 15:14:32 helpers:104] Loss: 0.14303067326545715\n",
      "[NeMo I 2020-05-07 15:14:32 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:14:32 callbacks:239] Step time: 0.042816877365112305 seconds\n",
      "[NeMo I 2020-05-07 15:14:33 callbacks:224] Step: 750\n",
      "[NeMo I 2020-05-07 15:14:33 helpers:104] Loss: 0.2162884771823883\n",
      "[NeMo I 2020-05-07 15:14:33 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:33 callbacks:239] Step time: 0.04045510292053223 seconds\n",
      "[NeMo I 2020-05-07 15:14:34 callbacks:224] Step: 775\n",
      "[NeMo I 2020-05-07 15:14:34 helpers:104] Loss: 0.1837081015110016\n",
      "[NeMo I 2020-05-07 15:14:34 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:14:34 callbacks:239] Step time: 0.04410815238952637 seconds\n",
      "[NeMo I 2020-05-07 15:14:35 callbacks:224] Step: 800\n",
      "[NeMo I 2020-05-07 15:14:35 helpers:104] Loss: 0.16572292149066925\n",
      "[NeMo I 2020-05-07 15:14:35 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:35 callbacks:239] Step time: 0.04050898551940918 seconds\n",
      "[NeMo I 2020-05-07 15:14:35 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:14:37 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.1590137481689453\n",
      "[NeMo I 2020-05-07 15:14:37 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 92.9442\n",
      "[NeMo I 2020-05-07 15:14:37 callbacks:450] Evaluation time: 1.4588727951049805 seconds\n",
      "[NeMo I 2020-05-07 15:14:38 callbacks:224] Step: 825\n",
      "[NeMo I 2020-05-07 15:14:38 helpers:104] Loss: 0.2918494939804077\n",
      "[NeMo I 2020-05-07 15:14:38 helpers:110] training_batch_top@1:  87.5000\n",
      "[NeMo I 2020-05-07 15:14:38 callbacks:239] Step time: 0.04023098945617676 seconds\n",
      "[NeMo I 2020-05-07 15:14:39 callbacks:224] Step: 850\n",
      "[NeMo I 2020-05-07 15:14:39 helpers:104] Loss: 0.2354092001914978\n",
      "[NeMo I 2020-05-07 15:14:39 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:14:39 callbacks:239] Step time: 0.045671939849853516 seconds\n",
      "[NeMo I 2020-05-07 15:14:40 callbacks:224] Step: 875\n",
      "[NeMo I 2020-05-07 15:14:40 helpers:104] Loss: 0.22437933087348938\n",
      "[NeMo I 2020-05-07 15:14:40 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:14:40 callbacks:239] Step time: 0.039704084396362305 seconds\n",
      "[NeMo I 2020-05-07 15:14:41 callbacks:207] Finished epoch 0 in 0:00:46.638186\n",
      "[NeMo I 2020-05-07 15:14:41 callbacks:199] Starting epoch 1\n",
      "[NeMo I 2020-05-07 15:14:42 callbacks:224] Step: 900\n",
      "[NeMo I 2020-05-07 15:14:42 helpers:104] Loss: 0.18912702798843384\n",
      "[NeMo I 2020-05-07 15:14:42 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:42 callbacks:239] Step time: 0.04490351676940918 seconds\n",
      "[NeMo I 2020-05-07 15:14:43 callbacks:224] Step: 925\n",
      "[NeMo I 2020-05-07 15:14:43 helpers:104] Loss: 0.14234453439712524\n",
      "[NeMo I 2020-05-07 15:14:43 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:14:43 callbacks:239] Step time: 0.040595054626464844 seconds\n",
      "[NeMo I 2020-05-07 15:14:44 callbacks:224] Step: 950\n",
      "[NeMo I 2020-05-07 15:14:44 helpers:104] Loss: 0.17528051137924194\n",
      "[NeMo I 2020-05-07 15:14:44 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:44 callbacks:239] Step time: 0.04037165641784668 seconds\n",
      "[NeMo I 2020-05-07 15:14:45 callbacks:224] Step: 975\n",
      "[NeMo I 2020-05-07 15:14:45 helpers:104] Loss: 0.2852620482444763\n",
      "[NeMo I 2020-05-07 15:14:45 helpers:110] training_batch_top@1:  89.8438\n",
      "[NeMo I 2020-05-07 15:14:45 callbacks:239] Step time: 0.04462480545043945 seconds\n",
      "[NeMo I 2020-05-07 15:14:46 callbacks:224] Step: 1000\n",
      "[NeMo I 2020-05-07 15:14:46 helpers:104] Loss: 0.254167765378952\n",
      "[NeMo I 2020-05-07 15:14:46 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:14:46 callbacks:239] Step time: 0.05016946792602539 seconds\n",
      "[NeMo I 2020-05-07 15:14:46 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:14:48 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.1402544379234314\n",
      "[NeMo I 2020-05-07 15:14:48 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 95.3539\n",
      "[NeMo I 2020-05-07 15:14:48 callbacks:450] Evaluation time: 1.52079439163208 seconds\n",
      "[NeMo I 2020-05-07 15:14:48 callbacks:303] Saved checkpoint: .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints/trainer-STEP-1000.pt\n",
      "[NeMo I 2020-05-07 15:14:49 callbacks:224] Step: 1025\n",
      "[NeMo I 2020-05-07 15:14:49 helpers:104] Loss: 0.1658441424369812\n",
      "[NeMo I 2020-05-07 15:14:49 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:49 callbacks:239] Step time: 0.041591644287109375 seconds\n",
      "[NeMo I 2020-05-07 15:14:50 callbacks:224] Step: 1050\n",
      "[NeMo I 2020-05-07 15:14:50 helpers:104] Loss: 0.18558761477470398\n",
      "[NeMo I 2020-05-07 15:14:50 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:50 callbacks:239] Step time: 0.04383277893066406 seconds\n",
      "[NeMo I 2020-05-07 15:14:51 callbacks:224] Step: 1075\n",
      "[NeMo I 2020-05-07 15:14:51 helpers:104] Loss: 0.1495245099067688\n",
      "[NeMo I 2020-05-07 15:14:51 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:14:51 callbacks:239] Step time: 0.043962717056274414 seconds\n",
      "[NeMo I 2020-05-07 15:14:52 callbacks:224] Step: 1100\n",
      "[NeMo I 2020-05-07 15:14:52 helpers:104] Loss: 0.152304008603096\n",
      "[NeMo I 2020-05-07 15:14:52 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:52 callbacks:239] Step time: 0.0409998893737793 seconds\n",
      "[NeMo I 2020-05-07 15:14:53 callbacks:224] Step: 1125\n",
      "[NeMo I 2020-05-07 15:14:53 helpers:104] Loss: 0.22071683406829834\n",
      "[NeMo I 2020-05-07 15:14:53 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:14:53 callbacks:239] Step time: 0.041048526763916016 seconds\n",
      "[NeMo I 2020-05-07 15:14:54 callbacks:224] Step: 1150\n",
      "[NeMo I 2020-05-07 15:14:54 helpers:104] Loss: 0.24872538447380066\n",
      "[NeMo I 2020-05-07 15:14:54 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:14:54 callbacks:239] Step time: 0.040415048599243164 seconds\n",
      "[NeMo I 2020-05-07 15:14:55 callbacks:224] Step: 1175\n",
      "[NeMo I 2020-05-07 15:14:55 helpers:104] Loss: 0.12748883664608002\n",
      "[NeMo I 2020-05-07 15:14:55 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:14:55 callbacks:239] Step time: 0.05125284194946289 seconds\n",
      "[NeMo I 2020-05-07 15:14:57 callbacks:224] Step: 1200\n",
      "[NeMo I 2020-05-07 15:14:57 helpers:104] Loss: 0.17828308045864105\n",
      "[NeMo I 2020-05-07 15:14:57 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:14:57 callbacks:239] Step time: 0.04968380928039551 seconds\n",
      "[NeMo I 2020-05-07 15:14:57 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:14:58 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.09669506549835205\n",
      "[NeMo I 2020-05-07 15:14:58 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 96.7102\n",
      "[NeMo I 2020-05-07 15:14:58 callbacks:450] Evaluation time: 1.5062453746795654 seconds\n",
      "[NeMo I 2020-05-07 15:14:59 callbacks:224] Step: 1225\n",
      "[NeMo I 2020-05-07 15:14:59 helpers:104] Loss: 0.18895317614078522\n",
      "[NeMo I 2020-05-07 15:14:59 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:14:59 callbacks:239] Step time: 0.04082059860229492 seconds\n",
      "[NeMo I 2020-05-07 15:15:00 callbacks:224] Step: 1250\n",
      "[NeMo I 2020-05-07 15:15:00 helpers:104] Loss: 0.18386641144752502\n",
      "[NeMo I 2020-05-07 15:15:00 helpers:110] training_batch_top@1:  94.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:15:00 callbacks:239] Step time: 0.044036149978637695 seconds\n",
      "[NeMo I 2020-05-07 15:15:01 callbacks:224] Step: 1275\n",
      "[NeMo I 2020-05-07 15:15:01 helpers:104] Loss: 0.061141736805438995\n",
      "[NeMo I 2020-05-07 15:15:01 helpers:110] training_batch_top@1:  99.2188\n",
      "[NeMo I 2020-05-07 15:15:01 callbacks:239] Step time: 0.043936967849731445 seconds\n",
      "[NeMo I 2020-05-07 15:15:02 callbacks:224] Step: 1300\n",
      "[NeMo I 2020-05-07 15:15:02 helpers:104] Loss: 0.11661899089813232\n",
      "[NeMo I 2020-05-07 15:15:02 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:15:02 callbacks:239] Step time: 0.04396557807922363 seconds\n",
      "[NeMo I 2020-05-07 15:15:04 callbacks:224] Step: 1325\n",
      "[NeMo I 2020-05-07 15:15:04 helpers:104] Loss: 0.09770214557647705\n",
      "[NeMo I 2020-05-07 15:15:04 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:15:04 callbacks:239] Step time: 0.04267072677612305 seconds\n",
      "[NeMo I 2020-05-07 15:15:05 callbacks:224] Step: 1350\n",
      "[NeMo I 2020-05-07 15:15:05 helpers:104] Loss: 0.16344493627548218\n",
      "[NeMo I 2020-05-07 15:15:05 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:15:05 callbacks:239] Step time: 0.04527640342712402 seconds\n",
      "[NeMo I 2020-05-07 15:15:06 callbacks:224] Step: 1375\n",
      "[NeMo I 2020-05-07 15:15:06 helpers:104] Loss: 0.18233907222747803\n",
      "[NeMo I 2020-05-07 15:15:06 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:15:06 callbacks:239] Step time: 0.040608882904052734 seconds\n",
      "[NeMo I 2020-05-07 15:15:07 callbacks:224] Step: 1400\n",
      "[NeMo I 2020-05-07 15:15:07 helpers:104] Loss: 0.1132921501994133\n",
      "[NeMo I 2020-05-07 15:15:07 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:07 callbacks:239] Step time: 0.04062223434448242 seconds\n",
      "[NeMo I 2020-05-07 15:15:07 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:15:08 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.06934398412704468\n",
      "[NeMo I 2020-05-07 15:15:08 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 97.7347\n",
      "[NeMo I 2020-05-07 15:15:08 callbacks:450] Evaluation time: 1.476205587387085 seconds\n",
      "[NeMo I 2020-05-07 15:15:09 callbacks:224] Step: 1425\n",
      "[NeMo I 2020-05-07 15:15:09 helpers:104] Loss: 0.13039638102054596\n",
      "[NeMo I 2020-05-07 15:15:09 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:15:09 callbacks:239] Step time: 0.04897284507751465 seconds\n",
      "[NeMo I 2020-05-07 15:15:10 callbacks:224] Step: 1450\n",
      "[NeMo I 2020-05-07 15:15:10 helpers:104] Loss: 0.3157779276371002\n",
      "[NeMo I 2020-05-07 15:15:10 helpers:110] training_batch_top@1:  86.7188\n",
      "[NeMo I 2020-05-07 15:15:10 callbacks:239] Step time: 0.04423403739929199 seconds\n",
      "[NeMo I 2020-05-07 15:15:11 callbacks:224] Step: 1475\n",
      "[NeMo I 2020-05-07 15:15:11 helpers:104] Loss: 0.11424967646598816\n",
      "[NeMo I 2020-05-07 15:15:11 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:11 callbacks:239] Step time: 0.040531158447265625 seconds\n",
      "[NeMo I 2020-05-07 15:15:13 callbacks:224] Step: 1500\n",
      "[NeMo I 2020-05-07 15:15:13 helpers:104] Loss: 0.1504301130771637\n",
      "[NeMo I 2020-05-07 15:15:13 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:13 callbacks:239] Step time: 0.05157899856567383 seconds\n",
      "[NeMo I 2020-05-07 15:15:14 callbacks:224] Step: 1525\n",
      "[NeMo I 2020-05-07 15:15:14 helpers:104] Loss: 0.2467605322599411\n",
      "[NeMo I 2020-05-07 15:15:14 helpers:110] training_batch_top@1:  89.8438\n",
      "[NeMo I 2020-05-07 15:15:14 callbacks:239] Step time: 0.04388308525085449 seconds\n",
      "[NeMo I 2020-05-07 15:15:15 callbacks:224] Step: 1550\n",
      "[NeMo I 2020-05-07 15:15:15 helpers:104] Loss: 0.24032269418239594\n",
      "[NeMo I 2020-05-07 15:15:15 helpers:110] training_batch_top@1:  90.6250\n",
      "[NeMo I 2020-05-07 15:15:15 callbacks:239] Step time: 0.04434704780578613 seconds\n",
      "[NeMo I 2020-05-07 15:15:16 callbacks:224] Step: 1575\n",
      "[NeMo I 2020-05-07 15:15:16 helpers:104] Loss: 0.22340892255306244\n",
      "[NeMo I 2020-05-07 15:15:16 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:15:16 callbacks:239] Step time: 0.043924570083618164 seconds\n",
      "[NeMo I 2020-05-07 15:15:17 callbacks:224] Step: 1600\n",
      "[NeMo I 2020-05-07 15:15:17 helpers:104] Loss: 0.1500718742609024\n",
      "[NeMo I 2020-05-07 15:15:17 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:17 callbacks:239] Step time: 0.04705619812011719 seconds\n",
      "[NeMo I 2020-05-07 15:15:17 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:15:18 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.13349078595638275\n",
      "[NeMo I 2020-05-07 15:15:18 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 95.8156\n",
      "[NeMo I 2020-05-07 15:15:18 callbacks:450] Evaluation time: 1.4354946613311768 seconds\n",
      "[NeMo I 2020-05-07 15:15:19 callbacks:224] Step: 1625\n",
      "[NeMo I 2020-05-07 15:15:19 helpers:104] Loss: 0.24598705768585205\n",
      "[NeMo I 2020-05-07 15:15:19 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:15:19 callbacks:239] Step time: 0.044823408126831055 seconds\n",
      "[NeMo I 2020-05-07 15:15:21 callbacks:224] Step: 1650\n",
      "[NeMo I 2020-05-07 15:15:21 helpers:104] Loss: 0.17547276616096497\n",
      "[NeMo I 2020-05-07 15:15:21 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:15:21 callbacks:239] Step time: 0.0406491756439209 seconds\n",
      "[NeMo I 2020-05-07 15:15:22 callbacks:224] Step: 1675\n",
      "[NeMo I 2020-05-07 15:15:22 helpers:104] Loss: 0.14865076541900635\n",
      "[NeMo I 2020-05-07 15:15:22 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:15:22 callbacks:239] Step time: 0.0407865047454834 seconds\n",
      "[NeMo I 2020-05-07 15:15:23 callbacks:224] Step: 1700\n",
      "[NeMo I 2020-05-07 15:15:23 helpers:104] Loss: 0.259771466255188\n",
      "[NeMo I 2020-05-07 15:15:23 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:15:23 callbacks:239] Step time: 0.04092717170715332 seconds\n",
      "[NeMo I 2020-05-07 15:15:24 callbacks:224] Step: 1725\n",
      "[NeMo I 2020-05-07 15:15:24 helpers:104] Loss: 0.14778085052967072\n",
      "[NeMo I 2020-05-07 15:15:24 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:24 callbacks:239] Step time: 0.04073023796081543 seconds\n",
      "[NeMo I 2020-05-07 15:15:25 callbacks:224] Step: 1750\n",
      "[NeMo I 2020-05-07 15:15:25 helpers:104] Loss: 0.2086115926504135\n",
      "[NeMo I 2020-05-07 15:15:25 helpers:110] training_batch_top@1:  92.1875\n",
      "[NeMo I 2020-05-07 15:15:25 callbacks:239] Step time: 0.039457082748413086 seconds\n",
      "[NeMo I 2020-05-07 15:15:26 callbacks:224] Step: 1775\n",
      "[NeMo I 2020-05-07 15:15:26 helpers:104] Loss: 0.10855504870414734\n",
      "[NeMo I 2020-05-07 15:15:26 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:15:26 callbacks:239] Step time: 0.0400238037109375 seconds\n",
      "[NeMo I 2020-05-07 15:15:26 callbacks:207] Finished epoch 1 in 0:00:45.401095\n",
      "[NeMo I 2020-05-07 15:15:26 callbacks:199] Starting epoch 2\n",
      "[NeMo I 2020-05-07 15:15:28 callbacks:224] Step: 1800\n",
      "[NeMo I 2020-05-07 15:15:28 helpers:104] Loss: 0.12084701657295227\n",
      "[NeMo I 2020-05-07 15:15:28 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:28 callbacks:239] Step time: 0.044687509536743164 seconds\n",
      "[NeMo I 2020-05-07 15:15:28 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:15:29 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.12121707201004028\n",
      "[NeMo I 2020-05-07 15:15:29 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 96.7607\n",
      "[NeMo I 2020-05-07 15:15:29 callbacks:450] Evaluation time: 1.5420820713043213 seconds\n",
      "[NeMo I 2020-05-07 15:15:30 callbacks:224] Step: 1825\n",
      "[NeMo I 2020-05-07 15:15:30 helpers:104] Loss: 0.12237970530986786\n",
      "[NeMo I 2020-05-07 15:15:30 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:30 callbacks:239] Step time: 0.043710947036743164 seconds\n",
      "[NeMo I 2020-05-07 15:15:31 callbacks:224] Step: 1850\n",
      "[NeMo I 2020-05-07 15:15:31 helpers:104] Loss: 0.15227821469306946\n",
      "[NeMo I 2020-05-07 15:15:31 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:31 callbacks:239] Step time: 0.04571056365966797 seconds\n",
      "[NeMo I 2020-05-07 15:15:33 callbacks:224] Step: 1875\n",
      "[NeMo I 2020-05-07 15:15:33 helpers:104] Loss: 0.1827729195356369\n",
      "[NeMo I 2020-05-07 15:15:33 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:15:33 callbacks:239] Step time: 0.04132533073425293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:15:34 callbacks:224] Step: 1900\n",
      "[NeMo I 2020-05-07 15:15:34 helpers:104] Loss: 0.2002420425415039\n",
      "[NeMo I 2020-05-07 15:15:34 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:15:34 callbacks:239] Step time: 0.04331159591674805 seconds\n",
      "[NeMo I 2020-05-07 15:15:35 callbacks:224] Step: 1925\n",
      "[NeMo I 2020-05-07 15:15:35 helpers:104] Loss: 0.2031973898410797\n",
      "[NeMo I 2020-05-07 15:15:35 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:15:35 callbacks:239] Step time: 0.043143272399902344 seconds\n",
      "[NeMo I 2020-05-07 15:15:36 callbacks:224] Step: 1950\n",
      "[NeMo I 2020-05-07 15:15:36 helpers:104] Loss: 0.1090618371963501\n",
      "[NeMo I 2020-05-07 15:15:36 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:36 callbacks:239] Step time: 0.040833234786987305 seconds\n",
      "[NeMo I 2020-05-07 15:15:37 callbacks:224] Step: 1975\n",
      "[NeMo I 2020-05-07 15:15:37 helpers:104] Loss: 0.08569393306970596\n",
      "[NeMo I 2020-05-07 15:15:37 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:15:37 callbacks:239] Step time: 0.040720462799072266 seconds\n",
      "[NeMo I 2020-05-07 15:15:38 callbacks:224] Step: 2000\n",
      "[NeMo I 2020-05-07 15:15:38 helpers:104] Loss: 0.16857895255088806\n",
      "[NeMo I 2020-05-07 15:15:38 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:38 callbacks:239] Step time: 0.04076337814331055 seconds\n",
      "[NeMo I 2020-05-07 15:15:38 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:15:39 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.07222012430429459\n",
      "[NeMo I 2020-05-07 15:15:39 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 97.5615\n",
      "[NeMo I 2020-05-07 15:15:39 callbacks:450] Evaluation time: 1.5546159744262695 seconds\n",
      "[NeMo I 2020-05-07 15:15:39 callbacks:303] Saved checkpoint: .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints/trainer-STEP-2000.pt\n",
      "[NeMo I 2020-05-07 15:15:41 callbacks:224] Step: 2025\n",
      "[NeMo I 2020-05-07 15:15:41 helpers:104] Loss: 0.24618317186832428\n",
      "[NeMo I 2020-05-07 15:15:41 helpers:110] training_batch_top@1:  89.8438\n",
      "[NeMo I 2020-05-07 15:15:41 callbacks:239] Step time: 0.0406031608581543 seconds\n",
      "[NeMo I 2020-05-07 15:15:42 callbacks:224] Step: 2050\n",
      "[NeMo I 2020-05-07 15:15:42 helpers:104] Loss: 0.1103210598230362\n",
      "[NeMo I 2020-05-07 15:15:42 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:15:42 callbacks:239] Step time: 0.041055917739868164 seconds\n",
      "[NeMo I 2020-05-07 15:15:43 callbacks:224] Step: 2075\n",
      "[NeMo I 2020-05-07 15:15:43 helpers:104] Loss: 0.1486695110797882\n",
      "[NeMo I 2020-05-07 15:15:43 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:15:43 callbacks:239] Step time: 0.0406951904296875 seconds\n",
      "[NeMo I 2020-05-07 15:15:44 callbacks:224] Step: 2100\n",
      "[NeMo I 2020-05-07 15:15:44 helpers:104] Loss: 0.09481994807720184\n",
      "[NeMo I 2020-05-07 15:15:44 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:44 callbacks:239] Step time: 0.04542207717895508 seconds\n",
      "[NeMo I 2020-05-07 15:15:45 callbacks:224] Step: 2125\n",
      "[NeMo I 2020-05-07 15:15:45 helpers:104] Loss: 0.19153282046318054\n",
      "[NeMo I 2020-05-07 15:15:45 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:45 callbacks:239] Step time: 0.04079866409301758 seconds\n",
      "[NeMo I 2020-05-07 15:15:46 callbacks:224] Step: 2150\n",
      "[NeMo I 2020-05-07 15:15:46 helpers:104] Loss: 0.10870757699012756\n",
      "[NeMo I 2020-05-07 15:15:46 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:46 callbacks:239] Step time: 0.04061603546142578 seconds\n",
      "[NeMo I 2020-05-07 15:15:47 callbacks:224] Step: 2175\n",
      "[NeMo I 2020-05-07 15:15:47 helpers:104] Loss: 0.10283950716257095\n",
      "[NeMo I 2020-05-07 15:15:47 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:47 callbacks:239] Step time: 0.04610252380371094 seconds\n",
      "[NeMo I 2020-05-07 15:15:48 callbacks:224] Step: 2200\n",
      "[NeMo I 2020-05-07 15:15:48 helpers:104] Loss: 0.12849493324756622\n",
      "[NeMo I 2020-05-07 15:15:48 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:48 callbacks:239] Step time: 0.045732736587524414 seconds\n",
      "[NeMo I 2020-05-07 15:15:48 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:15:50 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.07120270282030106\n",
      "[NeMo I 2020-05-07 15:15:50 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 97.7996\n",
      "[NeMo I 2020-05-07 15:15:50 callbacks:450] Evaluation time: 1.4331729412078857 seconds\n",
      "[NeMo I 2020-05-07 15:15:51 callbacks:224] Step: 2225\n",
      "[NeMo I 2020-05-07 15:15:51 helpers:104] Loss: 0.1980820745229721\n",
      "[NeMo I 2020-05-07 15:15:51 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:15:51 callbacks:239] Step time: 0.048070430755615234 seconds\n",
      "[NeMo I 2020-05-07 15:15:52 callbacks:224] Step: 2250\n",
      "[NeMo I 2020-05-07 15:15:52 helpers:104] Loss: 0.10248121619224548\n",
      "[NeMo I 2020-05-07 15:15:52 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:15:52 callbacks:239] Step time: 0.044321298599243164 seconds\n",
      "[NeMo I 2020-05-07 15:15:53 callbacks:224] Step: 2275\n",
      "[NeMo I 2020-05-07 15:15:53 helpers:104] Loss: 0.17686432600021362\n",
      "[NeMo I 2020-05-07 15:15:53 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:15:53 callbacks:239] Step time: 0.0452113151550293 seconds\n",
      "[NeMo I 2020-05-07 15:15:54 callbacks:224] Step: 2300\n",
      "[NeMo I 2020-05-07 15:15:54 helpers:104] Loss: 0.29510706663131714\n",
      "[NeMo I 2020-05-07 15:15:54 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:15:54 callbacks:239] Step time: 0.04999828338623047 seconds\n",
      "[NeMo I 2020-05-07 15:15:55 callbacks:224] Step: 2325\n",
      "[NeMo I 2020-05-07 15:15:55 helpers:104] Loss: 0.12475143373012543\n",
      "[NeMo I 2020-05-07 15:15:55 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:15:55 callbacks:239] Step time: 0.04774117469787598 seconds\n",
      "[NeMo I 2020-05-07 15:15:56 callbacks:224] Step: 2350\n",
      "[NeMo I 2020-05-07 15:15:56 helpers:104] Loss: 0.24854618310928345\n",
      "[NeMo I 2020-05-07 15:15:56 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:15:56 callbacks:239] Step time: 0.049581289291381836 seconds\n",
      "[NeMo I 2020-05-07 15:15:57 callbacks:224] Step: 2375\n",
      "[NeMo I 2020-05-07 15:15:57 helpers:104] Loss: 0.07531730085611343\n",
      "[NeMo I 2020-05-07 15:15:57 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:15:57 callbacks:239] Step time: 0.04277968406677246 seconds\n",
      "[NeMo I 2020-05-07 15:15:58 callbacks:224] Step: 2400\n",
      "[NeMo I 2020-05-07 15:15:58 helpers:104] Loss: 0.17620857059955597\n",
      "[NeMo I 2020-05-07 15:15:58 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:15:58 callbacks:239] Step time: 0.045278310775756836 seconds\n",
      "[NeMo I 2020-05-07 15:15:58 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:16:00 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.09246914088726044\n",
      "[NeMo I 2020-05-07 15:16:00 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 97.1286\n",
      "[NeMo I 2020-05-07 15:16:00 callbacks:450] Evaluation time: 1.443627119064331 seconds\n",
      "[NeMo I 2020-05-07 15:16:01 callbacks:224] Step: 2425\n",
      "[NeMo I 2020-05-07 15:16:01 helpers:104] Loss: 0.24871942400932312\n",
      "[NeMo I 2020-05-07 15:16:01 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:16:01 callbacks:239] Step time: 0.04388761520385742 seconds\n",
      "[NeMo I 2020-05-07 15:16:02 callbacks:224] Step: 2450\n",
      "[NeMo I 2020-05-07 15:16:02 helpers:104] Loss: 0.10014215111732483\n",
      "[NeMo I 2020-05-07 15:16:02 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:02 callbacks:239] Step time: 0.04067873954772949 seconds\n",
      "[NeMo I 2020-05-07 15:16:03 callbacks:224] Step: 2475\n",
      "[NeMo I 2020-05-07 15:16:03 helpers:104] Loss: 0.11029844731092453\n",
      "[NeMo I 2020-05-07 15:16:03 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:03 callbacks:239] Step time: 0.04421424865722656 seconds\n",
      "[NeMo I 2020-05-07 15:16:04 callbacks:224] Step: 2500\n",
      "[NeMo I 2020-05-07 15:16:04 helpers:104] Loss: 0.16866207122802734\n",
      "[NeMo I 2020-05-07 15:16:04 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:16:04 callbacks:239] Step time: 0.041597843170166016 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:16:05 callbacks:224] Step: 2525\n",
      "[NeMo I 2020-05-07 15:16:05 helpers:104] Loss: 0.10689946264028549\n",
      "[NeMo I 2020-05-07 15:16:05 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:05 callbacks:239] Step time: 0.040480613708496094 seconds\n",
      "[NeMo I 2020-05-07 15:16:06 callbacks:224] Step: 2550\n",
      "[NeMo I 2020-05-07 15:16:06 helpers:104] Loss: 0.08988360315561295\n",
      "[NeMo I 2020-05-07 15:16:06 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:06 callbacks:239] Step time: 0.04315996170043945 seconds\n",
      "[NeMo I 2020-05-07 15:16:07 callbacks:224] Step: 2575\n",
      "[NeMo I 2020-05-07 15:16:07 helpers:104] Loss: 0.05460293963551521\n",
      "[NeMo I 2020-05-07 15:16:07 helpers:110] training_batch_top@1:  99.2188\n",
      "[NeMo I 2020-05-07 15:16:07 callbacks:239] Step time: 0.04502248764038086 seconds\n",
      "[NeMo I 2020-05-07 15:16:08 callbacks:224] Step: 2600\n",
      "[NeMo I 2020-05-07 15:16:08 helpers:104] Loss: 0.08232153952121735\n",
      "[NeMo I 2020-05-07 15:16:08 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:08 callbacks:239] Step time: 0.042578935623168945 seconds\n",
      "[NeMo I 2020-05-07 15:16:08 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:16:10 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.05540851876139641\n",
      "[NeMo I 2020-05-07 15:16:10 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.2469\n",
      "[NeMo I 2020-05-07 15:16:10 callbacks:450] Evaluation time: 1.4381837844848633 seconds\n",
      "[NeMo I 2020-05-07 15:16:11 callbacks:224] Step: 2625\n",
      "[NeMo I 2020-05-07 15:16:11 helpers:104] Loss: 0.10861805826425552\n",
      "[NeMo I 2020-05-07 15:16:11 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:11 callbacks:239] Step time: 0.044283390045166016 seconds\n",
      "[NeMo I 2020-05-07 15:16:12 callbacks:224] Step: 2650\n",
      "[NeMo I 2020-05-07 15:16:12 helpers:104] Loss: 0.1220366433262825\n",
      "[NeMo I 2020-05-07 15:16:12 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:12 callbacks:239] Step time: 0.041335105895996094 seconds\n",
      "[NeMo I 2020-05-07 15:16:13 callbacks:224] Step: 2675\n",
      "[NeMo I 2020-05-07 15:16:13 helpers:104] Loss: 0.1283651739358902\n",
      "[NeMo I 2020-05-07 15:16:13 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:13 callbacks:239] Step time: 0.04171347618103027 seconds\n",
      "[NeMo I 2020-05-07 15:16:13 callbacks:207] Finished epoch 2 in 0:00:46.800629\n",
      "[NeMo I 2020-05-07 15:16:13 callbacks:199] Starting epoch 3\n",
      "[NeMo I 2020-05-07 15:16:15 callbacks:224] Step: 2700\n",
      "[NeMo I 2020-05-07 15:16:15 helpers:104] Loss: 0.1129126250743866\n",
      "[NeMo I 2020-05-07 15:16:15 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:15 callbacks:239] Step time: 0.04223012924194336 seconds\n",
      "[NeMo I 2020-05-07 15:16:16 callbacks:224] Step: 2725\n",
      "[NeMo I 2020-05-07 15:16:16 helpers:104] Loss: 0.22471824288368225\n",
      "[NeMo I 2020-05-07 15:16:16 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:16:16 callbacks:239] Step time: 0.0402524471282959 seconds\n",
      "[NeMo I 2020-05-07 15:16:17 callbacks:224] Step: 2750\n",
      "[NeMo I 2020-05-07 15:16:17 helpers:104] Loss: 0.18061688542366028\n",
      "[NeMo I 2020-05-07 15:16:17 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:17 callbacks:239] Step time: 0.047112226486206055 seconds\n",
      "[NeMo I 2020-05-07 15:16:18 callbacks:224] Step: 2775\n",
      "[NeMo I 2020-05-07 15:16:18 helpers:104] Loss: 0.21922661364078522\n",
      "[NeMo I 2020-05-07 15:16:18 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:18 callbacks:239] Step time: 0.04598593711853027 seconds\n",
      "[NeMo I 2020-05-07 15:16:19 callbacks:224] Step: 2800\n",
      "[NeMo I 2020-05-07 15:16:19 helpers:104] Loss: 0.1756233274936676\n",
      "[NeMo I 2020-05-07 15:16:19 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:19 callbacks:239] Step time: 0.040400028228759766 seconds\n",
      "[NeMo I 2020-05-07 15:16:19 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:16:21 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.06593305617570877\n",
      "[NeMo I 2020-05-07 15:16:21 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.2108\n",
      "[NeMo I 2020-05-07 15:16:21 callbacks:450] Evaluation time: 1.408510684967041 seconds\n",
      "[NeMo I 2020-05-07 15:16:22 callbacks:224] Step: 2825\n",
      "[NeMo I 2020-05-07 15:16:22 helpers:104] Loss: 0.06459734588861465\n",
      "[NeMo I 2020-05-07 15:16:22 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:22 callbacks:239] Step time: 0.04136943817138672 seconds\n",
      "[NeMo I 2020-05-07 15:16:23 callbacks:224] Step: 2850\n",
      "[NeMo I 2020-05-07 15:16:23 helpers:104] Loss: 0.08715814352035522\n",
      "[NeMo I 2020-05-07 15:16:23 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:23 callbacks:239] Step time: 0.04060506820678711 seconds\n",
      "[NeMo I 2020-05-07 15:16:24 callbacks:224] Step: 2875\n",
      "[NeMo I 2020-05-07 15:16:24 helpers:104] Loss: 0.13128700852394104\n",
      "[NeMo I 2020-05-07 15:16:24 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:24 callbacks:239] Step time: 0.040628910064697266 seconds\n",
      "[NeMo I 2020-05-07 15:16:25 callbacks:224] Step: 2900\n",
      "[NeMo I 2020-05-07 15:16:25 helpers:104] Loss: 0.19417265057563782\n",
      "[NeMo I 2020-05-07 15:16:25 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:16:25 callbacks:239] Step time: 0.044480085372924805 seconds\n",
      "[NeMo I 2020-05-07 15:16:26 callbacks:224] Step: 2925\n",
      "[NeMo I 2020-05-07 15:16:26 helpers:104] Loss: 0.18265920877456665\n",
      "[NeMo I 2020-05-07 15:16:26 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:16:26 callbacks:239] Step time: 0.04687786102294922 seconds\n",
      "[NeMo I 2020-05-07 15:16:27 callbacks:224] Step: 2950\n",
      "[NeMo I 2020-05-07 15:16:27 helpers:104] Loss: 0.11231696605682373\n",
      "[NeMo I 2020-05-07 15:16:27 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:27 callbacks:239] Step time: 0.04064774513244629 seconds\n",
      "[NeMo I 2020-05-07 15:16:28 callbacks:224] Step: 2975\n",
      "[NeMo I 2020-05-07 15:16:28 helpers:104] Loss: 0.08524055033922195\n",
      "[NeMo I 2020-05-07 15:16:28 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:16:28 callbacks:239] Step time: 0.040703535079956055 seconds\n",
      "[NeMo I 2020-05-07 15:16:29 callbacks:224] Step: 3000\n",
      "[NeMo I 2020-05-07 15:16:29 helpers:104] Loss: 0.11292848736047745\n",
      "[NeMo I 2020-05-07 15:16:29 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:29 callbacks:239] Step time: 0.04369473457336426 seconds\n",
      "[NeMo I 2020-05-07 15:16:29 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:16:31 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.059930842369794846\n",
      "[NeMo I 2020-05-07 15:16:31 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.0304\n",
      "[NeMo I 2020-05-07 15:16:31 callbacks:450] Evaluation time: 1.4665532112121582 seconds\n",
      "[NeMo I 2020-05-07 15:16:31 callbacks:303] Saved checkpoint: .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints/trainer-STEP-3000.pt\n",
      "[NeMo I 2020-05-07 15:16:32 callbacks:224] Step: 3025\n",
      "[NeMo I 2020-05-07 15:16:32 helpers:104] Loss: 0.0316426157951355\n",
      "[NeMo I 2020-05-07 15:16:32 helpers:110] training_batch_top@1:  99.2188\n",
      "[NeMo I 2020-05-07 15:16:32 callbacks:239] Step time: 0.040522098541259766 seconds\n",
      "[NeMo I 2020-05-07 15:16:33 callbacks:224] Step: 3050\n",
      "[NeMo I 2020-05-07 15:16:33 helpers:104] Loss: 0.08335485309362411\n",
      "[NeMo I 2020-05-07 15:16:33 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:33 callbacks:239] Step time: 0.040462493896484375 seconds\n",
      "[NeMo I 2020-05-07 15:16:34 callbacks:224] Step: 3075\n",
      "[NeMo I 2020-05-07 15:16:34 helpers:104] Loss: 0.13772451877593994\n",
      "[NeMo I 2020-05-07 15:16:34 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:34 callbacks:239] Step time: 0.04489326477050781 seconds\n",
      "[NeMo I 2020-05-07 15:16:35 callbacks:224] Step: 3100\n",
      "[NeMo I 2020-05-07 15:16:35 helpers:104] Loss: 0.13283835351467133\n",
      "[NeMo I 2020-05-07 15:16:35 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:35 callbacks:239] Step time: 0.043814897537231445 seconds\n",
      "[NeMo I 2020-05-07 15:16:36 callbacks:224] Step: 3125\n",
      "[NeMo I 2020-05-07 15:16:36 helpers:104] Loss: 0.12803229689598083\n",
      "[NeMo I 2020-05-07 15:16:36 helpers:110] training_batch_top@1:  95.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:16:36 callbacks:239] Step time: 0.046907663345336914 seconds\n",
      "[NeMo I 2020-05-07 15:16:37 callbacks:224] Step: 3150\n",
      "[NeMo I 2020-05-07 15:16:37 helpers:104] Loss: 0.13977688550949097\n",
      "[NeMo I 2020-05-07 15:16:37 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:37 callbacks:239] Step time: 0.04143500328063965 seconds\n",
      "[NeMo I 2020-05-07 15:16:38 callbacks:224] Step: 3175\n",
      "[NeMo I 2020-05-07 15:16:38 helpers:104] Loss: 0.14391139149665833\n",
      "[NeMo I 2020-05-07 15:16:38 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:38 callbacks:239] Step time: 0.04433631896972656 seconds\n",
      "[NeMo I 2020-05-07 15:16:39 callbacks:224] Step: 3200\n",
      "[NeMo I 2020-05-07 15:16:39 helpers:104] Loss: 0.0497245192527771\n",
      "[NeMo I 2020-05-07 15:16:39 helpers:110] training_batch_top@1:  99.2188\n",
      "[NeMo I 2020-05-07 15:16:39 callbacks:239] Step time: 0.049695491790771484 seconds\n",
      "[NeMo I 2020-05-07 15:16:39 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:16:41 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.05766056850552559\n",
      "[NeMo I 2020-05-07 15:16:41 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.3335\n",
      "[NeMo I 2020-05-07 15:16:41 callbacks:450] Evaluation time: 1.4327411651611328 seconds\n",
      "[NeMo I 2020-05-07 15:16:42 callbacks:224] Step: 3225\n",
      "[NeMo I 2020-05-07 15:16:42 helpers:104] Loss: 0.2420656383037567\n",
      "[NeMo I 2020-05-07 15:16:42 helpers:110] training_batch_top@1:  91.4062\n",
      "[NeMo I 2020-05-07 15:16:42 callbacks:239] Step time: 0.041473388671875 seconds\n",
      "[NeMo I 2020-05-07 15:16:43 callbacks:224] Step: 3250\n",
      "[NeMo I 2020-05-07 15:16:43 helpers:104] Loss: 0.06371011584997177\n",
      "[NeMo I 2020-05-07 15:16:43 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:16:43 callbacks:239] Step time: 0.04279160499572754 seconds\n",
      "[NeMo I 2020-05-07 15:16:44 callbacks:224] Step: 3275\n",
      "[NeMo I 2020-05-07 15:16:44 helpers:104] Loss: 0.07613019645214081\n",
      "[NeMo I 2020-05-07 15:16:44 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:16:44 callbacks:239] Step time: 0.04519462585449219 seconds\n",
      "[NeMo I 2020-05-07 15:16:45 callbacks:224] Step: 3300\n",
      "[NeMo I 2020-05-07 15:16:45 helpers:104] Loss: 0.08703242987394333\n",
      "[NeMo I 2020-05-07 15:16:45 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:45 callbacks:239] Step time: 0.044480323791503906 seconds\n",
      "[NeMo I 2020-05-07 15:16:46 callbacks:224] Step: 3325\n",
      "[NeMo I 2020-05-07 15:16:46 helpers:104] Loss: 0.09267021715641022\n",
      "[NeMo I 2020-05-07 15:16:46 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:46 callbacks:239] Step time: 0.04466128349304199 seconds\n",
      "[NeMo I 2020-05-07 15:16:47 callbacks:224] Step: 3350\n",
      "[NeMo I 2020-05-07 15:16:47 helpers:104] Loss: 0.15973235666751862\n",
      "[NeMo I 2020-05-07 15:16:47 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:16:47 callbacks:239] Step time: 0.04070639610290527 seconds\n",
      "[NeMo I 2020-05-07 15:16:48 callbacks:224] Step: 3375\n",
      "[NeMo I 2020-05-07 15:16:48 helpers:104] Loss: 0.10007070004940033\n",
      "[NeMo I 2020-05-07 15:16:48 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:16:48 callbacks:239] Step time: 0.043998003005981445 seconds\n",
      "[NeMo I 2020-05-07 15:16:49 callbacks:224] Step: 3400\n",
      "[NeMo I 2020-05-07 15:16:49 helpers:104] Loss: 0.08348584175109863\n",
      "[NeMo I 2020-05-07 15:16:49 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:49 callbacks:239] Step time: 0.04016447067260742 seconds\n",
      "[NeMo I 2020-05-07 15:16:49 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:16:51 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.06083636358380318\n",
      "[NeMo I 2020-05-07 15:16:51 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.0232\n",
      "[NeMo I 2020-05-07 15:16:51 callbacks:450] Evaluation time: 1.447690486907959 seconds\n",
      "[NeMo I 2020-05-07 15:16:52 callbacks:224] Step: 3425\n",
      "[NeMo I 2020-05-07 15:16:52 helpers:104] Loss: 0.10097171366214752\n",
      "[NeMo I 2020-05-07 15:16:52 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:16:52 callbacks:239] Step time: 0.040837764739990234 seconds\n",
      "[NeMo I 2020-05-07 15:16:53 callbacks:224] Step: 3450\n",
      "[NeMo I 2020-05-07 15:16:53 helpers:104] Loss: 0.11388406902551651\n",
      "[NeMo I 2020-05-07 15:16:53 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:16:53 callbacks:239] Step time: 0.04294872283935547 seconds\n",
      "[NeMo I 2020-05-07 15:16:54 callbacks:224] Step: 3475\n",
      "[NeMo I 2020-05-07 15:16:54 helpers:104] Loss: 0.10020145773887634\n",
      "[NeMo I 2020-05-07 15:16:54 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:16:54 callbacks:239] Step time: 0.0406184196472168 seconds\n",
      "[NeMo I 2020-05-07 15:16:55 callbacks:224] Step: 3500\n",
      "[NeMo I 2020-05-07 15:16:55 helpers:104] Loss: 0.13642096519470215\n",
      "[NeMo I 2020-05-07 15:16:55 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:55 callbacks:239] Step time: 0.04100823402404785 seconds\n",
      "[NeMo I 2020-05-07 15:16:56 callbacks:224] Step: 3525\n",
      "[NeMo I 2020-05-07 15:16:56 helpers:104] Loss: 0.06647752225399017\n",
      "[NeMo I 2020-05-07 15:16:56 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:16:56 callbacks:239] Step time: 0.040627241134643555 seconds\n",
      "[NeMo I 2020-05-07 15:16:57 callbacks:224] Step: 3550\n",
      "[NeMo I 2020-05-07 15:16:57 helpers:104] Loss: 0.11803070455789566\n",
      "[NeMo I 2020-05-07 15:16:57 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:16:57 callbacks:239] Step time: 0.04001903533935547 seconds\n",
      "[NeMo I 2020-05-07 15:16:58 callbacks:207] Finished epoch 3 in 0:00:44.900741\n",
      "[NeMo I 2020-05-07 15:16:58 callbacks:199] Starting epoch 4\n",
      "[NeMo I 2020-05-07 15:16:59 callbacks:224] Step: 3575\n",
      "[NeMo I 2020-05-07 15:16:59 helpers:104] Loss: 0.10971112549304962\n",
      "[NeMo I 2020-05-07 15:16:59 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:16:59 callbacks:239] Step time: 0.04479193687438965 seconds\n",
      "[NeMo I 2020-05-07 15:17:00 callbacks:224] Step: 3600\n",
      "[NeMo I 2020-05-07 15:17:00 helpers:104] Loss: 0.08547915518283844\n",
      "[NeMo I 2020-05-07 15:17:00 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:00 callbacks:239] Step time: 0.040688276290893555 seconds\n",
      "[NeMo I 2020-05-07 15:17:00 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:17:02 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.05642352253198624\n",
      "[NeMo I 2020-05-07 15:17:02 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.3840\n",
      "[NeMo I 2020-05-07 15:17:02 callbacks:450] Evaluation time: 1.5339970588684082 seconds\n",
      "[NeMo I 2020-05-07 15:17:03 callbacks:224] Step: 3625\n",
      "[NeMo I 2020-05-07 15:17:03 helpers:104] Loss: 0.21720190346240997\n",
      "[NeMo I 2020-05-07 15:17:03 helpers:110] training_batch_top@1:  92.9688\n",
      "[NeMo I 2020-05-07 15:17:03 callbacks:239] Step time: 0.0436398983001709 seconds\n",
      "[NeMo I 2020-05-07 15:17:04 callbacks:224] Step: 3650\n",
      "[NeMo I 2020-05-07 15:17:04 helpers:104] Loss: 0.08605539798736572\n",
      "[NeMo I 2020-05-07 15:17:04 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:04 callbacks:239] Step time: 0.04380202293395996 seconds\n",
      "[NeMo I 2020-05-07 15:17:05 callbacks:224] Step: 3675\n",
      "[NeMo I 2020-05-07 15:17:05 helpers:104] Loss: 0.13857519626617432\n",
      "[NeMo I 2020-05-07 15:17:05 helpers:110] training_batch_top@1:  93.7500\n",
      "[NeMo I 2020-05-07 15:17:05 callbacks:239] Step time: 0.047478437423706055 seconds\n",
      "[NeMo I 2020-05-07 15:17:06 callbacks:224] Step: 3700\n",
      "[NeMo I 2020-05-07 15:17:06 helpers:104] Loss: 0.09419677406549454\n",
      "[NeMo I 2020-05-07 15:17:06 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:06 callbacks:239] Step time: 0.0442051887512207 seconds\n",
      "[NeMo I 2020-05-07 15:17:07 callbacks:224] Step: 3725\n",
      "[NeMo I 2020-05-07 15:17:07 helpers:104] Loss: 0.08435119688510895\n",
      "[NeMo I 2020-05-07 15:17:07 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:07 callbacks:239] Step time: 0.05014467239379883 seconds\n",
      "[NeMo I 2020-05-07 15:17:08 callbacks:224] Step: 3750\n",
      "[NeMo I 2020-05-07 15:17:08 helpers:104] Loss: 0.09392467141151428\n",
      "[NeMo I 2020-05-07 15:17:08 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:08 callbacks:239] Step time: 0.041466474533081055 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:17:09 callbacks:224] Step: 3775\n",
      "[NeMo I 2020-05-07 15:17:09 helpers:104] Loss: 0.09113907068967819\n",
      "[NeMo I 2020-05-07 15:17:09 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:09 callbacks:239] Step time: 0.04052901268005371 seconds\n",
      "[NeMo I 2020-05-07 15:17:10 callbacks:224] Step: 3800\n",
      "[NeMo I 2020-05-07 15:17:10 helpers:104] Loss: 0.10832063108682632\n",
      "[NeMo I 2020-05-07 15:17:10 helpers:110] training_batch_top@1:  96.8750\n",
      "[NeMo I 2020-05-07 15:17:10 callbacks:239] Step time: 0.04409003257751465 seconds\n",
      "[NeMo I 2020-05-07 15:17:10 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:17:12 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.046951159834861755\n",
      "[NeMo I 2020-05-07 15:17:12 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.5138\n",
      "[NeMo I 2020-05-07 15:17:12 callbacks:450] Evaluation time: 1.4619972705841064 seconds\n",
      "[NeMo I 2020-05-07 15:17:13 callbacks:224] Step: 3825\n",
      "[NeMo I 2020-05-07 15:17:13 helpers:104] Loss: 0.07323834300041199\n",
      "[NeMo I 2020-05-07 15:17:13 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:13 callbacks:239] Step time: 0.04062795639038086 seconds\n",
      "[NeMo I 2020-05-07 15:17:14 callbacks:224] Step: 3850\n",
      "[NeMo I 2020-05-07 15:17:14 helpers:104] Loss: 0.0825362354516983\n",
      "[NeMo I 2020-05-07 15:17:14 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:14 callbacks:239] Step time: 0.04042959213256836 seconds\n",
      "[NeMo I 2020-05-07 15:17:15 callbacks:224] Step: 3875\n",
      "[NeMo I 2020-05-07 15:17:15 helpers:104] Loss: 0.1349354237318039\n",
      "[NeMo I 2020-05-07 15:17:15 helpers:110] training_batch_top@1:  94.5312\n",
      "[NeMo I 2020-05-07 15:17:15 callbacks:239] Step time: 0.04066205024719238 seconds\n",
      "[NeMo I 2020-05-07 15:17:16 callbacks:224] Step: 3900\n",
      "[NeMo I 2020-05-07 15:17:16 helpers:104] Loss: 0.06945277005434036\n",
      "[NeMo I 2020-05-07 15:17:16 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:16 callbacks:239] Step time: 0.05304098129272461 seconds\n",
      "[NeMo I 2020-05-07 15:17:17 callbacks:224] Step: 3925\n",
      "[NeMo I 2020-05-07 15:17:17 helpers:104] Loss: 0.09070822596549988\n",
      "[NeMo I 2020-05-07 15:17:17 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:17 callbacks:239] Step time: 0.04117178916931152 seconds\n",
      "[NeMo I 2020-05-07 15:17:18 callbacks:224] Step: 3950\n",
      "[NeMo I 2020-05-07 15:17:18 helpers:104] Loss: 0.08331187069416046\n",
      "[NeMo I 2020-05-07 15:17:18 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:18 callbacks:239] Step time: 0.04728221893310547 seconds\n",
      "[NeMo I 2020-05-07 15:17:19 callbacks:224] Step: 3975\n",
      "[NeMo I 2020-05-07 15:17:19 helpers:104] Loss: 0.05017802119255066\n",
      "[NeMo I 2020-05-07 15:17:19 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:17:19 callbacks:239] Step time: 0.041014909744262695 seconds\n",
      "[NeMo I 2020-05-07 15:17:20 callbacks:224] Step: 4000\n",
      "[NeMo I 2020-05-07 15:17:20 helpers:104] Loss: 0.06909394264221191\n",
      "[NeMo I 2020-05-07 15:17:20 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:20 callbacks:239] Step time: 0.04794931411743164 seconds\n",
      "[NeMo I 2020-05-07 15:17:20 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:17:22 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.06802641600370407\n",
      "[NeMo I 2020-05-07 15:17:22 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 97.6120\n",
      "[NeMo I 2020-05-07 15:17:22 callbacks:450] Evaluation time: 1.509591817855835 seconds\n",
      "[NeMo I 2020-05-07 15:17:22 callbacks:303] Saved checkpoint: .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints/trainer-STEP-4000.pt\n",
      "[NeMo I 2020-05-07 15:17:23 callbacks:224] Step: 4025\n",
      "[NeMo I 2020-05-07 15:17:23 helpers:104] Loss: 0.039266716688871384\n",
      "[NeMo I 2020-05-07 15:17:23 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:17:23 callbacks:239] Step time: 0.040494680404663086 seconds\n",
      "[NeMo I 2020-05-07 15:17:24 callbacks:224] Step: 4050\n",
      "[NeMo I 2020-05-07 15:17:24 helpers:104] Loss: 0.05289606750011444\n",
      "[NeMo I 2020-05-07 15:17:24 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:17:24 callbacks:239] Step time: 0.05100750923156738 seconds\n",
      "[NeMo I 2020-05-07 15:17:25 callbacks:224] Step: 4075\n",
      "[NeMo I 2020-05-07 15:17:25 helpers:104] Loss: 0.12804165482521057\n",
      "[NeMo I 2020-05-07 15:17:25 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:25 callbacks:239] Step time: 0.04368138313293457 seconds\n",
      "[NeMo I 2020-05-07 15:17:26 callbacks:224] Step: 4100\n",
      "[NeMo I 2020-05-07 15:17:26 helpers:104] Loss: 0.10640858113765717\n",
      "[NeMo I 2020-05-07 15:17:26 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:26 callbacks:239] Step time: 0.043984174728393555 seconds\n",
      "[NeMo I 2020-05-07 15:17:27 callbacks:224] Step: 4125\n",
      "[NeMo I 2020-05-07 15:17:27 helpers:104] Loss: 0.06041750684380531\n",
      "[NeMo I 2020-05-07 15:17:27 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:17:27 callbacks:239] Step time: 0.04113411903381348 seconds\n",
      "[NeMo I 2020-05-07 15:17:28 callbacks:224] Step: 4150\n",
      "[NeMo I 2020-05-07 15:17:28 helpers:104] Loss: 0.08969740569591522\n",
      "[NeMo I 2020-05-07 15:17:28 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:28 callbacks:239] Step time: 0.04403543472290039 seconds\n",
      "[NeMo I 2020-05-07 15:17:29 callbacks:224] Step: 4175\n",
      "[NeMo I 2020-05-07 15:17:29 helpers:104] Loss: 0.03646955266594887\n",
      "[NeMo I 2020-05-07 15:17:29 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:17:29 callbacks:239] Step time: 0.0403902530670166 seconds\n",
      "[NeMo I 2020-05-07 15:17:30 callbacks:224] Step: 4200\n",
      "[NeMo I 2020-05-07 15:17:30 helpers:104] Loss: 0.11153241991996765\n",
      "[NeMo I 2020-05-07 15:17:30 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:17:30 callbacks:239] Step time: 0.0404505729675293 seconds\n",
      "[NeMo I 2020-05-07 15:17:30 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:17:32 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.05421211197972298\n",
      "[NeMo I 2020-05-07 15:17:32 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.1603\n",
      "[NeMo I 2020-05-07 15:17:32 callbacks:450] Evaluation time: 1.4315314292907715 seconds\n",
      "[NeMo I 2020-05-07 15:17:33 callbacks:224] Step: 4225\n",
      "[NeMo I 2020-05-07 15:17:33 helpers:104] Loss: 0.046866126358509064\n",
      "[NeMo I 2020-05-07 15:17:33 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:33 callbacks:239] Step time: 0.05193924903869629 seconds\n",
      "[NeMo I 2020-05-07 15:17:34 callbacks:224] Step: 4250\n",
      "[NeMo I 2020-05-07 15:17:34 helpers:104] Loss: 0.1411949247121811\n",
      "[NeMo I 2020-05-07 15:17:34 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:17:34 callbacks:239] Step time: 0.042346954345703125 seconds\n",
      "[NeMo I 2020-05-07 15:17:35 callbacks:224] Step: 4275\n",
      "[NeMo I 2020-05-07 15:17:35 helpers:104] Loss: 0.10326157510280609\n",
      "[NeMo I 2020-05-07 15:17:35 helpers:110] training_batch_top@1:  96.0938\n",
      "[NeMo I 2020-05-07 15:17:35 callbacks:239] Step time: 0.04581141471862793 seconds\n",
      "[NeMo I 2020-05-07 15:17:36 callbacks:224] Step: 4300\n",
      "[NeMo I 2020-05-07 15:17:36 helpers:104] Loss: 0.020285561680793762\n",
      "[NeMo I 2020-05-07 15:17:36 helpers:110] training_batch_top@1:  100.0000\n",
      "[NeMo I 2020-05-07 15:17:36 callbacks:239] Step time: 0.04303932189941406 seconds\n",
      "[NeMo I 2020-05-07 15:17:37 callbacks:224] Step: 4325\n",
      "[NeMo I 2020-05-07 15:17:37 helpers:104] Loss: 0.08083977550268173\n",
      "[NeMo I 2020-05-07 15:17:37 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:37 callbacks:239] Step time: 0.040705204010009766 seconds\n",
      "[NeMo I 2020-05-07 15:17:38 callbacks:224] Step: 4350\n",
      "[NeMo I 2020-05-07 15:17:38 helpers:104] Loss: 0.05492332577705383\n",
      "[NeMo I 2020-05-07 15:17:38 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:38 callbacks:239] Step time: 0.04054117202758789 seconds\n",
      "[NeMo I 2020-05-07 15:17:39 callbacks:224] Step: 4375\n",
      "[NeMo I 2020-05-07 15:17:39 helpers:104] Loss: 0.06473033130168915\n",
      "[NeMo I 2020-05-07 15:17:39 helpers:110] training_batch_top@1:  98.4375\n",
      "[NeMo I 2020-05-07 15:17:39 callbacks:239] Step time: 0.04604649543762207 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-07 15:17:41 callbacks:224] Step: 4400\n",
      "[NeMo I 2020-05-07 15:17:41 helpers:104] Loss: 0.06995581835508347\n",
      "[NeMo I 2020-05-07 15:17:41 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:41 callbacks:239] Step time: 0.040346622467041016 seconds\n",
      "[NeMo I 2020-05-07 15:17:41 callbacks:445] Doing Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:17:42 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.05379670113325119\n",
      "[NeMo I 2020-05-07 15:17:42 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.1675\n",
      "[NeMo I 2020-05-07 15:17:42 callbacks:450] Evaluation time: 1.4363057613372803 seconds\n",
      "[NeMo I 2020-05-07 15:17:43 callbacks:224] Step: 4425\n",
      "[NeMo I 2020-05-07 15:17:43 helpers:104] Loss: 0.09613458812236786\n",
      "[NeMo I 2020-05-07 15:17:43 helpers:110] training_batch_top@1:  95.3125\n",
      "[NeMo I 2020-05-07 15:17:43 callbacks:239] Step time: 0.04565882682800293 seconds\n",
      "[NeMo I 2020-05-07 15:17:44 callbacks:224] Step: 4450\n",
      "[NeMo I 2020-05-07 15:17:44 helpers:104] Loss: 0.10379315912723541\n",
      "[NeMo I 2020-05-07 15:17:44 helpers:110] training_batch_top@1:  97.6562\n",
      "[NeMo I 2020-05-07 15:17:44 callbacks:239] Step time: 0.04911184310913086 seconds\n",
      "[NeMo I 2020-05-07 15:17:45 callbacks:207] Finished epoch 4 in 0:00:46.754081\n",
      "[NeMo I 2020-05-07 15:17:45 callbacks:195] Done in 0:03:50.511758\n",
      "[NeMo I 2020-05-07 15:17:45 callbacks:468] Final Evaluation ..............................\n",
      "[NeMo I 2020-05-07 15:17:46 helpers:273] ==========>>>>>>Evaluation Loss TestSet: 0.03992021083831787\n",
      "[NeMo I 2020-05-07 15:17:46 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 TestSet: 98.6365\n",
      "[NeMo I 2020-05-07 15:17:46 callbacks:473] Evaluation time: 1.4902443885803223 seconds\n",
      "[NeMo I 2020-05-07 15:17:46 callbacks:303] Saved checkpoint: .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc_prob0.8/checkpoints/trainer-STEP-4465.pt\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Now we have all the components required to train the model\n",
    "# Lets define a learning rate schedule\n",
    "\n",
    "# Define a learning rate schedule\n",
    "lr_policy = CosineAnnealing(\n",
    "    total_steps=num_epochs * steps_per_epoch,\n",
    "    warmup_ratio=0.05,\n",
    "    min_lr=0.001,\n",
    ")\n",
    "\n",
    "logging.info(f\"Using `{lr_policy}` Learning Rate Scheduler\")\n",
    "\n",
    "# Finally, lets train this model !\n",
    "neural_factory.train(\n",
    "    tensors_to_optimize=[train_loss],\n",
    "    callbacks=callbacks,\n",
    "    lr_policy=lr_policy,\n",
    "    optimizer=\"novograd\",\n",
    "    optimization_params={\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"max_steps\": None,\n",
    "        \"lr\": lr,\n",
    "        \"momentum\": 0.95,\n",
    "        \"betas\": (0.98, 0.5),\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"grad_norm_clip\": None,\n",
    "    },\n",
    "    batches_per_step=1,\n",
    ")\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232.0180184841156"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the checkpoint files\n",
    "\n",
    "base_checkpoint_path = '/home/fjia/code/NeMo-fei/examples/asr/quartznet_VAD_2balanced_o0_200ep_mfcc_prob88/results/quartznet_VAD_2balanced_o0_200ep_mfcc_prob88/1'\n",
    "# base_checkpoint_path = './quartznet_VAD_2balanced_o0_200ep_mfcc_prob88/results/quartznet_VAD_2balanced_o0_200ep_mfcc_prob88/1'\n",
    "CHECKPOINT_ENCODER = os.path.join(base_checkpoint_path, 'JasperEncoder-STEP-87000.pt')\n",
    "CHECKPOINT_DECODER = os.path.join(base_checkpoint_path, 'JasperDecoderForClassification-STEP-87000.pt')\n",
    "\n",
    "# if not os.path.exists(base_checkpoint_path):\n",
    "#     os.makedirs(base_checkpoint_path)\n",
    "    \n",
    "# if not os.path.exists(CHECKPOINT_ENCODER):\n",
    "#     !wget https://api.ngc.nvidia.com/v2/models/nvidia/google_speech_commands_v2___matchboxnet_3x1x1/versions/1/files/JasperEncoder-STEP-89000.pt -P {base_checkpoint_path};\n",
    "\n",
    "# if not os.path.exists(CHECKPOINT_DECODER):\n",
    "#     !wget https://api.ngc.nvidia.com/v2/models/nvidia/google_speech_commands_v2___matchboxnet_3x1x1/versions/1/files/JasperDecoderForClassification-STEP-89000.pt -P {base_checkpoint_path};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the checkpoint files\n",
    "\n",
    "base_checkpoint_path = '/home/fjia/code/NeMo-fei/examples/asr/quartznet_VAD_2balanced_o0_200ep_mels_prob88/results/quartznet_VAD_2balanced_o0_200ep_mels_prob88/1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = base_checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of incorrectly predicted samples\n",
    "\n",
    "Given that we have a trained model, which performs reasonably well, lets try to listen to the samples where the model is least confident in its predictions.\n",
    "\n",
    "For this, we need support of the librosa library.\n",
    "\n",
    "**NOTE**: The following code depends on librosa. To install it, run the following code block first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add a path to the checkpoint dir\n",
    "model_path = neural_factory.checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fjia/code/NeMo-fei/examples/asr/quartznet_VAD_2balanced_o0_200ep_mels_prob88/results/quartznet_VAD_2balanced_o0_200ep_mels_prob88/1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the predictions from the model\n",
    "\n",
    "We want to possess the actual logits of the model instead of just the final evaluation score, so we use `NeuralFactory.infer(...)` to extract the logits per batch of samples provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-08 17:42:02 actions:1493] Restoring JasperEncoder from /home/fjia/code/NeMo-fei/examples/asr/quartznet_VAD_2balanced_o0_200ep_mels_prob88/results/quartznet_VAD_2balanced_o0_200ep_mels_prob88/1/JasperEncoder-STEP-89400.pt\n",
      "[NeMo I 2020-05-08 17:42:02 actions:1493] Restoring JasperDecoderForClassification from /home/fjia/code/NeMo-fei/examples/asr/quartznet_VAD_2balanced_o0_200ep_mels_prob88/results/quartznet_VAD_2balanced_o0_200ep_mels_prob88/1/JasperDecoderForClassification-STEP-89400.pt\n",
      "[NeMo I 2020-05-08 17:42:02 actions:734] Evaluating batch 0 out of 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-08 17:42:03 actions:734] Evaluating batch 10 out of 109\n",
      "[NeMo I 2020-05-08 17:42:03 actions:734] Evaluating batch 20 out of 109\n",
      "[NeMo I 2020-05-08 17:42:03 actions:734] Evaluating batch 30 out of 109\n",
      "[NeMo I 2020-05-08 17:42:03 actions:734] Evaluating batch 40 out of 109\n",
      "[NeMo I 2020-05-08 17:42:03 actions:734] Evaluating batch 50 out of 109\n",
      "[NeMo I 2020-05-08 17:42:04 actions:734] Evaluating batch 60 out of 109\n",
      "[NeMo I 2020-05-08 17:42:04 actions:734] Evaluating batch 70 out of 109\n",
      "[NeMo I 2020-05-08 17:42:04 actions:734] Evaluating batch 80 out of 109\n",
      "[NeMo I 2020-05-08 17:42:04 actions:734] Evaluating batch 90 out of 109\n",
      "[NeMo I 2020-05-08 17:42:04 actions:734] Evaluating batch 100 out of 109\n"
     ]
    }
   ],
   "source": [
    "# --- Inference Only --- #\n",
    "# We've already built the inference DAG above, so all we need is to call infer().\n",
    "evaluated_tensors = neural_factory.infer(\n",
    "    # These are the tensors we want to get from the model.\n",
    "    tensors=[test_loss, test_decoded, test_labels],\n",
    "    # checkpoint_dir specifies where the model params are loaded from.\n",
    "    checkpoint_dir=model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-08 17:42:05 <ipython-input-20-674fb7de9132>:19] Total correct / Total count : 13740 / 13861\n",
      "[NeMo I 2020-05-08 17:42:05 <ipython-input-20-674fb7de9132>:20] Final accuracy : 0.9912704711059808\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for batch_idx, (logits, labels) in enumerate(zip(evaluated_tensors[1], evaluated_tensors[2])):\n",
    "    acc = classification_accuracy(\n",
    "        logits=logits,\n",
    "        targets=labels,\n",
    "        top_k=[1]\n",
    "    )\n",
    "\n",
    "    # Select top 1 accuracy only\n",
    "    acc = acc[0]\n",
    "\n",
    "    # Since accuracy here is \"per batch\", we simply denormalize it by multiplying\n",
    "    # by batch size to recover the count of correct samples.\n",
    "    correct_count += int(acc * logits.size(0))\n",
    "    total_count += logits.size(0)\n",
    "\n",
    "logging.info(f\"Total correct / Total count : {correct_count} / {total_count}\")\n",
    "logging.info(f\"Final accuracy : {correct_count / float(total_count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Recall F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo test\n",
    "from typing import List, Optional\n",
    "def binary_classification_confusion_matrix(logits: torch.Tensor, targets: torch.Tensor, top_k: Optional[List[int]] = None) -> List[float]:\n",
    "    \"\"\"\n",
    "    ]\n",
    "    [TODO]\n",
    "    \"\"\"\n",
    "    if top_k is None:\n",
    "        top_k = [1]\n",
    "    max_k = max(top_k)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        true_positive = 0\n",
    "        false_positive = 0\n",
    "        _, predictions = logits.topk(max_k, dim=1, largest=True, sorted=True)\n",
    "        predictions = predictions.t().squeeze()\n",
    "\n",
    "        # speech(command) positive | background negative\n",
    "        \n",
    "        true_negative = 0\n",
    "        false_negative = 0\n",
    "        false_positive = 0\n",
    "        true_positive = 0\n",
    "        \n",
    "        for i in range(predictions.size(-1)):\n",
    "            pred = predictions[i]\n",
    "            targ = targets[i]\n",
    "#             print(pred, targ)\n",
    "            if pred == 0 and targ == 0:\n",
    "                true_negative += 1\n",
    "            elif pred == 0 and targ == 1:\n",
    "                false_negative += 1\n",
    "            elif pred == 1 and targ == 0:\n",
    "                false_positive += 1\n",
    "            elif pred == 1 and targ == 1:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                raise ValueError('Predictions or targets not in 0/1')\n",
    "               \n",
    "                \n",
    "#         correct = predictions.eq(targets.view(1, -1)).expand_as(predictions)\n",
    "#         print(correct)\n",
    "\n",
    "#         results = []\n",
    "#         for k in top_k:\n",
    "#             correct_k = correct[:k].view(-1).float().mean().to('cpu').numpy()\n",
    "#             results.append(correct_k)\n",
    "\n",
    "#     return results\n",
    "    return true_negative, false_negative , false_positive, true_positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:17]  TN : 6814\n",
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:18]  FN : 75\n",
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:19]  FP : 46\n",
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:20]  TP : 6926\n",
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:24] Final Precision: 0.9934021801491681\n",
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:25] Final Recall : 0.9892872446793315\n",
      "[NeMo I 2020-05-08 17:42:48 <ipython-input-23-3fdd580e5c72>:26] Final F1 score : 0.991340442281543\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "# total_count = 0\n",
    "\n",
    "total_true_negative, total_false_negative , total_false_positive, total_true_positive = 0, 0, 0, 0\n",
    "for batch_idx, (logits, labels) in enumerate(zip(evaluated_tensors[1], evaluated_tensors[2])):\n",
    "    true_negative, false_negative , false_positive, true_positive = binary_classification_confusion_matrix(\n",
    "        logits=logits,\n",
    "        targets=labels,\n",
    "        top_k=[1]\n",
    "    )\n",
    "\n",
    "    total_true_negative += true_negative\n",
    "    total_false_negative += false_negative\n",
    "    total_false_positive += false_positive\n",
    "    total_true_positive  += true_positive\n",
    "\n",
    "logging.info(f\" TN : {total_true_negative}\")\n",
    "logging.info(f\" FN : {total_false_negative}\")\n",
    "logging.info(f\" FP : {total_false_positive}\")\n",
    "logging.info(f\" TP : {total_true_positive}\")\n",
    "precision = total_true_positive / (total_true_positive + total_false_positive)\n",
    "recall = total_true_positive / (total_true_positive + total_false_negative)\n",
    "f1_score =  2 * precision * recall / (precision + recall)\n",
    "logging.info(f\"Final Precision: {precision}\")\n",
    "logging.info(f\"Final Recall : {recall}\")\n",
    "logging.info(f\"Final F1 score : {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out incorrect samples\n",
    "Let us now filter out the incorrectly labeled samples from the total set of samples in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import json\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets create a utility class to remap the integer class labels to actual string label\n",
    "class ReverseMapLabel:\n",
    "    def __init__(self, data_layer: nemo_asr.AudioToSpeechLabelDataLayer):\n",
    "        self.label2id = dict(data_layer._dataset.label2id)\n",
    "        self.id2label = dict(data_layer._dataset.id2label)\n",
    "\n",
    "    def __call__(self, pred_idx, label_idx):\n",
    "        return self.id2label[pred_idx], self.id2label[label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-04 19:20:18 <ipython-input-37-6b4c4e5eff4b>:22] Num test samples : 13861\n",
      "[NeMo I 2020-05-04 19:20:18 <ipython-input-37-6b4c4e5eff4b>:23] Num errors : 208\n"
     ]
    }
   ],
   "source": [
    "# Next, lets get the indices of all the incorrectly labeled samples\n",
    "sample_idx = 0\n",
    "incorrect_preds = []\n",
    "rev_map = ReverseMapLabel(eval_data_layer)\n",
    "\n",
    "# Remember, evaluated_tensor = (loss, logits, labels)\n",
    "for batch_idx, (logits, labels) in enumerate(zip(evaluated_tensors[1], evaluated_tensors[2])):\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    probas, preds = torch.max(probs, dim=-1)\n",
    "\n",
    "    incorrect_ids = (preds != labels).nonzero()\n",
    "    for idx in incorrect_ids:\n",
    "        proba = float(probas[idx][0])\n",
    "        pred = int(preds[idx][0])\n",
    "        label = int(labels[idx][0])\n",
    "        idx = int(idx[0]) + sample_idx\n",
    "\n",
    "        incorrect_preds.append((idx, *rev_map(pred, label), proba))\n",
    "\n",
    "    sample_idx += labels.size(0)\n",
    "\n",
    "logging.info(f\"Num test samples : {total_count}\")\n",
    "logging.info(f\"Num errors : {len(incorrect_preds)}\")\n",
    "\n",
    "# First lets sort by confidence of prediction\n",
    "incorrect_preds = sorted(incorrect_preds, key=lambda x: x[-1], reverse=True) #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-04 19:20:20 <ipython-input-38-aa5f2c5e1dea>:22] Num test samples : 13861\n",
      "[NeMo I 2020-05-04 19:20:20 <ipython-input-38-aa5f2c5e1dea>:23] Num correct : 13653\n"
     ]
    }
   ],
   "source": [
    "# Next, lets get the indices of all the incorrectly labeled samples\n",
    "sample_idx = 0\n",
    "correct_preds = []\n",
    "rev_map = ReverseMapLabel(eval_data_layer)\n",
    "\n",
    "# Remember, evaluated_tensor = (loss, logits, labels)\n",
    "for batch_idx, (logits, labels) in enumerate(zip(evaluated_tensors[1], evaluated_tensors[2])):\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    probas, preds = torch.max(probs, dim=-1)\n",
    "\n",
    "    correct_ids = (preds == labels).nonzero()\n",
    "    for idx in correct_ids:\n",
    "        proba = float(probas[idx][0])\n",
    "        pred = int(preds[idx][0])\n",
    "        label = int(labels[idx][0])\n",
    "        idx = int(idx[0]) + sample_idx\n",
    "\n",
    "        correct_preds.append((idx, *rev_map(pred, label), proba))\n",
    "\n",
    "    sample_idx += labels.size(0)\n",
    "\n",
    "logging.info(f\"Num test samples : {total_count}\")\n",
    "logging.info(f\"Num correct : {len(correct_preds)}\")\n",
    "\n",
    "# First lets sort by confidence of prediction\n",
    "correct_preds = sorted(correct_preds, key=lambda x: x[-1], reverse=True) #False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine a subset of incorrect samples\n",
    "Lets print out the (test id, predicted label, ground truth label, confidence) tuple of first 20 incorrectly labeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (5887, 'commands', 'background', 0.999923825263977)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (1716, 'commands', 'background', 0.9997192025184631)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (2720, 'commands', 'background', 0.9995511174201965)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7094, 'background', 'commands', 0.9978386759757996)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (8307, 'background', 'commands', 0.9977680444717407)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (10848, 'background', 'commands', 0.9977318644523621)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (9008, 'background', 'commands', 0.9976598024368286)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (12281, 'background', 'commands', 0.9975294470787048)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (13719, 'background', 'commands', 0.9974554181098938)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7773, 'background', 'commands', 0.9973828196525574)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7975, 'background', 'commands', 0.9973467588424683)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (13711, 'background', 'commands', 0.9973164200782776)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (4642, 'commands', 'background', 0.9973112344741821)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (12871, 'background', 'commands', 0.9971923232078552)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (9336, 'background', 'commands', 0.9971566200256348)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (11968, 'background', 'commands', 0.996856689453125)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7513, 'background', 'commands', 0.9965193271636963)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (1711, 'commands', 'background', 0.9963500499725342)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (8495, 'background', 'commands', 0.9963498115539551)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (12543, 'background', 'commands', 0.9963478446006775)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (378, 'commands', 'background', 0.9963454604148865)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (558, 'commands', 'background', 0.9962843060493469)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (9329, 'background', 'commands', 0.9961477518081665)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (5183, 'commands', 'background', 0.9937565326690674)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (561, 'commands', 'background', 0.9927355051040649)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (2551, 'commands', 'background', 0.9915231466293335)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (3472, 'commands', 'background', 0.9884422421455383)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (482, 'commands', 'background', 0.9881965517997742)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (1672, 'commands', 'background', 0.9873079657554626)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (13358, 'background', 'commands', 0.985944926738739)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (5943, 'commands', 'background', 0.985089123249054)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7850, 'background', 'commands', 0.9849634766578674)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (4865, 'commands', 'background', 0.9844909310340881)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (3432, 'commands', 'background', 0.9806489944458008)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (5871, 'commands', 'background', 0.9782313704490662)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (3142, 'commands', 'background', 0.9780452251434326)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (5822, 'commands', 'background', 0.976699709892273)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (3336, 'commands', 'background', 0.9744731783866882)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (5910, 'commands', 'background', 0.9723972082138062)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (583, 'commands', 'background', 0.9723126292228699)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7234, 'background', 'commands', 0.9719521403312683)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7849, 'background', 'commands', 0.970802366733551)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (7277, 'background', 'commands', 0.9677569270133972)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (8801, 'background', 'commands', 0.9614009857177734)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (4126, 'commands', 'background', 0.9607676267623901)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (490, 'commands', 'background', 0.9604196548461914)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (8048, 'background', 'commands', 0.9575250744819641)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (6102, 'commands', 'background', 0.9525377154350281)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (1718, 'commands', 'background', 0.9501205682754517)\n",
      "[NeMo I 2020-05-04 19:20:26 <ipython-input-39-e74830bb82ce>:5] (585, 'commands', 'background', 0.9479658007621765)\n"
     ]
    }
   ],
   "source": [
    "for incorrect_sample in incorrect_preds[:50]:\n",
    "    \n",
    "#     if incorrect_sample[2] == 'background':\n",
    "#         print(incorrect_sample)\n",
    "    logging.info(str(incorrect_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a threshold below which we designate a model's prediction as \"low confidence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out how many such samples exist\n",
    "low_confidence_threshold = 0.55\n",
    "count_low_confidence = len(list(filter(lambda x: x[-1] <= low_confidence_threshold, incorrect_preds)))\n",
    "logging.info(f\"Number of low confidence predictions : {count_low_confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out how many such samples exist\n",
    "high_confidence_threshold = 0.99\n",
    "count_high_confidence = len(list(filter(lambda x: x[-1] >= high_confidence_threshold, incorrect_preds)))\n",
    "logging.info(f\"Number of high confidence predictions : {count_high_confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets hear the samples which the model has least confidence in !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets create a helper function to parse the manifest files\n",
    "def parse_manifest(manifest):\n",
    "    data = []\n",
    "    for line in manifest:\n",
    "        line = json.loads(line)\n",
    "        data.append(line)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, lets create a helper function to actually listen to certain samples\n",
    "def listen_to_file(sample_id, pred=None, label=None, proba=None):\n",
    "    # Load the audio waveform using librosa\n",
    "    filepath = test_samples[sample_id]['audio_filepath']\n",
    "    if 'offset' in test_samples[sample_id]:\n",
    "        audio, sample_rate = librosa.load(filepath,\n",
    "                                          offset = test_samples[sample_id]['offset'],\n",
    "                                          duration = test_samples[sample_id]['duration'])\n",
    "    else:\n",
    "         audio, sample_rate = librosa.load(filepath)\n",
    "\n",
    "    if pred is not None and label is not None and proba is not None:\n",
    "        logging.info(f\"filepath: {filepath}, Sample : {sample_id} Prediction : {pred} Label : {label} Confidence = {proba: 0.4f}\")\n",
    "    else:\n",
    "        \n",
    "        logging.info(f\"Sample : {sample_id}\")\n",
    "\n",
    "    return ipd.Audio(audio, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets load the test manifest into memory\n",
    "\n",
    "all_test_samples = []\n",
    "for _ in test_dataset.split(','):\n",
    "    with open(_, 'r') as test_f:\n",
    "        test_samples = test_f.readlines()\n",
    "        print(_, len(test_samples))\n",
    "       \n",
    "        all_test_samples.extend(test_samples)\n",
    "        \n",
    "test_samples = parse_manifest(all_test_samples)\n",
    "print(len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, lets listen to all the audio samples where the model made a mistake\n",
    "# Note: This list of incorrect samples may be quite large, so you may choose to subsample `incorrect_preds`\n",
    "\n",
    "for sample_id, pred, label, proba in incorrect_preds[:200]:\n",
    "    filepath = test_samples[sample_id]['audio_filepath']\n",
    "    \n",
    "    print(test_samples[sample_id])\n",
    "#     if filepath not in exist:\n",
    "    ipd.display(listen_to_file(sample_id, pred=pred, label=label, proba=proba))\n",
    "    exist.add(filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Finally, lets listen to all the audio samples where the model made a mistake\n",
    "# Note: This list of incorrect samples may be quite large, so you may choose to subsample `incorrect_preds`\n",
    "for sample_id, pred, label, proba in incorrect_preds[:count_low_confidence]:\n",
    "    ipd.display(listen_to_file(sample_id, pred=pred, label=label, proba=proba))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'audio_filepath': '/home/fjia/data/freesound_resampled/Aircraft/id_437765 G04-01_P-51FighterBy.wav', 'duration': 1.0, 'label': 'background', 'text': '_', 'offset': 2.0}\n",
    "[NeMo I 2020-04-19 22:04:47 <ipython-input-41-3d463c444dc4>:13] filepaht: /home/fjia/data/freesound_resampled/Aircraft/id_437765 G04-01_P-51FighterBy.wav, Sample : 3353 Prediction : commands Label : background Confidence =  0.9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = test_dataset\n",
    "data = []\n",
    "for line in open(data_json, 'r'):\n",
    "    data.append(json.loads(line))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wave\n",
    "sample_rate, signal = wave.read(data[0]['audio_filepath'])\n",
    "\n",
    "# make sure that sample rate is the same as expected by Jasper\n",
    "# assert sample_rate == model_definition['sample_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-05 15:38:20 collections:222] Filtered duration for loading collection is 1.173313.\n"
     ]
    }
   ],
   "source": [
    "eval_data_layer2 = nemo_asr.AudioToSpeechLabelDataLayer(\n",
    "    manifest_filepath=test_dataset,\n",
    "    sample_rate=sample_rate,\n",
    "    labels=labels,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=os.cpu_count(),\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the test graph in a similar way, reusing the above components\n",
    "## Build the test data loader and preprocess same way as train graph\n",
    "## But note, we do not add the spectrogram augmentation to the test graph !\n",
    "test_audio_signal, test_audio_signal_len, test_labels, test_label_len = eval_data_layer2()\n",
    "test_processed_signal, test_processed_signal_len = data_preprocessor(\n",
    "    input_signal=test_audio_signal, length=test_audio_signal_len\n",
    ")\n",
    "test_processed_signal, test_processed_signal_len = crop_pad_augmentation(\n",
    "    input_signal=test_processed_signal, length=test_processed_signal_len\n",
    ")\n",
    "\n",
    "# Pass the test data through the model encoder and decoder\n",
    "test_encoded, test_encoded_len = jasper_encoder(\n",
    "    audio_signal=test_processed_signal, length=test_processed_signal_len\n",
    ")\n",
    "test_decoded = jasper_decoder(encoder_output=test_encoded)\n",
    "\n",
    "# Compute test loss for visualization\n",
    "# test_loss = ce_loss(logits=test_decoded, labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-05 15:38:32 actions:1493] Restoring JasperEncoder from .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc/checkpoints/JasperEncoder-STEP-4465.pt\n",
      "[NeMo I 2020-05-05 15:38:32 actions:1493] Restoring JasperDecoderForClassification from .//home/fjia/data/freesound_resampled/quartznet-3x1-v1combo_balanced_all_Mfcc/checkpoints/JasperDecoderForClassification-STEP-4465.pt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/nemo/collections/asr/parts/dataset.py\", line 402, in __getitem__\n    t = self.label2id[sample.label]\nKeyError: 'background'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-ced599b975b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mtest_decoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# checkpoint_dir specifies where the model params are loaded from.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/nemo/core/neural_factory.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensors, checkpoint_dir, ckpt_pattern, verbose, cache, use_cache, offload_to_cpu, modules_to_restore)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0mmodules_to_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodules_to_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/nemo/backends/pytorch/actions.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensors, checkpoint_dir, ckpt_pattern, verbose, cache, use_cache, offload_to_cpu, modules_to_restore)\u001b[0m\n\u001b[1;32m   1518\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m         )\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/nemo/backends/pytorch/actions.py\u001b[0m in \u001b[0;36m_infer\u001b[0;34m(self, tensors_to_return, verbose, cache, use_cache, offload_to_cpu)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mloop_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating batch {epoch_i} out of {num_batches}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vad/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/nemo/collections/asr/parts/dataset.py\", line 402, in __getitem__\n    t = self.label2id[sample.label]\nKeyError: 'background'\n"
     ]
    }
   ],
   "source": [
    "evaluated_tensors = neural_factory.infer(\n",
    "    # These are the tensors we want to get from the model.\n",
    "    tensors=[ test_decoded, test_labels],\n",
    "    # checkpoint_dir specifies where the model params are loaded from.\n",
    "    checkpoint_dir=model_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
