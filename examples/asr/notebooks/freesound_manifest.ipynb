{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May be necessary for Linux based OS\n",
    "# !sudo apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/fjia/anaconda3/envs/vad/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "from process_vad_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import wrapt\n",
    "import inspect\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/fjia/data/freesound_resampled/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process google speech command dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data_folder = '/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have provided splited datalist. We follow that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 105835, Train: 84849, Validatoin: 9981, Test: 11005\n"
     ]
    }
   ],
   "source": [
    "process_google_speech_train(sc_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finished preparing manifest ! Skip 0 samples ===\n",
      "=== Writing 9981 to ./manifest/sc_validation_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 0 samples ===\n",
      "=== Writing 11005 to ./manifest/sc_testing_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 0 samples ===\n",
      "=== Writing 85245 to ./manifest/sc_training_manifest.json ===\n",
      "Val: Skip 0 samples. Get 9981 segments!\n",
      "Test: Skip 0 samples. Get 11005 segments!\n",
      "Train: Skip 0 samples. Get 85245 segments!\n"
     ]
    }
   ],
   "source": [
    "data_dir = sc_data_folder\n",
    "out_dir = './manifest'\n",
    "\n",
    "skip_num_val, seg_num_val = load_list_write_manifest(data_dir, out_dir, 'validation_list.txt', 'sc')\n",
    "skip_num_test, seg_num_test = load_list_write_manifest(data_dir, out_dir, 'testing_list.txt', 'sc')\n",
    "skip_num_train, seg_num_train = load_list_write_manifest(data_dir, out_dir, 'training_list.txt', 'sc')\n",
    "\n",
    "print(f'Val: Skip {skip_num_val} samples. Get {seg_num_val} segments!')\n",
    "print(f'Test: Skip {skip_num_test} samples. Get {seg_num_test} segments!')\n",
    "print(f'Train: Skip {skip_num_train} samples. Get {seg_num_train} segments!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finished preparing manifest ! Skip 0 samples ===\n",
      "=== Writing 107252 to ./manifest/100ms_sc_validation_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 0 samples ===\n",
      "=== Writing 118641 to ./manifest/100ms_sc_testing_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 0 samples ===\n",
      "=== Writing 916063 to ./manifest/100ms_sc_training_manifest.json ===\n",
      "Val: Skip 0 samples. Get 107252 segments!\n",
      "Test: Skip 0 samples. Get 118641 segments!\n",
      "Train: Skip 0 samples. Get 916063 segments!\n"
     ]
    }
   ],
   "source": [
    "data_dir = sc_data_folder\n",
    "out_dir = './manifest'\n",
    "\n",
    "skip_num_val, seg_num_val = load_list_write_manifest(data_dir, out_dir, 'validation_list.txt', '100ms_sc', 0.1, 0.1)\n",
    "skip_num_test, seg_num_test = load_list_write_manifest(data_dir, out_dir, 'testing_list.txt', '100ms_sc', 0.1, 0.1)\n",
    "skip_num_train, seg_num_train = load_list_write_manifest(data_dir, out_dir, 'training_list.txt', '100ms_sc', 0.1, 0.1)\n",
    "\n",
    "print(f'Val: Skip {skip_num_val} samples. Get {seg_num_val} segments!')\n",
    "print(f'Test: Skip {skip_num_test} samples. Get {seg_num_test} segments!')\n",
    "print(f'Train: Skip {skip_num_train} samples. Get {seg_num_train} segments!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process freesound dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fjia/data/freesound_resampled/all.txt exists. Overwrite it!\n",
      "File /home/fjia/data/freesound_resampled/background.txt exists. Overwrite it!\n",
      "File /home/fjia/data/freesound_resampled/speech.txt exists. Overwrite it!\n",
      "=== 5837 total samples! 1849 speech samples, 3988 background samples! ===\n",
      "Finished split and write to file by class !\n"
     ]
    }
   ],
   "source": [
    "split_dataset_class(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_train_val_test(data_dir, 'all.txt' 0.20 ,  0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 1849, Train: 1479, Validatoin: 185, Test: 185\n",
      "Finished split train, val and test for speech.txt. Write to files !\n",
      "Overall: 3988, Train: 3190, Validatoin: 399, Test: 399\n",
      "Finished split train, val and test for background.txt. Write to files !\n"
     ]
    }
   ],
   "source": [
    "split_train_val_test(data_dir, 'speech.txt',  0.10 ,  0.10)\n",
    "split_train_val_test(data_dir, 'background.txt',  0.10 ,  0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration = 60.0 would lead to skipping too many samples (2k/5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## freesound\n",
    "### speech inside freesound / NOT USE NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdir ./manifest does not exist. Creat directory.\n",
      "=== Finished preparing manifest ! Skip 43 samples ===\n",
      "=== Writing 2335 to ./manifest/speech_validation_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 36 samples ===\n",
      "=== Writing 2643 to ./manifest/speech_testing_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 282 samples ===\n",
      "=== Writing 19636 to ./manifest/speech_training_manifest.json ===\n",
      "Val: Skip 43 samples. Get 2335 segments!\n",
      "Test: Skip 36 samples. Get 2643 segments!\n",
      "Train: Skip 282 samples. Get 19636 segments!\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/fjia/data/freesound_resampled/'\n",
    "out_dir = './manifest'\n",
    "\n",
    "skip_num_val, seg_num_val = load_list_write_manifest(data_dir, out_dir, 'speech_validation_list.txt')\n",
    "skip_num_test, seg_num_test = load_list_write_manifest(data_dir, out_dir, 'speech_testing_list.txt')\n",
    "skip_num_train, seg_num_train = load_list_write_manifest(data_dir, out_dir, 'speech_training_list.txt')\n",
    "\n",
    "print(f'Val: Skip {skip_num_val} samples. Get {seg_num_val} segments!')\n",
    "print(f'Test: Skip {skip_num_test} samples. Get {seg_num_test} segments!')\n",
    "print(f'Train: Skip {skip_num_train} samples. Get {seg_num_train} segments!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background inside freesound / WE WANT IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finished preparing manifest ! Skip 142 samples ===\n",
      "=== Writing 71190 to ./manifest/100ms_background_validation_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 146 samples ===\n",
      "=== Writing 67828 to ./manifest/100ms_background_testing_manifest.json ===\n",
      "=== Finished preparing manifest ! Skip 1129 samples ===\n",
      "=== Writing 565503 to ./manifest/100ms_background_training_manifest.json ===\n",
      "Val: Skip 142 samples. Get 71190 segments!\n",
      "Test: Skip 146 samples. Get 67828 segments!\n",
      "Train: Skip 1129 samples. Get 565503 segments!\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/fjia/data/freesound_resampled/'\n",
    "out_dir = './manifest'\n",
    "\n",
    "skip_num_val, seg_num_val = load_list_write_manifest(data_dir, out_dir, 'background_validation_list.txt', '100ms', 0.1, 0.1)\n",
    "skip_num_test, seg_num_test = load_list_write_manifest(data_dir, out_dir, 'background_testing_list.txt', '100ms', 0.1, 0.1)\n",
    "skip_num_train, seg_num_train = load_list_write_manifest(data_dir, out_dir, 'background_training_list.txt', '100ms', 0.1, 0.1)\n",
    "\n",
    "print(f'Val: Skip {skip_num_val} samples. Get {seg_num_val} segments!')\n",
    "print(f'Test: Skip {skip_num_test} samples. Get {seg_num_test} segments!')\n",
    "print(f'Train: Skip {skip_num_train} samples. Get {seg_num_train} segments!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "files = sorted(glob.glob(data_dir + '/*/*.wav'))\n",
    "write_manifest(data_dir, files, manifest_name='noise_manifest_100', duration_max=1.0, filter_long=True, duration_limit=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct  manifest for train, val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background + Speech Command 57k, 7k, 7k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 570000 speech command to ./manifest/2balanced_100ms_sc_training_manifest.json from speech commands\n",
      "Get 70000 speech command to ./manifest/2balanced_100ms_sc_validation_manifest.json from speech commands\n",
      "Get 70000 speech command to ./manifest/2balanced_100ms_sc_testing_manifest.json from speech commands\n"
     ]
    }
   ],
   "source": [
    "sc_dir = './manifest/'\n",
    "get_clean_max_json(sc_dir, out_dir, '100ms_sc_training_manifest.json', 570000, '2balanced')\n",
    "get_clean_max_json(sc_dir, out_dir, '100ms_sc_validation_manifest.json', 70000, '2balanced')\n",
    "get_clean_max_json(sc_dir, out_dir, '100ms_sc_testing_manifest.json', 70000, '2balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 565503/570000 speech command to ./manifest/2balanced_100ms_background_training_manifest.json from speech commands\n",
      "Get 70001/70000 speech command to ./manifest/2balanced_100ms_background_validation_manifest.json from speech commands\n",
      "Get 67828/70000 speech command to ./manifest/2balanced_100ms_background_testing_manifest.json from speech commands\n"
     ]
    }
   ],
   "source": [
    "sc_dir = './manifest/'\n",
    "get_clean_max_json(sc_dir, out_dir, '100ms_background_training_manifest.json', 570000, '2balanced')\n",
    "get_clean_max_json(sc_dir, out_dir, '100ms_background_validation_manifest.json', 70000, '2balanced')\n",
    "get_clean_max_json(sc_dir, out_dir, '100ms_background_testing_manifest.json', 70000, '2balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "files = sorted(glob.glob(data_dir + '/*/*.wav'))\n",
    "write_manifest('.', files, manifest_name='noise_cls_manifest', duration_max=1.0, filter_long=True, duration_limit=10.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc_dir = '/home/fjia/NEMO/examples/asr/notebooks/google_dataset_v2/google_speech_recognition_v2/'\n",
    "get_clean_max_json(sc_dir, 'sc_train_manifest.json', 17000)\n",
    "get_clean_max_json(sc_dir, 'sc_validation_manifest.json', 2000)\n",
    "get_clean_max_json(sc_dir, 'sc_test_manifest.json', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sc_dir = '/home/fjia/NEMO/examples/asr/notebooks/manifest'\n",
    "get_clean_max_json(sc_dir, 'background_training_manifest.json', 17000)\n",
    "get_clean_max_json(sc_dir, 'background_validation_manifest.json', 2000)\n",
    "get_clean_max_json(sc_dir, 'background_testing_manifest.json', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine test json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./manifest/background_testing_manifest.json\n",
      "./manifest/2balanced_sc_testing_manifest.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13886"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_des = './manifest/all_test.json'\n",
    "manifest_to_combine  = './manifest/background_testing_manifest.json,./manifest/2balanced_sc_testing_manifest.json'\n",
    "\n",
    "combine_test_set(manifest_to_combine, combined_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24614 71475\n"
     ]
    }
   ],
   "source": [
    "data_json = os.path.join(data_dir, 'noise_manifest_100.json')\n",
    "data = []\n",
    "for line in open(data_json, 'r'):\n",
    "    data.append(json.loads(line))    \n",
    "\n",
    "speech = 0\n",
    "background = 0\n",
    "\n",
    "for i in data:\n",
    "    if i['label'] == 'speech' :\n",
    "        speech += 1\n",
    "    elif i['label'] == 'background':\n",
    "        background +=1\n",
    "    else:\n",
    "        print('something wrong!')\n",
    "        \n",
    "print(speech, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data_folder = '/home/fjia/NEMO/examples/asr/notebooks/google_dataset_v2/google_speech_recognition/v2'\n",
    "\n",
    "sc_test_manifest.json\n",
    "\n",
    "sc_train_manifest.json\n",
    "\n",
    "sc_validation_manifest.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843\n",
      "9981\n",
      "11005\n"
     ]
    }
   ],
   "source": [
    "def speech_command(sc_data_json):\n",
    "    dataset_basedir =  '/home/fjia/NEMO/examples/asr/notebooks/google_dataset_v2/google_speech_recognition_v2/'\n",
    "    data = []\n",
    "    sc_seg = 0\n",
    "    for line in open(os.path.join(dataset_basedir, sc_data_json), 'r'):\n",
    "        data.append(json.loads(line))    \n",
    "        \n",
    "    print(len(data))\n",
    "    return len(data)\n",
    "    \n",
    "train = speech_command('sc_train_manifest.json')\n",
    "val = speech_command('sc_validation_manifest.json')\n",
    "test = speech_command('sc_test_manifest.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = '/home/fjia/code/NeMo-fei/examples/asr/notebooks/manifest/all_test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/home/fjia/data/google_dataset_v2/google_speech_recognition_v2/test_manifest.json'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
