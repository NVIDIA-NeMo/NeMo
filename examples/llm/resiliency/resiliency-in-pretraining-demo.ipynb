{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63d934c-f709-4e6d-aa44-03f6b1926180",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfb9b8b-3359-4d00-88fa-abf0e24f7850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2025-02-28 20:32:58 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "      cm = get_cmap(\"Set1\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.\n",
    "\n",
    "# Required Libraries\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from functools import partial\n",
    "from typing import Any\n",
    "import torch\n",
    "\n",
    "import nemo_run as run\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "from nemo.collections import llm\n",
    "from nemo.collections.llm.recipes.callbacks.common import straggler_det_callback\n",
    "from nemo.lightning.run import plugins\n",
    "\n",
    "from crash_simulator import CrashSimulationCallback\n",
    "\n",
    "\n",
    "print(\"Required libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a19a6d-8df8-4930-bb50-d622b6b72af7",
   "metadata": {},
   "source": [
    "Define and initialize a local executor, which is used to manage distributed computing tasks. The executor encapsulates configurations for launching jobs (e.g. number of devices, environment variables, task distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8740b1b8-0f89-40a9-a361-a88a6371d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor setup complete.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"349pt\" height=\"356pt\"\n",
       " viewBox=\"0.00 0.00 349.00 356.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 352)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-352 345,-352 345,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"127.5,-37.5 127.5,-56.5 313.5,-56.5 313.5,-37.5 127.5,-37.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-37.5 127.5,-56.5 313.5,-56.5 313.5,-37.5 127.5,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"177\" y=\"-45.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"209\" y=\"-45.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> Packager</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"127.5,-18.5 127.5,-37.5 274.5,-37.5 274.5,-18.5 127.5,-18.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-18.5 127.5,-37.5 274.5,-37.5 274.5,-18.5 127.5,-18.5\"/>\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-25.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">debug</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"274.5,-18.5 274.5,-37.5 313.5,-37.5 313.5,-18.5 274.5,-18.5\"/>\n",
       "<text text-anchor=\"start\" x=\"278.5\" y=\"-25.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">False</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"127.5,0.5 127.5,-18.5 274.5,-18.5 274.5,0.5 127.5,0.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"127.5,0.5 127.5,-18.5 274.5,-18.5 274.5,0.5 127.5,0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"131.5\" y=\"-6.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">symlink_from_remote_dir</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"274.5,0.5 274.5,-18.5 313.5,-18.5 313.5,0.5 274.5,0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"278.5\" y=\"-6.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">None</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#ffc0cb\" stroke=\"transparent\" points=\"0.5,-328.5 0.5,-347.5 341.5,-347.5 341.5,-328.5 0.5,-328.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-328.5 0.5,-347.5 341.5,-347.5 341.5,-328.5 0.5,-328.5\"/>\n",
       "<text text-anchor=\"start\" x=\"112.5\" y=\"-336.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"144.5\" y=\"-336.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> LocalExecutor</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-309.5 0.5,-328.5 99.5,-328.5 99.5,-309.5 0.5,-309.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-309.5 0.5,-328.5 99.5,-328.5 99.5,-309.5 0.5,-309.5\"/>\n",
       "<text text-anchor=\"start\" x=\"46.5\" y=\"-316.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">packager</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-309.5 99.5,-328.5 341.5,-328.5 341.5,-309.5 99.5,-309.5\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"103.5,-313.5 103.5,-324.5 337.5,-324.5 337.5,-313.5 103.5,-313.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-313.5 103.5,-324.5 337.5,-324.5 337.5,-313.5 103.5,-313.5\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-290.5 0.5,-309.5 99.5,-309.5 99.5,-290.5 0.5,-290.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-290.5 0.5,-309.5 99.5,-309.5 99.5,-290.5 0.5,-290.5\"/>\n",
       "<text text-anchor=\"start\" x=\"46.5\" y=\"-297.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">launcher</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-290.5 99.5,-309.5 341.5,-309.5 341.5,-290.5 99.5,-290.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-297.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;ft&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-168.5 0.5,-290.5 99.5,-290.5 99.5,-168.5 0.5,-168.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-168.5 0.5,-290.5 99.5,-290.5 99.5,-168.5 0.5,-168.5\"/>\n",
       "<text text-anchor=\"start\" x=\"46.5\" y=\"-227\" font-family=\"Courier,monospace\" font-size=\"10.00\">env_vars</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-168.5 99.5,-290.5 341.5,-290.5 341.5,-168.5 99.5,-168.5\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"103.5,-267.5 103.5,-286.5 337.5,-286.5 337.5,-267.5 103.5,-267.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-267.5 103.5,-286.5 337.5,-286.5 337.5,-267.5 103.5,-267.5\"/>\n",
       "<text text-anchor=\"start\" x=\"208\" y=\"-274.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">dict</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"103.5,-248.5 103.5,-267.5 310.5,-267.5 310.5,-248.5 103.5,-248.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-248.5 103.5,-267.5 310.5,-267.5 310.5,-248.5 103.5,-248.5\"/>\n",
       "<text text-anchor=\"start\" x=\"173.5\" y=\"-255.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;TRANSFORMERS_OFFLINE&#39;</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"310.5,-248.5 310.5,-267.5 337.5,-267.5 337.5,-248.5 310.5,-248.5\"/>\n",
       "<text text-anchor=\"start\" x=\"314.5\" y=\"-255.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;1&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"103.5,-229.5 103.5,-248.5 310.5,-248.5 310.5,-229.5 103.5,-229.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-229.5 103.5,-248.5 310.5,-248.5 310.5,-229.5 103.5,-229.5\"/>\n",
       "<text text-anchor=\"start\" x=\"107.5\" y=\"-236.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;TORCH_NCCL_AVOID_RECORD_STREAMS&#39;</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"310.5,-229.5 310.5,-248.5 337.5,-248.5 337.5,-229.5 310.5,-229.5\"/>\n",
       "<text text-anchor=\"start\" x=\"314.5\" y=\"-236.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;1&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"103.5,-210.5 103.5,-229.5 310.5,-229.5 310.5,-210.5 103.5,-210.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-210.5 103.5,-229.5 310.5,-229.5 310.5,-210.5 103.5,-210.5\"/>\n",
       "<text text-anchor=\"start\" x=\"197.5\" y=\"-217.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;NCCL_NVLS_ENABLE&#39;</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"310.5,-210.5 310.5,-229.5 337.5,-229.5 337.5,-210.5 310.5,-210.5\"/>\n",
       "<text text-anchor=\"start\" x=\"314.5\" y=\"-217.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;0&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"103.5,-191.5 103.5,-210.5 310.5,-210.5 310.5,-191.5 103.5,-191.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-191.5 103.5,-210.5 310.5,-210.5 310.5,-191.5 103.5,-191.5\"/>\n",
       "<text text-anchor=\"start\" x=\"125.5\" y=\"-198.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;NVTE_DP_AMAX_REDUCE_INTERVAL&#39;</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"310.5,-191.5 310.5,-210.5 337.5,-210.5 337.5,-191.5 310.5,-191.5\"/>\n",
       "<text text-anchor=\"start\" x=\"314.5\" y=\"-198.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;0&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"103.5,-172.5 103.5,-191.5 310.5,-191.5 310.5,-172.5 103.5,-172.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-172.5 103.5,-191.5 310.5,-191.5 310.5,-172.5 103.5,-172.5\"/>\n",
       "<text text-anchor=\"start\" x=\"143.5\" y=\"-179.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;NVTE_ASYNC_AMAX_REDUCTION&#39;</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"310.5,-172.5 310.5,-191.5 337.5,-191.5 337.5,-172.5 310.5,-172.5\"/>\n",
       "<text text-anchor=\"start\" x=\"314.5\" y=\"-179.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;1&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-149.5 0.5,-168.5 99.5,-168.5 99.5,-149.5 0.5,-149.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-149.5 0.5,-168.5 99.5,-168.5 99.5,-149.5 0.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"52.5\" y=\"-156.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">retries</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-149.5 99.5,-168.5 341.5,-168.5 341.5,-149.5 99.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-156.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">0</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-130.5 0.5,-149.5 99.5,-149.5 99.5,-130.5 0.5,-130.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-130.5 0.5,-149.5 99.5,-149.5 99.5,-130.5 0.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"16.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">experiment_id</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-130.5 99.5,-149.5 341.5,-149.5 341.5,-130.5 99.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">None</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-111.5 0.5,-130.5 99.5,-130.5 99.5,-111.5 0.5,-111.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-111.5 0.5,-130.5 99.5,-130.5 99.5,-111.5 0.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"52.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">job_dir</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-111.5 99.5,-130.5 341.5,-130.5 341.5,-111.5 99.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-92.5 0.5,-111.5 99.5,-111.5 99.5,-92.5 0.5,-92.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-92.5 0.5,-111.5 99.5,-111.5 99.5,-92.5 0.5,-92.5\"/>\n",
       "<text text-anchor=\"start\" x=\"4.5\" y=\"-99.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">ntasks_per_node</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-92.5 99.5,-111.5 341.5,-111.5 341.5,-92.5 99.5,-92.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-99.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">8</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;1:c</title>\n",
       "<path fill=\"none\" stroke=\"#73be73\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M220.5,-313.48C220.5,-283.05 220.5,-122.31 220.5,-57.06\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "LocalExecutor(packager=Packager(debug=False, symlink_from_remote_dir=None), launcher='ft', env_vars={'TRANSFORMERS_OFFLINE': '1', 'TORCH_NCCL_AVOID_RECORD_STREAMS': '1', 'NCCL_NVLS_ENABLE': '0', 'NVTE_DP_AMAX_REDUCE_INTERVAL': '0', 'NVTE_ASYNC_AMAX_REDUCTION': '1'}, retries=0, experiment_id=None, job_dir='', experiment_dir='', _launcher_setup=False, ntasks_per_node=8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local_executor(devices: int = 2) -> run.LocalExecutor:\n",
    "    \"\"\"\n",
    "    Factory method for creating a LocalExecutor instance. \n",
    "    This sets up environment variables and configures the number of devices.\n",
    "\n",
    "    Args:\n",
    "        devices (int): Number of devices to be used per node.\n",
    "\n",
    "    Returns:\n",
    "        run.LocalExecutor: Configured local executor object.\n",
    "    \"\"\"\n",
    "    env_vars = {\n",
    "        \"TRANSFORMERS_OFFLINE\": \"1\",   # Run Transformer models offline\n",
    "        \"TORCH_NCCL_AVOID_RECORD_STREAMS\": \"1\",  # Optimize PyTorch NCCL\n",
    "        \"NCCL_NVLS_ENABLE\": \"0\",      # Experimental NCCL environment variable\n",
    "        \"NVTE_DP_AMAX_REDUCE_INTERVAL\": \"0\", \n",
    "        \"NVTE_ASYNC_AMAX_REDUCTION\": \"1\",\n",
    "    }\n",
    "    # Create LocalExecutor with the `ft` launcher\n",
    "    executor = run.LocalExecutor(ntasks_per_node=devices, launcher=\"ft\", env_vars=env_vars)\n",
    "    return executor\n",
    "\n",
    "# Initialize the executor based on the arguments\n",
    "executor = local_executor(8)\n",
    "\n",
    "print(\"Executor setup complete.\")\n",
    "executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ffd38-5f97-4001-ad86-46b686edb0e8",
   "metadata": {},
   "source": [
    "## Model Recipe Setup\n",
    "Load and configure the LLAMA pretrain recipe. We apply optional configurations\n",
    "such as:\n",
    "1. Enabling callbacks for straggler detection.\n",
    "2. Adding fault tolerance plugins.\n",
    "3. Updating training configurations for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52245a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small LLAMA3 model configuration\n",
    "# TODO: Add info on current model size and how to change model size\n",
    "def small_llama_cfg() -> llm.GPTConfig:\n",
    "    \"\"\"Small 180m model\"\"\"\n",
    "    return run.Config(\n",
    "        llm.Llama3Config8B,\n",
    "        rotary_base=500_000,\n",
    "        seq_length=128,\n",
    "        num_layers=4,\n",
    "        hidden_size=768,\n",
    "        ffn_hidden_size=2688,\n",
    "        num_attention_heads=16,\n",
    "        init_method_std=0.023,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6988ce3",
   "metadata": {},
   "source": [
    "Create a pretrain recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c99ffc-3718-4383-b77a-161f387ce302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment name\n",
    "exp_name = \"resiliency-in-pretraining-demo\"\n",
    "\n",
    "# Preliminary setup for the LLAMA pretrain recipe\n",
    "# TODO: Add info on how to change num_nodes and num_gpus_per_node\n",
    "pretrain = partial(llm.llama31_8b.pretrain_recipe, num_nodes=1, num_gpus_per_node=8)(\n",
    "    name=exp_name, dir=\"/tmp/nemo_run/checkpoints\"\n",
    ")\n",
    "# Use smaller LLAMA model for faster execution\n",
    "pretrain.model = run.Config(llm.LlamaModel, small_llama_cfg())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67639495",
   "metadata": {},
   "source": [
    "# TODO: Add info on Straggler Detection callback, Preemption Plugin, Fault Tolerance Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a1e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model recipe setup complete.\n"
     ]
    }
   ],
   "source": [
    "# use CP=1 TP=2\n",
    "pretrain.trainer.strategy.tensor_model_parallel_size = 2\n",
    "pretrain.trainer.strategy.context_parallel_size = 1\n",
    "\n",
    "# Automatically detect and mitigate stragglers during training\n",
    "pretrain.trainer.callbacks.append(straggler_det_callback(straggler_report_time_interval=1))\n",
    "\n",
    "# Add runtime plugins (e.g., preemption and fault tolerance)\n",
    "run_plugins = [plugins.PreemptionPlugin()]\n",
    "run_plugins.append(plugins.FaultTolerancePlugin())\n",
    "\n",
    "# Disable validation sanity checks to reduce startup time\n",
    "pretrain.trainer.num_sanity_val_steps = 0\n",
    "\n",
    "# Limit the number of training steps for a concise demo\n",
    "max_steps = 20\n",
    "pretrain.broadcast(max_steps=max_steps)\n",
    "pretrain.trainer.limit_val_batches = 2\n",
    "pretrain.trainer.log_every_n_steps = 1\n",
    "pretrain.trainer.val_check_interval = 10\n",
    "\n",
    "# Confirm that recipe setup is complete\n",
    "print(\"Model recipe setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716602ab-7b1a-4a6a-a50b-15ba877c0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add info on what these env variables are for\n",
    "# Setup ENV\n",
    "os.environ[\"FAULT_TOL_CFG_PATH\"] = \"/tmp/sample_job_ft_cfg.yml\"\n",
    "os.environ[\"FAULT_TOL_FINISHED_FLAG_FILE\"] = \"/tmp/sample_job_finished_flag\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae75f7-1a91-4429-bfbf-3ebe62bce123",
   "metadata": {},
   "source": [
    "## Running the Experiment\n",
    "Run the entire pretraining experiment. Depending on the arguments passed:\n",
    "- If `dryrun` is True, it performs a dry run (to validate configurations).\n",
    "- Otherwise, it launches the actual training run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03887dd7-a23b-44c9-825a-311849729531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False):\n",
    "    \"\"\"\n",
    "    Run the pretraining experiment either as a dry run or actual training.\n",
    "    \n",
    "    Args:\n",
    "        exp_name: Name of the experiment\n",
    "        pretrain: Pretrain configuration object\n",
    "        executor: Executor to run the experiment\n",
    "        run_plugins: List of runtime plugins\n",
    "        dryrun: Boolean flag to perform a dry run\n",
    "    \"\"\"\n",
    "    with run.Experiment(f\"{exp_name}\") as exp:\n",
    "        # Add the pretrain job to the experiment\n",
    "        exp.add(\n",
    "            pretrain,\n",
    "            executor=executor,\n",
    "            name=exp_name,\n",
    "            plugins=run_plugins,\n",
    "            tail_logs=True,\n",
    "        )\n",
    "\n",
    "        # Execute the experiment based on the dryrun flag\n",
    "        if dryrun:\n",
    "            print(\"Performing dry run ...\")\n",
    "            exp.dryrun()\n",
    "        else:\n",
    "            print(\"Launching training run ...\")\n",
    "            exp.run(sequential=True, detach=True)\n",
    "            print(\"Experiment executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836df0e-3a43-4dfd-9534-4633f5aa2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2943a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1740774781</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────── \u001b[0m\u001b[1;35mEntering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1740774781\u001b[0m\u001b[92m ──────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training run ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:33:01] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cannot detach from this experiment. Please keep it running until completion.</span>          <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:33:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31m Cannot detach from this experiment. Please keep it running until completion.\u001b[0m          \u001b]8;id=169399;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=908529;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\u001b\\\u001b[2m651\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job resiliency-in-pretraining-demo for experiment </span>                           <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">resiliency-in-pretraining-demo</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job resiliency-in-pretraining-demo for experiment \u001b[0m                           \u001b]8;id=640043;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=756850;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\u001b\\\u001b[2m724\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mresiliency-in-pretraining-demo\u001b[0m                                                         \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo\n",
      "Launched app: local_persistent://nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p\n",
      "AppStatus:\n",
      "    State: RUNNING\n",
      "    Num Restarts: 0\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: file:///root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment executed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment resiliency-in-pretraining-demo_1740774781 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment resiliency-in-pretraining-demo_1740774781 to finish\u001b[0m\u001b[92m ────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo_1740774781</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mresiliency-in-pretraining-demo_1740774781\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: resiliency-in-pretraining-demo-dwj3fvbzxhz5p\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mresiliency-in-pretraining-demo\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: resiliency-in-pretraining-demo-dwj3fvbzxhz5p\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job resiliency-in-pretraining-demo-dwj3fvbzxhz5p to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ining-demo/0 [2025-02-28 20:33:02,664] [WARNING] [ft_launcher@c032f989068c] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
      "ining-demo/0 [2025-02-28 20:33:02,664] [WARNING] [ft_launcher@c032f989068c] \n",
      "ining-demo/0 *****************************************\n",
      "ining-demo/0 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "ining-demo/0 *****************************************\n",
      "ining-demo/0 [2025-02-28 20:33:02,669] [INFO] [ft_launcher@c032f989068c] [default] starting workers for entrypoint: python\n",
      "ining-demo/0 [2025-02-28 20:33:02,669] [INFO] [ft_launcher@c032f989068c] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 [2025-02-28 20:33:02,964] [INFO] [ft_launcher@c032f989068c] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0   restart_count=0\n",
      "ining-demo/0   master_addr=c032f989068c\n",
      "ining-demo/0   master_port=60327\n",
      "ining-demo/0   group_rank=0\n",
      "ining-demo/0   group_world_size=1\n",
      "ining-demo/0   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 \n",
      "ining-demo/0 [2025-02-28 20:33:02,964] [INFO] [ft_launcher@c032f989068c] [default] Starting worker group\n",
      "ining-demo/0 [2025-02-28 20:33:14,272] [INFO] [ft_launcher@c032f989068c] Setting worker0 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/0/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,272] [INFO] [ft_launcher@c032f989068c] Setting worker1 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/1/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,272] [INFO] [ft_launcher@c032f989068c] Setting worker2 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/2/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,272] [INFO] [ft_launcher@c032f989068c] Setting worker3 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/3/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,272] [INFO] [ft_launcher@c032f989068c] Setting worker4 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/4/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,273] [INFO] [ft_launcher@c032f989068c] Setting worker5 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/5/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,273] [INFO] [ft_launcher@c032f989068c] Setting worker6 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/6/error.json\n",
      "ining-demo/0 [2025-02-28 20:33:14,273] [INFO] [ft_launcher@c032f989068c] Setting worker7 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_0/7/error.json\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:23 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default4]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default2]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default1]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:24 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:24 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default5]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default6]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default0]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default7]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:24 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:24 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:24 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:24 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:24 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:24 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:24 resume:228] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints. Training from scratch.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:25 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default3]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance dir: /tmp/nemo_run/checkpoints\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance client initialized. Timeouts: HeartbeatTimeouts(initial=1800.00, subsequent=300.00, were_calculated=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:33:26 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:39 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:33:39 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 0/19 | lr: 1.499e-07 | global_batch_size: 512 | global_step: 0 | reduced_train_loss: 11.03 | train_step_timing in s: 13.07\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 1/19 | lr: 2.999e-07 | global_batch_size: 512 | global_step: 1 | reduced_train_loss: 11.03 | train_step_timing in s: 5.604 | consumed_samples: 1024\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 2/19 | lr: 4.498e-07 | global_batch_size: 512 | global_step: 2 | reduced_train_loss: 11.03 | train_step_timing in s: 5.598 | consumed_samples: 1536\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 3/19 | lr: 5.997e-07 | global_batch_size: 512 | global_step: 3 | reduced_train_loss: 11.03 | train_step_timing in s: 5.59 | consumed_samples: 2048\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 4/19 | lr: 7.496e-07 | global_batch_size: 512 | global_step: 4 | reduced_train_loss: 11.03 | train_step_timing in s: 5.596 | consumed_samples: 2560\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 5/19 | lr: 8.996e-07 | global_batch_size: 512 | global_step: 5 | reduced_train_loss: 11.03 | train_step_timing in s: 5.598 | consumed_samples: 3072\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 6/19 | lr: 1.049e-06 | global_batch_size: 512 | global_step: 6 | reduced_train_loss: 11.03 | train_step_timing in s: 5.599 | consumed_samples: 3584\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 7/19 | lr: 1.199e-06 | global_batch_size: 512 | global_step: 7 | reduced_train_loss: 11.03 | train_step_timing in s: 5.657 | consumed_samples: 4096\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 8/19 | lr: 1.349e-06 | global_batch_size: 512 | global_step: 8 | reduced_train_loss: 11.03 | train_step_timing in s: 5.652 | consumed_samples: 4608\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 9/19 | lr: 1.499e-06 | global_batch_size: 512 | global_step: 9 | reduced_train_loss: 11.03 | train_step_timing in s: 5.601 | consumed_samples: 5120\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:34:31 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:34:34 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last.ckpt\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 10/19 | lr: 1.649e-06 | global_batch_size: 512 | global_step: 10 | reduced_train_loss: 11.03 | train_step_timing in s: 5.608 | consumed_samples: 5632\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:34:40 model_checkpoint:522] Async checkpoint save for step 10 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 11/19 | lr: 1.799e-06 | global_batch_size: 512 | global_step: 11 | reduced_train_loss: 11.03 | train_step_timing in s: 5.602 | consumed_samples: 6144\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 12/19 | lr: 1.949e-06 | global_batch_size: 512 | global_step: 12 | reduced_train_loss: 11.03 | train_step_timing in s: 5.606 | consumed_samples: 6656\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 13/19 | lr: 2.099e-06 | global_batch_size: 512 | global_step: 13 | reduced_train_loss: 11.03 | train_step_timing in s: 5.602 | consumed_samples: 7168\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 14/19 | lr: 2.249e-06 | global_batch_size: 512 | global_step: 14 | reduced_train_loss: 11.03 | train_step_timing in s: 5.599 | consumed_samples: 7680\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 15/19 | lr: 2.399e-06 | global_batch_size: 512 | global_step: 15 | reduced_train_loss: 11.03 | train_step_timing in s: 5.603 | consumed_samples: 8192\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:13 straggler_det_callback:144] \n",
      "ining-demo/0 [default0]:    GPU relative performance:\n",
      "ining-demo/0 [default0]:      Rank=3 Node=c032f989068c Score=0.97\n",
      "ining-demo/0 [default0]:      Rank=5 Node=c032f989068c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=4 Node=c032f989068c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=2 Node=c032f989068c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=0 Node=c032f989068c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=1 Node=c032f989068c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=7 Node=c032f989068c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=6 Node=c032f989068c Score=0.99\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:13 straggler_det_callback:153] \n",
      "ining-demo/0 [default0]:    GPU individual performance:\n",
      "ining-demo/0 [default0]:      Rank=0 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=1 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=2 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=3 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=4 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=5 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=6 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=7 Node=c032f989068c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:13 straggler_det_callback:236] Straggler report processing time: 0.051 sec.\n",
      "ining-demo/0 [default4]:[rank4]: Traceback (most recent call last):\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default4]:[rank4]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default4]:[rank4]:     exec(code, run_globals)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default4]:[rank4]:     fdl_runner_app()\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default4]:[rank4]:     raise e\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default4]:[rank4]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default4]:[rank4]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default4]:[rank4]:     return _main(\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default4]:[rank4]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default4]:[rank4]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default4]:[rank4]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default4]:[rank4]:     return callback(**use_params)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default4]:[rank4]:     fdl_fn()\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default4]:[rank4]:     return train(\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default4]:[rank4]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default4]:[rank4]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default4]:[rank4]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default4]:[rank4]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default4]:[rank4]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default4]:[rank4]:     results = self._run_stage()\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default4]:[rank4]:     self.fit_loop.run()\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default4]:[rank4]:     self.advance()\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default4]:[rank4]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default4]:[rank4]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default4]:[rank4]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default4]:[rank4]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default4]:[rank4]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default4]:[rank4]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default4]:[rank4]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default4]:[rank4]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default7]:[rank7]: Traceback (most recent call last):\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default7]:[rank7]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default7]:[rank7]:     exec(code, run_globals)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default7]:[rank7]:     fdl_runner_app()\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default7]:[rank7]:     raise e\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default7]:[rank7]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default7]:[rank7]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default7]:[rank7]:     return _main(\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default7]:[rank7]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default7]:[rank7]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default7]:[rank7]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default7]:[rank7]:     return callback(**use_params)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default7]:[rank7]:     fdl_fn()\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default7]:[rank7]:     return train(\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default7]:[rank7]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default7]:[rank7]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default7]:[rank7]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default7]:[rank7]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default7]:[rank7]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default7]:[rank7]:     results = self._run_stage()\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default7]:[rank7]:     self.fit_loop.run()\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default0]:[rank0]: Traceback (most recent call last):\n",
      "ining-demo/0 [default7]:[rank7]:     self.advance()\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default0]:[rank0]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default7]:[rank7]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default0]:[rank0]:     exec(code, run_globals)\n",
      "ining-demo/0 [default7]:[rank7]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default7]:[rank7]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default0]:[rank0]:     fdl_runner_app()\n",
      "ining-demo/0 [default7]:[rank7]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default0]:[rank0]:     raise e\n",
      "ining-demo/0 [default7]:[rank7]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default7]:[rank7]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default0]:[rank0]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default7]:[rank7]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default7]:[rank7]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default0]:[rank0]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default0]:[rank0]:     return _main(\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default0]:[rank0]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default0]:[rank0]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default0]:[rank0]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default0]:[rank0]:     return callback(**use_params)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default0]:[rank0]:     fdl_fn()\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default0]:[rank0]:     return train(\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default0]:[rank0]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default0]:[rank0]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default0]:[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default0]:[rank0]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default0]:[rank0]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default0]:[rank0]:     results = self._run_stage()\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default0]:[rank0]:     self.fit_loop.run()\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default0]:[rank0]:     self.advance()\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default0]:[rank0]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default0]:[rank0]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default0]:[rank0]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default0]:[rank0]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default0]:[rank0]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default0]:[rank0]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default0]:[rank0]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default0]:[rank0]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default1]:[rank1]: Traceback (most recent call last):\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default1]:[rank1]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default1]:[rank1]:     exec(code, run_globals)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default1]:[rank1]:     fdl_runner_app()\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default1]:[rank1]:     raise e\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default1]:[rank1]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default1]:[rank1]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default1]:[rank1]:     return _main(\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default1]:[rank1]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default1]:[rank1]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default1]:[rank1]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default1]:[rank1]:     return callback(**use_params)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default1]:[rank1]:     fdl_fn()\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default1]:[rank1]:     return train(\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default1]:[rank1]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default1]:[rank1]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default1]:[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default1]:[rank1]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default1]:[rank1]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default1]:[rank1]:     results = self._run_stage()\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default1]:[rank1]:     self.fit_loop.run()\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default1]:[rank1]:     self.advance()\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default1]:[rank1]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default1]:[rank1]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default1]:[rank1]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default1]:[rank1]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default1]:[rank1]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default1]:[rank1]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default1]:[rank1]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default1]:[rank1]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default3]:[rank3]: Traceback (most recent call last):\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default3]:[rank3]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default3]:[rank3]:     exec(code, run_globals)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default3]:[rank3]:     fdl_runner_app()\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default3]:[rank3]:     raise e\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default3]:[rank3]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default3]:[rank3]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default3]:[rank3]:     return _main(\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default3]:[rank3]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default3]:[rank3]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default3]:[rank3]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default3]:[rank3]:     return callback(**use_params)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default3]:[rank3]:     fdl_fn()\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default3]:[rank3]:     return train(\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default3]:[rank3]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default3]:[rank3]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default3]:[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default3]:[rank3]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default3]:[rank3]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default3]:[rank3]:     results = self._run_stage()\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default3]:[rank3]:     self.fit_loop.run()\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default3]:[rank3]:     self.advance()\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default3]:[rank3]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default3]:[rank3]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default3]:[rank3]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default3]:[rank3]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default3]:[rank3]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default3]:[rank3]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default3]:[rank3]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default3]:[rank3]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default5]:[rank5]: Traceback (most recent call last):\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default5]:[rank5]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default5]:[rank5]:     exec(code, run_globals)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default5]:[rank5]:     fdl_runner_app()\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default5]:[rank5]:     raise e\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default5]:[rank5]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default5]:[rank5]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default5]:[rank5]:     return _main(\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default5]:[rank5]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default5]:[rank5]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default5]:[rank5]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default5]:[rank5]:     return callback(**use_params)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default5]:[rank5]:     fdl_fn()\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default5]:[rank5]:     return train(\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default5]:[rank5]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default5]:[rank5]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default5]:[rank5]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default5]:[rank5]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default5]:[rank5]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default5]:[rank5]:     results = self._run_stage()\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default5]:[rank5]:     self.fit_loop.run()\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default5]:[rank5]:     self.advance()\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default5]:[rank5]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default5]:[rank5]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default5]:[rank5]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default5]:[rank5]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default5]:[rank5]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default5]:[rank5]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default5]:[rank5]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default5]:[rank5]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default2]:[rank2]: Traceback (most recent call last):\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default2]:[rank2]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default2]:[rank2]:     exec(code, run_globals)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default2]:[rank2]:     fdl_runner_app()\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default2]:[rank2]:     raise e\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default2]:[rank2]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default2]:[rank2]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default2]:[rank2]:     return _main(\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default2]:[rank2]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default2]:[rank2]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default2]:[rank2]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default2]:[rank2]:     return callback(**use_params)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default2]:[rank2]:     fdl_fn()\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default2]:[rank2]:     return train(\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default2]:[rank2]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default2]:[rank2]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default2]:[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default2]:[rank2]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default2]:[rank2]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default2]:[rank2]:     results = self._run_stage()\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default2]:[rank2]:     self.fit_loop.run()\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default2]:[rank2]:     self.advance()\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default2]:[rank2]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default2]:[rank2]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default2]:[rank2]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default2]:[rank2]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default2]:[rank2]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default2]:[rank2]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default2]:[rank2]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default2]:[rank2]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [default6]:[rank6]: Traceback (most recent call last):\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ining-demo/0 [default6]:[rank6]:     return _run_code(code, main_globals, None,\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ining-demo/0 [default6]:[rank6]:     exec(code, run_globals)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 66, in <module>\n",
      "ining-demo/0 [default6]:[rank6]:     fdl_runner_app()\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 338, in __call__\n",
      "ining-demo/0 [default6]:[rank6]:     raise e\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 321, in __call__\n",
      "ining-demo/0 [default6]:[rank6]:     return get_command(self)(*args, **kwargs)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
      "ining-demo/0 [default6]:[rank6]:     return self.main(*args, **kwargs)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 665, in main\n",
      "ining-demo/0 [default6]:[rank6]:     return _main(\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
      "ining-demo/0 [default6]:[rank6]:     rv = self.invoke(ctx)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
      "ining-demo/0 [default6]:[rank6]:     return ctx.invoke(self.callback, **ctx.params)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
      "ining-demo/0 [default6]:[rank6]:     return __callback(*args, **kwargs)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
      "ining-demo/0 [default6]:[rank6]:     return callback(**use_params)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/opt/NeMo-Run/src/nemo_run/core/runners/fdl_runner.py\", line 62, in fdl_direct_run\n",
      "ining-demo/0 [default6]:[rank6]:     fdl_fn()\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 150, in pretrain\n",
      "ining-demo/0 [default6]:[rank6]:     return train(\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/opt/NeMo/nemo/collections/llm/api.py\", line 107, in train\n",
      "ining-demo/0 [default6]:[rank6]:     trainer.fit(model, data)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "ining-demo/0 [default6]:[rank6]:     call._call_and_handle_interrupt(\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "ining-demo/0 [default6]:[rank6]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "ining-demo/0 [default6]:[rank6]:     return function(*args, **kwargs)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "ining-demo/0 [default6]:[rank6]:     self._run(model, ckpt_path=ckpt_path)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "ining-demo/0 [default6]:[rank6]:     results = self._run_stage()\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "ining-demo/0 [default6]:[rank6]:     self.fit_loop.run()\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "ining-demo/0 [default6]:[rank6]:     self.advance()\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "ining-demo/0 [default6]:[rank6]:     self.epoch_loop.run(self._data_fetcher)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "ining-demo/0 [default6]:[rank6]:     self.advance(data_fetcher)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/opt/NeMo/nemo/lightning/pytorch/trainer.py\", line 47, in advance\n",
      "ining-demo/0 [default6]:[rank6]:     super().advance(data_fetcher)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 269, in advance\n",
      "ining-demo/0 [default6]:[rank6]:     call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 218, in _call_callback_hooks\n",
      "ining-demo/0 [default6]:[rank6]:     fn(trainer, trainer.lightning_module, *args, **kwargs)\n",
      "ining-demo/0 [default6]:[rank6]:   File \"/gtc/NeMo/examples/llm/resiliency/crash_simulator.py\", line 26, in on_train_batch_end\n",
      "ining-demo/0 [default6]:[rank6]:     raise Exception(f\"Simulating a crash at step {self.crash_step}!\")\n",
      "ining-demo/0 [default6]:[rank6]: Exception: Simulating a crash at step 17!\n",
      "ining-demo/0 [2025-02-28 20:35:19,627] [ERROR] [ft_launcher@c032f989068c] failed (exitcode: 1) local_rank: 0 (pid: 1306) of binary: /usr/bin/python\n",
      "ining-demo/0 [2025-02-28 20:35:19,627] [INFO] [ft_launcher@c032f989068c] [default] Worker group FAILED. 3/3 attempts left; will restart worker group\n",
      "ining-demo/0 [2025-02-28 20:35:19,627] [INFO] [ft_launcher@c032f989068c] [default] Stopping worker group\n",
      "ining-demo/0 [2025-02-28 20:35:19,644] [INFO] [ft_launcher@c032f989068c] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 [2025-02-28 20:35:19,756] [INFO] [ft_launcher@c032f989068c] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0   restart_count=1\n",
      "ining-demo/0   master_addr=c032f989068c\n",
      "ining-demo/0   master_port=49595\n",
      "ining-demo/0   group_rank=0\n",
      "ining-demo/0   group_world_size=1\n",
      "ining-demo/0   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 \n",
      "ining-demo/0 [2025-02-28 20:35:19,756] [INFO] [ft_launcher@c032f989068c] [default] Starting worker group\n",
      "ining-demo/0 [2025-02-28 20:35:19,757] [INFO] [ft_launcher@c032f989068c] Setting worker0 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/0/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,757] [INFO] [ft_launcher@c032f989068c] Setting worker1 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/1/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,757] [INFO] [ft_launcher@c032f989068c] Setting worker2 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/2/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,757] [INFO] [ft_launcher@c032f989068c] Setting worker3 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/3/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,757] [INFO] [ft_launcher@c032f989068c] Setting worker4 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/4/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,757] [INFO] [ft_launcher@c032f989068c] Setting worker5 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/5/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,758] [INFO] [ft_launcher@c032f989068c] Setting worker6 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/6/error.json\n",
      "ining-demo/0 [2025-02-28 20:35:19,758] [INFO] [ft_launcher@c032f989068c] Setting worker7 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1740774781/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-dwj3fvbzxhz5p/torchelastic/resiliency-in-pretraining-demo/8051_kxvbyma2/attempt_1/7/error.json\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:28 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default6]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default5]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default3]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default7]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default2]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default0]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:30 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:30 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:30 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:30 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default1]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default4]:Setup to simulate a crash if step == 17\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:30 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance dir: /tmp/nemo_run/checkpoints\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance client initialized. Timeouts: HeartbeatTimeouts(initial=1800.00, subsequent=300.00, were_calculated=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default0]:Restoring states from the checkpoint path at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last/weights\n",
      "ining-demo/0 [default6]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default5]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default1]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default2]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default7]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default4]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default3]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default0]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:35:32 distrib_optimizer:705] Loading distributed optimizer sharded state of type fully_sharded_model_space\n",
      "ining-demo/0 [default0]:Restored all states from the checkpoint at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last/weights\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:32 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:161: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:41 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-02-28 20:35:41 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 10/19 | lr: 1.649e-06 | consumed_samples: 5632 | global_batch_size: 512 | global_step: 10 | reduced_train_loss: 11.03 | train_step_timing in s: 8.656\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 11/19 | lr: 1.799e-06 | consumed_samples: 6144 | global_batch_size: 512 | global_step: 11 | reduced_train_loss: 11.03 | train_step_timing in s: 5.65\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 12/19 | lr: 1.949e-06 | consumed_samples: 6656 | global_batch_size: 512 | global_step: 12 | reduced_train_loss: 11.03 | train_step_timing in s: 5.646\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 13/19 | lr: 2.099e-06 | consumed_samples: 7168 | global_batch_size: 512 | global_step: 13 | reduced_train_loss: 11.03 | train_step_timing in s: 5.635\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 14/19 | lr: 2.249e-06 | consumed_samples: 7680 | global_batch_size: 512 | global_step: 14 | reduced_train_loss: 11.03 | train_step_timing in s: 5.64\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 15/19 | lr: 2.399e-06 | consumed_samples: 8192 | global_batch_size: 512 | global_step: 15 | reduced_train_loss: 11.03 | train_step_timing in s: 5.663\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 16/19 | lr: 2.549e-06 | consumed_samples: 8704 | global_batch_size: 512 | global_step: 16 | reduced_train_loss: 11.03 | train_step_timing in s: 5.651\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 17/19 | lr: 2.699e-06 | consumed_samples: 9216 | global_batch_size: 512 | global_step: 17 | reduced_train_loss: 11.03 | train_step_timing in s: 5.648\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 18/19 | lr: 2.849e-06 | consumed_samples: 9728 | global_batch_size: 512 | global_step: 18 | reduced_train_loss: 11.03 | train_step_timing in s: 5.646\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 19/19 | lr: 2.999e-06 | consumed_samples: 10240 | global_batch_size: 512 | global_step: 19 | reduced_train_loss: 11.03 | train_step_timing in s: 5.648\n",
      "ining-demo/0 [default0]:[NeMo I 2025-02-28 20:36:36 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=19-consumed_samples=10240.0-last.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Enable a crash simulation callback\n",
    "pretrain.trainer.callbacks.append(run.Config(CrashSimulationCallback, crash_step=17))\n",
    "\n",
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3acd19-c456-4a81-a933-12f11032bfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
