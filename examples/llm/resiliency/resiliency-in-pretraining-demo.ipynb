{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63d934c-f709-4e6d-aa44-03f6b1926180",
   "metadata": {},
   "source": [
    "# Resilient LLM Training with NeMo Framework\n",
    "\n",
    "This notebook demonstrates how to use NeMo's resiliency features for robust LLM training. It covers:\n",
    "\n",
    "1. **Crash Recovery**: Using in-job restart capabilities to automatically recover from failures during training\n",
    "2. **Straggler Detection**: Identifying and handling slow/stuck processes in distributed training\n",
    "3. **Checkpointing**: Implementing asynchronous checkpointing for efficient model saving\n",
    "\n",
    "The demo uses a small LLaMA model and simulated crashes to showcase these features in action. We'll walk through:\n",
    "- Setting up a local executor with fault tolerance enabled\n",
    "- Configuring the straggler detection callbacks\n",
    "- Launching distributed training with resiliency features\n",
    "- Monitoring training progress and recovery from failures\n",
    "- Analyzing logs and checkpoints\n",
    "\n",
    "This demonstrates how NeMo makes LLM training more robust and production-ready by handling common failure modes automatically.\n",
    "\n",
    "NeMo Framework integrates resiliency features from the [NVIDIA Resiliency Extension](https://github.com/NVIDIA/nvidia-resiliency-ext) to minimize training disruptions and handle failures gracefully.\n",
    "\n",
    "The key features include\n",
    "- Fault Tolerance: Automatically resumes training from the last checkpoint in case of interruptions.\n",
    "- Straggler Detection: Identifies and mitigates slow-performing nodes to ensure efficient training.\n",
    "\n",
    "For detailed documentation on these resiliency features, see the [NeMo Framework Resiliency Guide](https://docs.nvidia.com/nemo-framework/user-guide/latest/resiliency.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f9cea8-a917-4c81-b80e-4fc52ce3359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# delete old checkpoints and prepare for a fresh run\n",
    "rm -rf /tmp/nemo_run/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a6466-45a4-4987-a5ac-10cdd4dbaf86",
   "metadata": {},
   "source": [
    "# 1. Setup a simple training job and demostrate successful training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfb9b8b-3359-4d00-88fa-abf0e24f7850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2025-03-07 00:01:19 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "      cm = get_cmap(\"Set1\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.\n",
    "\n",
    "# Required Libraries\n",
    "import argparse\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "from functools import partial\n",
    "from typing import Any\n",
    "import torch\n",
    "\n",
    "import nemo_run as run\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "from nemo.collections import llm\n",
    "from nemo.collections.llm.recipes.callbacks.common import straggler_det_callback\n",
    "from nemo.lightning.run import plugins\n",
    "\n",
    "from crash_simulator import CrashSimulationCallback\n",
    "from preemption_simulator import PreemptionSimulationCallback\n",
    "\n",
    "print(\"Required libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a19a6d-8df8-4930-bb50-d622b6b72af7",
   "metadata": {},
   "source": [
    "## 1.1 Define the executor\n",
    "\n",
    "Define and initialize a local executor, which is used to manage distributed computing tasks. The executor encapsulates configurations for launching jobs (e.g. number of devices, environment variables, task distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8740b1b8-0f89-40a9-a361-a88a6371d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor setup complete.\n"
     ]
    }
   ],
   "source": [
    "def local_executor(devices: int = 8) -> run.LocalExecutor:\n",
    "    \"\"\"\n",
    "    Factory method for creating a LocalExecutor instance. \n",
    "    This sets up environment variables and configures the number of devices.\n",
    "\n",
    "    Args:\n",
    "        devices (int): Number of devices to be used per node.\n",
    "\n",
    "    Returns:\n",
    "        run.LocalExecutor: Configured local executor object.\n",
    "    \"\"\"\n",
    "    env_vars = {\n",
    "        \"TRANSFORMERS_OFFLINE\": \"1\",   # Run Transformer models offline\n",
    "        \"TORCH_NCCL_AVOID_RECORD_STREAMS\": \"1\",  # Optimize PyTorch NCCL\n",
    "        \"NCCL_NVLS_ENABLE\": \"0\",      # Experimental NCCL environment variable\n",
    "        \"NVTE_DP_AMAX_REDUCE_INTERVAL\": \"0\", \n",
    "        \"NVTE_ASYNC_AMAX_REDUCTION\": \"1\",\n",
    "    }\n",
    "    # Create LocalExecutor with the `ft` launcher\n",
    "    executor = run.LocalExecutor(ntasks_per_node=devices, launcher=\"torchrun\", env_vars=env_vars)\n",
    "    return executor\n",
    "\n",
    "# Initialize the executor based on the arguments\n",
    "executor = local_executor(devices=8)\n",
    "\n",
    "print(\"Executor setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ffd38-5f97-4001-ad86-46b686edb0e8",
   "metadata": {},
   "source": [
    "## 1.2 Model setup\n",
    "Load and configure a LLAMA pretrain recipe. We choose a small 54M parameter llama3 based model for faster execution. This model is obtained by reducing the sequence length, number of layers, hidden size and number of attention heads from the original llama3 8B model configuration as defined in the [Llama3Config8B class](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/gpt/model/llama.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52245a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small LLAMA3 model configuration\n",
    "def small_llama_cfg() -> llm.GPTConfig:\n",
    "    \"\"\"Small 54M parameter model\"\"\"\n",
    "    return run.Config(\n",
    "        llm.Llama3Config8B,\n",
    "        rotary_base=500_000,\n",
    "        seq_length=128,\n",
    "        num_layers=4,\n",
    "        hidden_size=768,\n",
    "        ffn_hidden_size=2688,\n",
    "        num_attention_heads=16,\n",
    "        init_method_std=0.023,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6988ce3",
   "metadata": {},
   "source": [
    "## 1.3 Modify the training recipe\n",
    "`pretrain` is a partial function that takes in the experiment name and checkpoint directory, and returns a pretrain recipe. It is setup to use `num_nodes=1` and `num_gpus_per_node=8` by default but this can be changed by modifying the `num_nodes` and `num_gpus_per_node` arguments. This demo uses the llama3 8b pretrain recipe as defined in the `llama31_8b.pretrain_recipe` [module](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes/llama3_8b.py). This defaults to using a mock dataset: [MockDataModule](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/gpt/data/mock.py) but please refer to the [Llama3_8b recipe](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes/llama3_8b.py) for instructions on how to use a custom dataset. Since we are using a mock dataset, we set the `max_steps` to 20 so we can run the experiment in a reasonable time.\n",
    "\n",
    "We also disable validation sanity checks to reduce startup time, and set tensor model parallel size to 2 and context parallel size to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c99ffc-3718-4383-b77a-161f387ce302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model recipe setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Experiment name\n",
    "exp_name = \"resiliency-in-pretraining-demo\"\n",
    "\n",
    "# Preliminary setup for the LLAMA pretrain recipe\n",
    "pretrain = partial(llm.llama31_8b.pretrain_recipe, num_nodes=1, num_gpus_per_node=8)(\n",
    "    name=exp_name, dir=\"/tmp/nemo_run/checkpoints\"\n",
    ")\n",
    "pretrain.model = run.Config(llm.LlamaModel, small_llama_cfg())\n",
    "pretrain.trainer.strategy.tensor_model_parallel_size = 2\n",
    "pretrain.trainer.strategy.context_parallel_size = 1\n",
    "pretrain.trainer.num_sanity_val_steps = 0\n",
    "pretrain.broadcast(max_steps=20)\n",
    "pretrain.trainer.limit_val_batches = 2\n",
    "pretrain.trainer.log_every_n_steps = 1\n",
    "pretrain.trainer.val_check_interval = 10\n",
    "print(\"Model recipe setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae75f7-1a91-4429-bfbf-3ebe62bce123",
   "metadata": {},
   "source": [
    "## 1.4 Running the Experiment\n",
    "Run the entire pretraining experiment. Depending on the arguments passed:\n",
    "- If `dryrun` is True, it performs a dry run (to validate configurations).\n",
    "- Otherwise, it launches the actual training run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03887dd7-a23b-44c9-825a-311849729531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False):\n",
    "    \"\"\"\n",
    "    Run the pretraining experiment either as a dry run or actual training.\n",
    "    \n",
    "    Args:\n",
    "        exp_name: Name of the experiment\n",
    "        pretrain: Pretrain configuration object\n",
    "        executor: Executor to run the experiment\n",
    "        run_plugins: List of runtime plugins\n",
    "        dryrun: Boolean flag to perform a dry run\n",
    "    \"\"\"\n",
    "    with run.Experiment(f\"{exp_name}\") as exp:\n",
    "        # Add the pretrain job to the experiment\n",
    "        exp.add(\n",
    "            pretrain,\n",
    "            executor=executor,\n",
    "            name=exp_name,\n",
    "            plugins=run_plugins,\n",
    "            tail_logs=True,\n",
    "        )\n",
    "\n",
    "        # Execute the experiment based on the dryrun flag\n",
    "        if dryrun:\n",
    "            print(\"Performing dry run ...\")\n",
    "            exp.dryrun()\n",
    "        else:\n",
    "            print(\"Launching training run ...\")\n",
    "            exp.run(sequential=True, detach=True)\n",
    "            print(\"Experiment executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998265d-628a-4a68-bfd2-c40c107c2a43",
   "metadata": {},
   "source": [
    "Note: This run genrally fails the first time around since we are using a Mock dataset and it cannot find the tokenizer files. So the error is usually `FileNotFoundError: [Errno 2] No such file or directory: 'gpt2-merges.txt'`.\n",
    "\n",
    "To avoid this, you can manually download the following files before launching a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a817a6-61dc-4122-8a03-dade66d0cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-03-07 00:01:21--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.177.241, 52.217.81.254, 52.217.92.142, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.177.241|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1042301 (1018K) [application/json]\n",
      "Saving to: ‘gpt2-vocab.json’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4%  829K 1s\n",
      "    50K .......... .......... .......... .......... ..........  9%  811K 1s\n",
      "   100K .......... .......... .......... .......... .......... 14%  200M 1s\n",
      "   150K .......... .......... .......... .......... .......... 19%  809K 1s\n",
      "   200K .......... .......... .......... .......... .......... 24%  147M 1s\n",
      "   250K .......... .......... .......... .......... .......... 29%  218M 0s\n",
      "   300K .......... .......... .......... .......... .......... 34%  277M 0s\n",
      "   350K .......... .......... .......... .......... .......... 39%  830K 0s\n",
      "   400K .......... .......... .......... .......... .......... 44% 99.4M 0s\n",
      "   450K .......... .......... .......... .......... .......... 49%  229M 0s\n",
      "   500K .......... .......... .......... .......... .......... 54%  169M 0s\n",
      "   550K .......... .......... .......... .......... .......... 58%  207M 0s\n",
      "   600K .......... .......... .......... .......... .......... 63%  226M 0s\n",
      "   650K .......... .......... .......... .......... .......... 68%  250M 0s\n",
      "   700K .......... .......... .......... .......... .......... 73%  837K 0s\n",
      "   750K .......... .......... .......... .......... .......... 78%  159M 0s\n",
      "   800K .......... .......... .......... .......... .......... 83% 86.0M 0s\n",
      "   850K .......... .......... .......... .......... .......... 88%  221M 0s\n",
      "   900K .......... .......... .......... .......... .......... 93%  261M 0s\n",
      "   950K .......... .......... .......... .......... .......... 98%  274M 0s\n",
      "  1000K .......... .......                                    100%  274M=0.3s\n",
      "\n",
      "2025-03-07 00:01:21 (3.23 MB/s) - ‘gpt2-vocab.json’ saved [1042301/1042301]\n",
      "\n",
      "--2025-03-07 00:01:21--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.81.254, 52.217.92.142, 52.217.125.184, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.81.254|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456318 (446K) [text/plain]\n",
      "Saving to: ‘gpt2-merges.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 11%  813K 0s\n",
      "    50K .......... .......... .......... .......... .......... 22%  817K 0s\n",
      "   100K .......... .......... .......... .......... .......... 33%  823K 0s\n",
      "   150K .......... .......... .......... .......... .......... 44% 86.5M 0s\n",
      "   200K .......... .......... .......... .......... .......... 56% 69.2M 0s\n",
      "   250K .......... .......... .......... .......... .......... 67% 78.0M 0s\n",
      "   300K .......... .......... .......... .......... .......... 78%  842K 0s\n",
      "   350K .......... .......... .......... .......... .......... 89% 97.1M 0s\n",
      "   400K .......... .......... .......... .......... .....     100%  221M=0.2s\n",
      "\n",
      "2025-03-07 00:01:22 (1.77 MB/s) - ‘gpt2-merges.txt’ saved [456318/456318]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p /root/.cache/torch/megatron\n",
    "wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json && mv gpt2-vocab.json /root/.cache/torch/megatron/megatron-gpt-345m_vocab\n",
    "wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt && mv gpt2-merges.txt /root/.cache/torch/megatron/megatron-gpt-345m_merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2836df0e-3a43-4dfd-9534-4633f5aa2441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741305682</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────── \u001b[0m\u001b[1;35mEntering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741305682\u001b[0m\u001b[92m ──────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training run ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:01:22] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cannot detach from this experiment. Please keep it running until completion.</span>          <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:01:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31m Cannot detach from this experiment. Please keep it running until completion.\u001b[0m          \u001b]8;id=850733;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=140805;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\u001b\\\u001b[2m651\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741305682/resiliency-in-pretraining-demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job resiliency-in-pretraining-demo for experiment </span>                           <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">resiliency-in-pretraining-demo</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job resiliency-in-pretraining-demo for experiment \u001b[0m                           \u001b]8;id=67174;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=30947;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\u001b\\\u001b[2m724\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mresiliency-in-pretraining-demo\u001b[0m                                                         \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741305682/resiliency-in-pretraining-demo\n",
      "Launched app: local_persistent://nemo_run/resiliency-in-pretraining-demo-x54gdq5j1b53jc\n",
      "AppStatus:\n",
      "    State: RUNNING\n",
      "    Num Restarts: 0\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: file:///root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741305682/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-x54gdq5j1b53jc\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment executed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment resiliency-in-pretraining-demo_1741305682 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment resiliency-in-pretraining-demo_1741305682 to finish\u001b[0m\u001b[92m ────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo_1741305682</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mresiliency-in-pretraining-demo_1741305682\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: resiliency-in-pretraining-demo-x54gdq5j1b53jc\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741305682/resiliency-in-pretraining-demo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mresiliency-in-pretraining-demo\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: resiliency-in-pretraining-demo-x54gdq5j1b53jc\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741305682/resiliency-in-pretraining-demo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job resiliency-in-pretraining-demo-x54gdq5j1b53jc to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ining-demo/0 W0307 00:01:24.135000 174947 torch/distributed/run.py:793] \n",
      "ining-demo/0 W0307 00:01:24.135000 174947 torch/distributed/run.py:793] *****************************************\n",
      "ining-demo/0 W0307 00:01:24.135000 174947 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "ining-demo/0 W0307 00:01:24.135000 174947 torch/distributed/run.py:793] *****************************************\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194] Starting elastic_operator with launch configs:\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   entrypoint       : nemo_run.core.runners.fdl_runner\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   min_nodes        : 1\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   max_nodes        : 1\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   nproc_per_node   : 8\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   run_id           : 3858\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   rdzv_backend     : c10d\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   rdzv_endpoint    : localhost:0\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   rdzv_configs     : {'timeout': 900}\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   max_restarts     : 0\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   monitor_interval : 0.1\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   log_dir          : /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741305682/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-x54gdq5j1b53jc/torchelastic/resiliency-in-pretraining-demo\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194]   metrics_cfg      : {}\n",
      "ining-demo/0 I0307 00:01:24.135000 174947 torch/distributed/launcher/api.py:194] \n",
      "ining-demo/0 I0307 00:01:24.141000 174947 torch/distributed/elastic/agent/server/api.py:845] [default] starting workers for entrypoint: python\n",
      "ining-demo/0 I0307 00:01:24.141000 174947 torch/distributed/elastic/agent/server/api.py:662] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   master_addr=localhost\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   master_port=38465\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:525] \n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/api.py:670] [default] Starting worker group\n",
      "ining-demo/0 I0307 00:01:24.436000 174947 torch/distributed/elastic/agent/server/local_elastic_agent.py:291] use_agent_store: True\n",
      "ining-demo/0 I0307 00:01:24.437000 174947 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "ining-demo/0 I0307 00:01:24.437000 174947 torch/distributed/elastic/agent/server/local_elastic_agent.py:229] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:01:33 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:34 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:34 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:34 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:34 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:01:34 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:01:34 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:01:34 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:01:34 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:01:34 resume:228] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints. Training from scratch.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:35 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:01:37 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:02:04 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:02:04 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 0/19 | lr: 1.499e-07 | global_batch_size: 512 | global_step: 0 | reduced_train_loss: 11.03 | train_step_timing in s: 27.73\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 1/19 | lr: 2.999e-07 | global_batch_size: 512 | global_step: 1 | reduced_train_loss: 11.03 | train_step_timing in s: 24.07 | consumed_samples: 1024\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 2/19 | lr: 4.498e-07 | global_batch_size: 512 | global_step: 2 | reduced_train_loss: 11.03 | train_step_timing in s: 24.15 | consumed_samples: 1536\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 3/19 | lr: 5.997e-07 | global_batch_size: 512 | global_step: 3 | reduced_train_loss: 11.03 | train_step_timing in s: 24.12 | consumed_samples: 2048\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 4/19 | lr: 7.496e-07 | global_batch_size: 512 | global_step: 4 | reduced_train_loss: 11.03 | train_step_timing in s: 24.1 | consumed_samples: 2560\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 5/19 | lr: 8.996e-07 | global_batch_size: 512 | global_step: 5 | reduced_train_loss: 11.03 | train_step_timing in s: 24.04 | consumed_samples: 3072\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 6/19 | lr: 1.049e-06 | global_batch_size: 512 | global_step: 6 | reduced_train_loss: 11.03 | train_step_timing in s: 24.09 | consumed_samples: 3584\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 7/19 | lr: 1.199e-06 | global_batch_size: 512 | global_step: 7 | reduced_train_loss: 11.03 | train_step_timing in s: 24.01 | consumed_samples: 4096\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 8/19 | lr: 1.349e-06 | global_batch_size: 512 | global_step: 8 | reduced_train_loss: 11.03 | train_step_timing in s: 24.12 | consumed_samples: 4608\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 9/19 | lr: 1.499e-06 | global_batch_size: 512 | global_step: 9 | reduced_train_loss: 11.03 | train_step_timing in s: 24.16 | consumed_samples: 5120\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:05:44 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:05:47 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last.ckpt\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 10/19 | lr: 1.649e-06 | global_batch_size: 512 | global_step: 10 | reduced_train_loss: 11.03 | train_step_timing in s: 23.87 | consumed_samples: 5632\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:06:11 model_checkpoint:522] Async checkpoint save for step 10 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 11/19 | lr: 1.799e-06 | global_batch_size: 512 | global_step: 11 | reduced_train_loss: 11.03 | train_step_timing in s: 20.29 | consumed_samples: 6144\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 12/19 | lr: 1.949e-06 | global_batch_size: 512 | global_step: 12 | reduced_train_loss: 11.03 | train_step_timing in s: 16.75 | consumed_samples: 6656\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 13/19 | lr: 2.099e-06 | global_batch_size: 512 | global_step: 13 | reduced_train_loss: 11.03 | train_step_timing in s: 21.8 | consumed_samples: 7168\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 14/19 | lr: 2.249e-06 | global_batch_size: 512 | global_step: 14 | reduced_train_loss: 11.03 | train_step_timing in s: 17.19 | consumed_samples: 7680\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 15/19 | lr: 2.399e-06 | global_batch_size: 512 | global_step: 15 | reduced_train_loss: 11.03 | train_step_timing in s: 17.19 | consumed_samples: 8192\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 16/19 | lr: 2.549e-06 | global_batch_size: 512 | global_step: 16 | reduced_train_loss: 11.03 | train_step_timing in s: 17.36 | consumed_samples: 8704\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 17/19 | lr: 2.699e-06 | global_batch_size: 512 | global_step: 17 | reduced_train_loss: 11.03 | train_step_timing in s: 17.16 | consumed_samples: 9216\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 18/19 | lr: 2.849e-06 | global_batch_size: 512 | global_step: 18 | reduced_train_loss: 11.03 | train_step_timing in s: 17.24 | consumed_samples: 9728\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:08:37 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:08:37 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=18-consumed_samples=9728.0-last.ckpt\n",
      "ining-demo/0 [default0]:Training epoch 1, iteration 0/19 | lr: 2.999e-06 | global_batch_size: 512 | global_step: 19 | reduced_train_loss: 11.03 | train_step_timing in s: 17.32 | consumed_samples: 10240\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:08:55 model_checkpoint:522] Async checkpoint save for step 19 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=18-consumed_samples=9728.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [default0]:`Trainer.fit` stopped: `max_steps=20` reached.\n",
      "ining-demo/0 I0307 00:09:01.625000 174947 torch/distributed/elastic/agent/server/api.py:864] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "ining-demo/0 I0307 00:09:01.626000 174947 torch/distributed/elastic/agent/server/api.py:917] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "ining-demo/0 I0307 00:09:01.626000 174947 torch/distributed/elastic/agent/server/api.py:931] Done waiting for other agents. Elapsed: 0.0003993511199951172 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job resiliency-in-pretraining-demo-x54gdq5j1b53jc finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']</span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo_1741305682\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo_1741305682\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status resiliency-in-pretraining-demo_1741305682</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs resiliency-in-pretraining-demo_1741305682 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel resiliency-in-pretraining-demo_1741305682 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741305682\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741305682\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741305682\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins=[], dryrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029deebc-505f-4609-a274-38825bb91971",
   "metadata": {},
   "source": [
    "## 1.5 Cleanup and save clean states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf0f185-b943-4050-b74d-6d8a4c0333bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# delete old checkpoints\n",
    "rm -rf /tmp/nemo_run/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57feef98-da24-4ac5-b218-9dad6249d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Config[TimingCallback()]>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_trainer_callbacks = copy.deepcopy(pretrain.trainer.callbacks)\n",
    "pretrain_trainer_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a72081-6f2e-46e7-9bec-2122b1d45acf",
   "metadata": {},
   "source": [
    "# 2. Demostrate Fault tolerance with crash detection and in-job restart\n",
    "The [Fault Tolerance plugin](https://github.com/NVIDIA/NeMo/blob/main/nemo/lightning/run/plugins.py)\n",
    "- Detects hangs/crashes during training and relaunches the training job without manual intervention\n",
    "- It uses NVIDIA Resiliency Extension's `ft_launcher` which has been integrated into [NeMo-Run](https://github.com/NVIDIA/NeMo-Run) as [FaultTolerance](https://github.com/NVIDIA/NeMo-Run/blob/main/nemo_run/core/execution/launcher.py).\n",
    "- It also uses the `FaultToleranceCallback` from NVIDIA Resiliency Extension which sets up the heartbeats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c0e6b-551b-46d9-8c3e-73626c5ab147",
   "metadata": {},
   "source": [
    "## 2.1 Setup FaultTolerancePlugin\n",
    "These env vars need to be set as well -\n",
    "- `FAULT_TOL_CFG_PATH` is the path to the fault tolerance config file. If it is empty, default configuration is used\n",
    "- `FAULT_TOL_FINISHED_FLAG_FILE` is the path where the fault tolerance package writes when a run is successfully completed so as to not trigger a re-launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a1e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FaultTolerancePlugin plugin and setup required env vars\n",
    "run_plugins = [plugins.FaultTolerancePlugin()]\n",
    "\n",
    "os.environ[\"FAULT_TOL_CFG_PATH\"] = \"/tmp/sample_job_ft_cfg.yml\"\n",
    "os.environ[\"FAULT_TOL_FINISHED_FLAG_FILE\"] = \"/tmp/sample_job_finished_flag\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88a1a5",
   "metadata": {},
   "source": [
    "## 2.2 Setup the crash simulator and run the experiment\n",
    "We use the `CrashSimulationCallback` to simulate a crash during training. This callback is configured to crash the process at step 17 if a crash has not already occurred.\n",
    "\n",
    "Expected workflow:\n",
    "- Start training: Trainer Step counter = 0\n",
    "- After 10 trainer steps: Trainer Step counter = 10 -> save checkpoint\n",
    "- After 17 trainer steps: Trainer Step counter = 17 -> crash simulated, set `has_simulated_crash_happened` to `True`\n",
    "- Automatic in-job restart from checkpoint at step 10: Trainer step counter = 10\n",
    "- After 17 trainer steps:Trainer Step counter = 17 -> no crash simulated as `has_simulated_crash_happened == True`\n",
    "- After 20 trainer steps: Trainer Step counter = 20 -> successfully completes training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2943a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306839</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────── \u001b[0m\u001b[1;35mEntering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306839\u001b[0m\u001b[92m ──────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training run ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:20:39] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cannot detach from this experiment. Please keep it running until completion.</span>          <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:20:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31m Cannot detach from this experiment. Please keep it running until completion.\u001b[0m          \u001b]8;id=984708;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=64344;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\u001b\\\u001b[2m651\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job resiliency-in-pretraining-demo for experiment </span>                           <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">resiliency-in-pretraining-demo</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job resiliency-in-pretraining-demo for experiment \u001b[0m                           \u001b]8;id=522030;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=233572;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\u001b\\\u001b[2m724\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mresiliency-in-pretraining-demo\u001b[0m                                                         \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo\n",
      "Launched app: local_persistent://nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz\n",
      "AppStatus:\n",
      "    State: RUNNING\n",
      "    Num Restarts: 0\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: file:///root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment executed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment resiliency-in-pretraining-demo_1741306839 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment resiliency-in-pretraining-demo_1741306839 to finish\u001b[0m\u001b[92m ────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo_1741306839</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mresiliency-in-pretraining-demo_1741306839\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: resiliency-in-pretraining-demo-m41jprq0v5zdz\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mresiliency-in-pretraining-demo\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: resiliency-in-pretraining-demo-m41jprq0v5zdz\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job resiliency-in-pretraining-demo-m41jprq0v5zdz to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ining-demo/0 [2025-03-07 00:20:41,075] [WARNING] [ft_launcher@efc34a2bee7c] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
      "ining-demo/0 [2025-03-07 00:20:41,075] [WARNING] [ft_launcher@efc34a2bee7c] \n",
      "ining-demo/0 *****************************************\n",
      "ining-demo/0 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "ining-demo/0 *****************************************\n",
      "ining-demo/0 [2025-03-07 00:20:41,080] [INFO] [ft_launcher@efc34a2bee7c] [default] starting workers for entrypoint: python\n",
      "ining-demo/0 [2025-03-07 00:20:41,080] [INFO] [ft_launcher@efc34a2bee7c] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 [2025-03-07 00:20:41,120] [INFO] [ft_launcher@efc34a2bee7c] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0   restart_count=0\n",
      "ining-demo/0   master_addr=efc34a2bee7c\n",
      "ining-demo/0   master_port=39031\n",
      "ining-demo/0   group_rank=0\n",
      "ining-demo/0   group_world_size=1\n",
      "ining-demo/0   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 \n",
      "ining-demo/0 [2025-03-07 00:20:41,121] [INFO] [ft_launcher@efc34a2bee7c] [default] Starting worker group\n",
      "ining-demo/0 [2025-03-07 00:20:52,530] [INFO] [ft_launcher@efc34a2bee7c] Setting worker0 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/0/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,530] [INFO] [ft_launcher@efc34a2bee7c] Setting worker1 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/1/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,530] [INFO] [ft_launcher@efc34a2bee7c] Setting worker2 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/2/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,530] [INFO] [ft_launcher@efc34a2bee7c] Setting worker3 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/3/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,530] [INFO] [ft_launcher@efc34a2bee7c] Setting worker4 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/4/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,530] [INFO] [ft_launcher@efc34a2bee7c] Setting worker5 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/5/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,531] [INFO] [ft_launcher@efc34a2bee7c] Setting worker6 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/6/error.json\n",
      "ining-demo/0 [2025-03-07 00:20:52,531] [INFO] [ft_launcher@efc34a2bee7c] Setting worker7 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306839/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-m41jprq0v5zdz/torchelastic/resiliency-in-pretraining-demo/7376_3x25ktyj/attempt_0/7/error.json\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:01 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default2]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default2]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default2]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default7]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default7]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default7]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:02 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:02 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default0]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default0]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default1]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default1]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default1]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default5]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default5]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default5]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:03 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:03 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:03 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:03 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:03 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default4]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default4]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default4]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default6]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default6]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default6]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default3]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default3]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default3]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance dir: /tmp/nemo_run/checkpoints\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance client initialized. Timeouts: HeartbeatTimeouts(initial=1800.00, subsequent=300.00, were_calculated=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:04 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default0]:Restoring states from the checkpoint path at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=3-consumed_samples=2048.0-last/weights\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default0]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:05 distrib_optimizer:705] Loading distributed optimizer sharded state of type fully_sharded_model_space\n",
      "ining-demo/0 [default1]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default5]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default5]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default1]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default2]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default7]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default2]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default7]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default4]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default4]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default6]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default3]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default6]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default3]:Resuming from checkpoint, setting has_simulated_crash_happened to True!\n",
      "ining-demo/0 [default0]:Restored all states from the checkpoint at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=3-consumed_samples=2048.0-last/weights\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:05 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:161: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:13 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:13 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 4/19 | lr: 7.496e-07 | consumed_samples: 2560 | global_batch_size: 512 | global_step: 4 | reduced_train_loss: 11.03 | train_step_timing in s: 8.46\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 5/19 | lr: 8.996e-07 | consumed_samples: 3072 | global_batch_size: 512 | global_step: 5 | reduced_train_loss: 11.03 | train_step_timing in s: 5.641\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 6/19 | lr: 1.049e-06 | consumed_samples: 3584 | global_batch_size: 512 | global_step: 6 | reduced_train_loss: 11.03 | train_step_timing in s: 5.633\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 7/19 | lr: 1.199e-06 | consumed_samples: 4096 | global_batch_size: 512 | global_step: 7 | reduced_train_loss: 11.03 | train_step_timing in s: 5.625\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 8/19 | lr: 1.349e-06 | consumed_samples: 4608 | global_batch_size: 512 | global_step: 8 | reduced_train_loss: 11.03 | train_step_timing in s: 5.673\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 9/19 | lr: 1.499e-06 | consumed_samples: 5120 | global_batch_size: 512 | global_step: 9 | reduced_train_loss: 11.03 | train_step_timing in s: 5.628\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 10/19 | lr: 1.649e-06 | consumed_samples: 5632 | global_batch_size: 512 | global_step: 10 | reduced_train_loss: 11.03 | train_step_timing in s: 5.642\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:21:49 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:51 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=10-consumed_samples=5632.0-last.ckpt\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 11/19 | lr: 1.799e-06 | consumed_samples: 6144 | global_batch_size: 512 | global_step: 11 | reduced_train_loss: 11.03 | train_step_timing in s: 5.643\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:21:57 model_checkpoint:522] Async checkpoint save for step 11 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=10-consumed_samples=5632.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 12/19 | lr: 1.949e-06 | consumed_samples: 6656 | global_batch_size: 512 | global_step: 12 | reduced_train_loss: 11.03 | train_step_timing in s: 5.636\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 13/19 | lr: 2.099e-06 | consumed_samples: 7168 | global_batch_size: 512 | global_step: 13 | reduced_train_loss: 11.03 | train_step_timing in s: 5.633\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 14/19 | lr: 2.249e-06 | consumed_samples: 7680 | global_batch_size: 512 | global_step: 14 | reduced_train_loss: 11.03 | train_step_timing in s: 5.643\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 15/19 | lr: 2.399e-06 | consumed_samples: 8192 | global_batch_size: 512 | global_step: 15 | reduced_train_loss: 11.03 | train_step_timing in s: 5.631\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 16/19 | lr: 2.549e-06 | consumed_samples: 8704 | global_batch_size: 512 | global_step: 16 | reduced_train_loss: 11.03 | train_step_timing in s: 5.631\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 17/19 | lr: 2.699e-06 | consumed_samples: 9216 | global_batch_size: 512 | global_step: 17 | reduced_train_loss: 11.03 | train_step_timing in s: 5.63\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 18/19 | lr: 2.849e-06 | consumed_samples: 9728 | global_batch_size: 512 | global_step: 18 | reduced_train_loss: 11.03 | train_step_timing in s: 5.644\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 19/19 | lr: 2.999e-06 | consumed_samples: 10240 | global_batch_size: 512 | global_step: 19 | reduced_train_loss: 11.03 | train_step_timing in s: 5.638\n",
      "ining-demo/0 [default0]:`Trainer.fit` stopped: `max_steps=20` reached.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:22:43 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Updated FT timeouts. New values: HeartbeatTimeouts(initial=4.56, subsequent=42.51, were_calculated=True)\n",
      "ining-demo/0 [2025-03-07 00:22:52,774] [INFO] [ft_launcher@efc34a2bee7c] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "ining-demo/0 [2025-03-07 00:22:52,774] [INFO] [ft_launcher@efc34a2bee7c] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "ining-demo/0 [2025-03-07 00:22:52,774] [INFO] [ft_launcher@efc34a2bee7c] Done waiting for other agents. Elapsed: 0.00034546852111816406 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job resiliency-in-pretraining-demo-m41jprq0v5zdz finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']</span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo_1741306839\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo_1741306839\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status resiliency-in-pretraining-demo_1741306839</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs resiliency-in-pretraining-demo_1741306839 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel resiliency-in-pretraining-demo_1741306839 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306839\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306839\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306839\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable a crash simulation callback\n",
    "pretrain.trainer.callbacks.append(run.Config(CrashSimulationCallback, crash_step=17))\n",
    "\n",
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947346fd-d62f-42e6-848b-b0e1ea2bf0e8",
   "metadata": {},
   "source": [
    "## 2.3 Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452b9478-25bc-491d-a9a6-71fd698cac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# delete old checkpoints\n",
    "rm -rf /tmp/nemo_run/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af2f22b1-8cc7-4281-a2f5-e3afb603e44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Config[TimingCallback()]>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore pretrain.trainer.callbacks and drop Crash Simulation\n",
    "pretrain.trainer.callbacks = copy.deepcopy(pretrain_trainer_callbacks)\n",
    "run_plugins = []\n",
    "pretrain_trainer_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef835d-dc96-416b-9b68-f3fb94037e71",
   "metadata": {},
   "source": [
    "# 3. Demonstrate Straggler Detection\n",
    "The [Straggler Detection Callback](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes/callbacks/common.py):\n",
    "- Monitors training performance across nodes\n",
    "- Identifies ranks that are running slower than others (\"stragglers\")\n",
    "- Wraps NVIDIA Resiliency Extension's straggler detection functionality in a NeMo-compatible interface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6efeba-5f66-4fb8-82ff-94361881a970",
   "metadata": {},
   "source": [
    "## 3.1 Setup and run an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840d26c5-7ce0-4ba0-a3c4-e1ec7c8ace90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306577</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────── \u001b[0m\u001b[1;35mEntering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306577\u001b[0m\u001b[92m ──────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training run ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:16:17] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cannot detach from this experiment. Please keep it running until completion.</span>          <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:16:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31m Cannot detach from this experiment. Please keep it running until completion.\u001b[0m          \u001b]8;id=586120;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=683039;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\u001b\\\u001b[2m651\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306577/resiliency-in-pretraining-demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job resiliency-in-pretraining-demo for experiment </span>                           <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">resiliency-in-pretraining-demo</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job resiliency-in-pretraining-demo for experiment \u001b[0m                           \u001b]8;id=263335;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=67538;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\u001b\\\u001b[2m724\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mresiliency-in-pretraining-demo\u001b[0m                                                         \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306577/resiliency-in-pretraining-demo\n",
      "Launched app: local_persistent://nemo_run/resiliency-in-pretraining-demo-v1ccsb3wqlk0\n",
      "AppStatus:\n",
      "    State: RUNNING\n",
      "    Num Restarts: 0\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: file:///root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306577/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-v1ccsb3wqlk0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment executed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment resiliency-in-pretraining-demo_1741306577 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment resiliency-in-pretraining-demo_1741306577 to finish\u001b[0m\u001b[92m ────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo_1741306577</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mresiliency-in-pretraining-demo_1741306577\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: resiliency-in-pretraining-demo-v1ccsb3wqlk0\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306577/resiliency-in-pretraining-demo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mresiliency-in-pretraining-demo\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: resiliency-in-pretraining-demo-v1ccsb3wqlk0\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306577/resiliency-in-pretraining-demo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job resiliency-in-pretraining-demo-v1ccsb3wqlk0 to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ining-demo/0 W0307 00:16:19.039000 206056 torch/distributed/run.py:793] \n",
      "ining-demo/0 W0307 00:16:19.039000 206056 torch/distributed/run.py:793] *****************************************\n",
      "ining-demo/0 W0307 00:16:19.039000 206056 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "ining-demo/0 W0307 00:16:19.039000 206056 torch/distributed/run.py:793] *****************************************\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194] Starting elastic_operator with launch configs:\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   entrypoint       : nemo_run.core.runners.fdl_runner\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   min_nodes        : 1\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   max_nodes        : 1\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   nproc_per_node   : 8\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   run_id           : 6633\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   rdzv_backend     : c10d\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   rdzv_endpoint    : localhost:0\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   rdzv_configs     : {'timeout': 900}\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   max_restarts     : 0\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   monitor_interval : 0.1\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   log_dir          : /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306577/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-v1ccsb3wqlk0/torchelastic/resiliency-in-pretraining-demo\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194]   metrics_cfg      : {}\n",
      "ining-demo/0 I0307 00:16:19.040000 206056 torch/distributed/launcher/api.py:194] \n",
      "ining-demo/0 I0307 00:16:19.044000 206056 torch/distributed/elastic/agent/server/api.py:845] [default] starting workers for entrypoint: python\n",
      "ining-demo/0 I0307 00:16:19.044000 206056 torch/distributed/elastic/agent/server/api.py:662] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   master_addr=localhost\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   master_port=36359\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:525] \n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/api.py:670] [default] Starting worker group\n",
      "ining-demo/0 I0307 00:16:19.283000 206056 torch/distributed/elastic/agent/server/local_elastic_agent.py:291] use_agent_store: True\n",
      "ining-demo/0 I0307 00:16:19.284000 206056 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "ining-demo/0 I0307 00:16:19.284000 206056 torch/distributed/elastic/agent/server/local_elastic_agent.py:229] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:28 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:29 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:29 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:29 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:29 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:29 resume:228] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints. Training from scratch.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:29 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:16:31 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:40 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:16:40 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 0/19 | lr: 1.499e-07 | global_batch_size: 512 | global_step: 0 | reduced_train_loss: 11.03 | train_step_timing in s: 8.512\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 1/19 | lr: 2.999e-07 | global_batch_size: 512 | global_step: 1 | reduced_train_loss: 11.03 | train_step_timing in s: 5.61 | consumed_samples: 1024\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 2/19 | lr: 4.498e-07 | global_batch_size: 512 | global_step: 2 | reduced_train_loss: 11.03 | train_step_timing in s: 5.604 | consumed_samples: 1536\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 3/19 | lr: 5.997e-07 | global_batch_size: 512 | global_step: 3 | reduced_train_loss: 11.03 | train_step_timing in s: 5.604 | consumed_samples: 2048\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 4/19 | lr: 7.496e-07 | global_batch_size: 512 | global_step: 4 | reduced_train_loss: 11.03 | train_step_timing in s: 5.603 | consumed_samples: 2560\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 5/19 | lr: 8.996e-07 | global_batch_size: 512 | global_step: 5 | reduced_train_loss: 11.03 | train_step_timing in s: 5.609 | consumed_samples: 3072\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 6/19 | lr: 1.049e-06 | global_batch_size: 512 | global_step: 6 | reduced_train_loss: 11.03 | train_step_timing in s: 5.607 | consumed_samples: 3584\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 7/19 | lr: 1.199e-06 | global_batch_size: 512 | global_step: 7 | reduced_train_loss: 11.03 | train_step_timing in s: 5.611 | consumed_samples: 4096\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 8/19 | lr: 1.349e-06 | global_batch_size: 512 | global_step: 8 | reduced_train_loss: 11.03 | train_step_timing in s: 5.604 | consumed_samples: 4608\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 9/19 | lr: 1.499e-06 | global_batch_size: 512 | global_step: 9 | reduced_train_loss: 11.03 | train_step_timing in s: 5.607 | consumed_samples: 5120\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:17:32 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:17:34 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last.ckpt\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 10/19 | lr: 1.649e-06 | global_batch_size: 512 | global_step: 10 | reduced_train_loss: 11.03 | train_step_timing in s: 5.625 | consumed_samples: 5632\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:17:40 model_checkpoint:522] Async checkpoint save for step 10 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=9-consumed_samples=5120.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 11/19 | lr: 1.799e-06 | global_batch_size: 512 | global_step: 11 | reduced_train_loss: 11.03 | train_step_timing in s: 5.619 | consumed_samples: 6144\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 12/19 | lr: 1.949e-06 | global_batch_size: 512 | global_step: 12 | reduced_train_loss: 11.03 | train_step_timing in s: 5.615 | consumed_samples: 6656\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 13/19 | lr: 2.099e-06 | global_batch_size: 512 | global_step: 13 | reduced_train_loss: 11.03 | train_step_timing in s: 5.614 | consumed_samples: 7168\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 14/19 | lr: 2.249e-06 | global_batch_size: 512 | global_step: 14 | reduced_train_loss: 11.03 | train_step_timing in s: 5.612 | consumed_samples: 7680\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 15/19 | lr: 2.399e-06 | global_batch_size: 512 | global_step: 15 | reduced_train_loss: 11.03 | train_step_timing in s: 5.617 | consumed_samples: 8192\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:14 straggler_det_callback:144] \n",
      "ining-demo/0 [default0]:    GPU relative performance:\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:14 straggler_det_callback:153] \n",
      "ining-demo/0 [default0]:    GPU individual performance:\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:14 straggler_det_callback:236] Straggler report processing time: 0.049 sec.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 16/19 | lr: 2.549e-06 | global_batch_size: 512 | global_step: 16 | reduced_train_loss: 11.03 | train_step_timing in s: 5.611 | consumed_samples: 8704\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:20 straggler_det_callback:144] \n",
      "ining-demo/0 [default0]:    GPU relative performance:\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:20 straggler_det_callback:153] \n",
      "ining-demo/0 [default0]:    GPU individual performance:\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:20 straggler_det_callback:236] Straggler report processing time: 0.020 sec.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 17/19 | lr: 2.699e-06 | global_batch_size: 512 | global_step: 17 | reduced_train_loss: 11.03 | train_step_timing in s: 5.614 | consumed_samples: 9216\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:25 straggler_det_callback:144] \n",
      "ining-demo/0 [default0]:    GPU relative performance:\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:25 straggler_det_callback:153] \n",
      "ining-demo/0 [default0]:    GPU individual performance:\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:25 straggler_det_callback:236] Straggler report processing time: 0.019 sec.\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 18/19 | lr: 2.849e-06 | global_batch_size: 512 | global_step: 18 | reduced_train_loss: 11.03 | train_step_timing in s: 5.622 | consumed_samples: 9728\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:26 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:26 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=18-consumed_samples=9728.0-last.ckpt\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:32 straggler_det_callback:144] \n",
      "ining-demo/0 [default0]:    GPU relative performance:\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=0.98\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:32 straggler_det_callback:153] \n",
      "ining-demo/0 [default0]:    GPU individual performance:\n",
      "ining-demo/0 [default0]:      Rank=5 Node=efc34a2bee7c Score=0.99\n",
      "ining-demo/0 [default0]:      Rank=1 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=4 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=2 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=7 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=3 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=0 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:      Rank=6 Node=efc34a2bee7c Score=1.00\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:32 straggler_det_callback:236] Straggler report processing time: 0.020 sec.\n",
      "ining-demo/0 [default0]:Training epoch 1, iteration 0/19 | lr: 2.999e-06 | global_batch_size: 512 | global_step: 19 | reduced_train_loss: 11.03 | train_step_timing in s: 5.799 | consumed_samples: 10240\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:32 model_checkpoint:522] Async checkpoint save for step 19 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=18-consumed_samples=9728.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [default0]:`Trainer.fit` stopped: `max_steps=20` reached.\n",
      "ining-demo/0 I0307 00:18:38.989000 206056 torch/distributed/elastic/agent/server/api.py:864] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "ining-demo/0 I0307 00:18:38.989000 206056 torch/distributed/elastic/agent/server/api.py:917] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "ining-demo/0 I0307 00:18:38.990000 206056 torch/distributed/elastic/agent/server/api.py:931] Done waiting for other agents. Elapsed: 0.0002875328063964844 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job resiliency-in-pretraining-demo-v1ccsb3wqlk0 finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']</span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo_1741306577\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo_1741306577\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status resiliency-in-pretraining-demo_1741306577</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs resiliency-in-pretraining-demo_1741306577 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel resiliency-in-pretraining-demo_1741306577 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306577\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306577\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306577\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Automatically detect and mitigate stragglers during training\n",
    "pretrain.trainer.callbacks.append(straggler_det_callback(straggler_report_time_interval=1))\n",
    "\n",
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7577e-3dec-4e42-90cd-98e3fa481000",
   "metadata": {},
   "source": [
    "## 3.2 Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fb5eea6-f2f7-4b7b-9c6d-a50a398d1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# delete old checkpoints\n",
    "rm -rf /tmp/nemo_run/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "988af6cf-d834-4902-a208-3cf82d32381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Config[TimingCallback()]>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore pretrain.trainer.callbacks and drop Straggler Detection callback\n",
    "pretrain.trainer.callbacks = copy.deepcopy(pretrain_trainer_callbacks)\n",
    "run_plugins = []\n",
    "pretrain.trainer.callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d3d72-eefa-4e5e-b800-8f81ded7fdc4",
   "metadata": {},
   "source": [
    "# 4. Demonstrate Preemption\n",
    "The [Preemption Plugin](https://github.com/NVIDIA/NeMo/blob/main/nemo/lightning/pytorch/callbacks/preemption.py) provides graceful shutdown capabilities:\n",
    "- Monitors for shutdown signals (default: `signal.SIGTERM`)\n",
    "- Saves a checkpoint when a shutdown signal is received\n",
    "- Ensures training progress is preserved before termination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430b91a-a19e-479a-862a-e009b69fd58f",
   "metadata": {},
   "source": [
    "## 4.1 Setup the preemption simulator\n",
    "We use the `PreemptionSimulationCallback` to simulate a `signal.SIGTERM` during training. This callback is configured to raise a `signal.SIGTERM` at step 4.\n",
    "\n",
    "Expected workflow:\n",
    "- Start training: Trainer Step counter = 0\n",
    "- After 4 trainer steps: Trainer Step counter = 10 -> raise `signal.SIGTERM` -> Preemption callback saves an async checkpoint before gracefully exiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f24a1d67-da9f-490c-91a7-b1b3a3f25273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Preemption plugin\n",
    "run_plugins = [plugins.PreemptionPlugin()]\n",
    "\n",
    "# Enable a preemption simulation callback\n",
    "pretrain.trainer.callbacks.append(run.Config(PreemptionSimulationCallback, preemption_step=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab72b7f-20b5-4513-a65a-69052b82b50d",
   "metadata": {},
   "source": [
    "## 4.2 Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "145c4c35-4aff-4985-a5de-24e826f33fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306720</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────── \u001b[0m\u001b[1;35mEntering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306720\u001b[0m\u001b[92m ──────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training run ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:18:40] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cannot detach from this experiment. Please keep it running until completion.</span>          <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:18:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31m Cannot detach from this experiment. Please keep it running until completion.\u001b[0m          \u001b]8;id=427270;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=689472;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\u001b\\\u001b[2m651\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306720/resiliency-in-pretraining-demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job resiliency-in-pretraining-demo for experiment </span>                           <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">resiliency-in-pretraining-demo</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job resiliency-in-pretraining-demo for experiment \u001b[0m                           \u001b]8;id=605617;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=593300;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\u001b\\\u001b[2m724\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mresiliency-in-pretraining-demo\u001b[0m                                                         \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306720/resiliency-in-pretraining-demo\n",
      "Launched app: local_persistent://nemo_run/resiliency-in-pretraining-demo-l71z4w3rsq2kl\n",
      "AppStatus:\n",
      "    State: RUNNING\n",
      "    Num Restarts: 0\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: file:///root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306720/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-l71z4w3rsq2kl\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment executed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment resiliency-in-pretraining-demo_1741306720 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment resiliency-in-pretraining-demo_1741306720 to finish\u001b[0m\u001b[92m ────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo_1741306720</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mresiliency-in-pretraining-demo_1741306720\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: resiliency-in-pretraining-demo-l71z4w3rsq2kl\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306720/resiliency-in-pretraining-demo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mresiliency-in-pretraining-demo\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: resiliency-in-pretraining-demo-l71z4w3rsq2kl\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306720/resiliency-in-pretraining-demo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job resiliency-in-pretraining-demo-l71z4w3rsq2kl to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ining-demo/0 W0307 00:18:41.957000 213842 torch/distributed/run.py:793] \n",
      "ining-demo/0 W0307 00:18:41.957000 213842 torch/distributed/run.py:793] *****************************************\n",
      "ining-demo/0 W0307 00:18:41.957000 213842 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "ining-demo/0 W0307 00:18:41.957000 213842 torch/distributed/run.py:793] *****************************************\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194] Starting elastic_operator with launch configs:\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   entrypoint       : nemo_run.core.runners.fdl_runner\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   min_nodes        : 1\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   max_nodes        : 1\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   nproc_per_node   : 8\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   run_id           : 9133\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   rdzv_backend     : c10d\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   rdzv_endpoint    : localhost:0\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   rdzv_configs     : {'timeout': 900}\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   max_restarts     : 0\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   monitor_interval : 0.1\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   log_dir          : /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306720/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-l71z4w3rsq2kl/torchelastic/resiliency-in-pretraining-demo\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194]   metrics_cfg      : {}\n",
      "ining-demo/0 I0307 00:18:41.957000 213842 torch/distributed/launcher/api.py:194] \n",
      "ining-demo/0 I0307 00:18:41.961000 213842 torch/distributed/elastic/agent/server/api.py:845] [default] starting workers for entrypoint: python\n",
      "ining-demo/0 I0307 00:18:41.962000 213842 torch/distributed/elastic/agent/server/api.py:662] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   master_addr=localhost\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   master_port=39879\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:525] \n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/api.py:670] [default] Starting worker group\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/local_elastic_agent.py:291] use_agent_store: True\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "ining-demo/0 I0307 00:18:42.015000 213842 torch/distributed/elastic/agent/server/local_elastic_agent.py:229] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:50 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default5]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default0]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:52 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:52 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:52 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:52 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:18:52 resume:228] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints. Training from scratch.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:52 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default3]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default7]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default6]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default4]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default2]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default1]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:18:53 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:02 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:02 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 0/19 | lr: 1.499e-07 | global_batch_size: 512 | global_step: 0 | reduced_train_loss: 11.03 | train_step_timing in s: 8.584\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 1/19 | lr: 2.999e-07 | global_batch_size: 512 | global_step: 1 | reduced_train_loss: 11.03 | train_step_timing in s: 5.618 | consumed_samples: 1024\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 2/19 | lr: 4.498e-07 | global_batch_size: 512 | global_step: 2 | reduced_train_loss: 11.03 | train_step_timing in s: 5.63 | consumed_samples: 1536\n",
      "ining-demo/0 [default5]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:19 preemption:87] Received signal 15, initiating graceful stop\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:19 preemption:67] Preemption detected, saving checkpoint and exiting\n",
      "ining-demo/0 [default3]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default6]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default4]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default7]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default2]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default1]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:19 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:22 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=3-consumed_samples=2048.0-last.ckpt\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:22 preemption:73] Async checkpointing detected, waiting for it to complete\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:24 model_checkpoint:522] Async checkpoint save for step 4 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=3-consumed_samples=2048.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 I0307 00:19:29.026000 213842 torch/distributed/elastic/agent/server/api.py:864] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "ining-demo/0 I0307 00:19:29.027000 213842 torch/distributed/elastic/agent/server/api.py:917] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "ining-demo/0 I0307 00:19:29.027000 213842 torch/distributed/elastic/agent/server/api.py:931] Done waiting for other agents. Elapsed: 0.0005397796630859375 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job resiliency-in-pretraining-demo-l71z4w3rsq2kl finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']</span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo_1741306720\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo_1741306720\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status resiliency-in-pretraining-demo_1741306720</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs resiliency-in-pretraining-demo_1741306720 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel resiliency-in-pretraining-demo_1741306720 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306720\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306720\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306720\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8838d46-3d6f-40d1-9741-d8702f6c8a45",
   "metadata": {},
   "source": [
    "## 4.2 Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5dbf5ea-9ef3-494e-b2d7-faafb1a1be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# delete old checkpoints\n",
    "rm -rf /tmp/nemo_run/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59138478-1bd1-47b9-87da-2c7516464221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Config[TimingCallback()]>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore pretrain.trainer.callbacks\n",
    "pretrain.trainer.callbacks = copy.deepcopy(pretrain_trainer_callbacks)\n",
    "run_plugins = []\n",
    "pretrain.trainer.callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3acd19-c456-4a81-a933-12f11032bfb5",
   "metadata": {},
   "source": [
    "# 5. Discuss asynchronous distributed checkpointing\n",
    "Checkpointing is important for recovering from failures, but traditional checkpointing has drawbacks:\n",
    "\n",
    "1. Training pauses while saving checkpoints\n",
    "2. To minimize these pauses, checkpoints are usually only saved once per epoch\n",
    "3. If training fails between checkpoints, work must be redone from the last checkpoint\n",
    "\n",
    "For example, with:\n",
    "- 500 steps per epoch\n",
    "- 10 seconds per step\n",
    "- 3 epochs total\n",
    "\n",
    "Best case (no failures):\n",
    "- Training time = 15,000 seconds (500 steps × 10 seconds × 3 epochs)\n",
    "\n",
    "Worst case (failure at step 799):\n",
    "- Must redo nearly 2 full epochs\n",
    "- Training time = 20,000 seconds (nearly 5,000 seconds wasted)\n",
    "\n",
    "Asynchronous checkpointing solves these problems by:\n",
    "- Saving checkpoints without pausing training\n",
    "- Using fast distributed checkpointing via Megatron-Core\n",
    "- Allowing frequent checkpoints with minimal overhead\n",
    "\n",
    "This means you can checkpoint often to minimize lost work, without slowing down training.\n",
    "\n",
    "For more details, see:\n",
    "- [Megatron-Core distributed checkpointing](https://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/dist_checkpointing.html)\n",
    "- [NeMo documentation](https://github.com/NVIDIA/NeMo/blob/main/docs/source/checkpoints/dist_ckpt.rst)\n",
    "\n",
    "Note: NeMo enables asynchronous and parallel checkpointing by default through MegatronStrategy's \n",
    "ckpt_async_save and ckpt_parallel_save options, so users automatically get these benefits\n",
    "without any additional configuration needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be03ce1-e51a-46b6-a818-a39b6e007a8e",
   "metadata": {},
   "source": [
    "# 6. Demostrate all features discussed above simultaneously\n",
    "This includes:\n",
    "1. Crash / Hang detection and in-job restart\n",
    "2. Straggler Detection\n",
    "3. Preemption\n",
    "4. Asynchronous checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb12cc-20d2-410d-91ea-f9e3cecd097f",
   "metadata": {},
   "source": [
    "## 6.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5d0d695-a9b7-46a0-8ccb-57a7fba72b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_plugins = [plugins.FaultTolerancePlugin()]\n",
    "pretrain.trainer.callbacks.append(run.Config(CrashSimulationCallback, crash_step=17))\n",
    "\n",
    "pretrain.trainer.callbacks.append(straggler_det_callback(straggler_report_time_interval=1))\n",
    "\n",
    "run_plugins.append(plugins.PreemptionPlugin())\n",
    "pretrain.trainer.callbacks.append(run.Config(PreemptionSimulationCallback, preemption_step=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363bd11-b7ce-4a0f-92f2-fe8f01f6390e",
   "metadata": {},
   "source": [
    "## 6.2 Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaa07195-9c8a-44ce-93a1-5da30708a2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306771</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────── \u001b[0m\u001b[1;35mEntering Experiment resiliency-in-pretraining-demo with id: resiliency-in-pretraining-demo_1741306771\u001b[0m\u001b[92m ──────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training run ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:19:31] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cannot detach from this experiment. Please keep it running until completion.</span>          <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:19:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31m Cannot detach from this experiment. Please keep it running until completion.\u001b[0m          \u001b]8;id=303051;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=47217;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#651\u001b\\\u001b[2m651\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job resiliency-in-pretraining-demo for experiment </span>                           <a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">resiliency-in-pretraining-demo</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job resiliency-in-pretraining-demo for experiment \u001b[0m                           \u001b]8;id=343983;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241749;file:///opt/NeMo-Run/src/nemo_run/run/experiment.py#724\u001b\\\u001b[2m724\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mresiliency-in-pretraining-demo\u001b[0m                                                         \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo\n",
      "Launched app: local_persistent://nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc\n",
      "AppStatus:\n",
      "    State: RUNNING\n",
      "    Num Restarts: 0\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: file:///root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment executed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment resiliency-in-pretraining-demo_1741306771 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment resiliency-in-pretraining-demo_1741306771 to finish\u001b[0m\u001b[92m ────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo_1741306771</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mresiliency-in-pretraining-demo_1741306771\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">resiliency-in-pretraining-demo</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: resiliency-in-pretraining-demo-f4xc4417506tc\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mresiliency-in-pretraining-demo\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: resiliency-in-pretraining-demo-f4xc4417506tc\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job resiliency-in-pretraining-demo-f4xc4417506tc to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ining-demo/0 [2025-03-07 00:19:32,707] [WARNING] [ft_launcher@efc34a2bee7c] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
      "ining-demo/0 [2025-03-07 00:19:32,707] [WARNING] [ft_launcher@efc34a2bee7c] \n",
      "ining-demo/0 *****************************************\n",
      "ining-demo/0 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "ining-demo/0 *****************************************\n",
      "ining-demo/0 [2025-03-07 00:19:32,712] [INFO] [ft_launcher@efc34a2bee7c] [default] starting workers for entrypoint: python\n",
      "ining-demo/0 [2025-03-07 00:19:32,712] [INFO] [ft_launcher@efc34a2bee7c] [default] Rendezvous'ing worker group\n",
      "ining-demo/0 [2025-03-07 00:19:32,735] [INFO] [ft_launcher@efc34a2bee7c] [default] Rendezvous complete for workers. Result:\n",
      "ining-demo/0   restart_count=0\n",
      "ining-demo/0   master_addr=efc34a2bee7c\n",
      "ining-demo/0   master_port=59993\n",
      "ining-demo/0   group_rank=0\n",
      "ining-demo/0   group_world_size=1\n",
      "ining-demo/0   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "ining-demo/0   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "ining-demo/0 \n",
      "ining-demo/0 [2025-03-07 00:19:32,735] [INFO] [ft_launcher@efc34a2bee7c] [default] Starting worker group\n",
      "ining-demo/0 [2025-03-07 00:19:44,150] [INFO] [ft_launcher@efc34a2bee7c] Setting worker0 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/0/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,150] [INFO] [ft_launcher@efc34a2bee7c] Setting worker1 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/1/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,150] [INFO] [ft_launcher@efc34a2bee7c] Setting worker2 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/2/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,150] [INFO] [ft_launcher@efc34a2bee7c] Setting worker3 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/3/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,151] [INFO] [ft_launcher@efc34a2bee7c] Setting worker4 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/4/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,151] [INFO] [ft_launcher@efc34a2bee7c] Setting worker5 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/5/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,151] [INFO] [ft_launcher@efc34a2bee7c] Setting worker6 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/6/error.json\n",
      "ining-demo/0 [2025-03-07 00:19:44,151] [INFO] [ft_launcher@efc34a2bee7c] Setting worker7 reply file to: /root/.nemo_run/experiments/resiliency-in-pretraining-demo/resiliency-in-pretraining-demo_1741306771/resiliency-in-pretraining-demo/nemo_run/resiliency-in-pretraining-demo-f4xc4417506tc/torchelastic/resiliency-in-pretraining-demo/7190_9p5fdcaj/attempt_0/7/error.json\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:53 nemo_logging:361] /usr/local/lib/python3.10/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "ining-demo/0 [default0]:      cm = get_cmap(\"Set1\")\n",
      "ining-demo/0 [default0]:    \n",
      "ining-demo/0 [default1]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default1]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 tokenizer_utils:224] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "ining-demo/0 [default1]:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "ining-demo/0 [default3]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default3]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default0]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:GPU available: True (cuda), used: True\n",
      "ining-demo/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "ining-demo/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "ining-demo/0 [default6]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default6]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default5]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default5]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default7]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default7]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default2]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 nemo_logger:145] Experiments will be logged at /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo\n",
      "ining-demo/0 [default2]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_strategy:315] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:54 nemo_logger:123] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:54 nemo_logger:173] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/nemo_run/checkpoints/tb_logs\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:54 nemo_logger:189] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:54 nemo_logger:212] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 20. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:19:54 resume:228] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints. Training from scratch.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:426] Rank 0 has data parallel group : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:432] Rank 0 has combined group of data parallel and context parallel : [0, 2, 4, 6]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:437] All data parallel group ranks with context parallel combined: [[0, 2, 4, 6], [1, 3, 5, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:440] Ranks 0 has data parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:448] Rank 0 has context parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:451] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:452] Ranks 0 has context parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:459] Rank 0 has model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:460] All model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:469] Rank 0 has tensor model parallel group: [0, 1]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:473] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:474] Rank 0 has tensor model parallel rank: 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:494] Rank 0 has pipeline model parallel group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:506] Rank 0 has embedding group: [0]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:512] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:513] Rank 0 has pipeline model parallel rank 0\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:514] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:54 megatron_init:515] Rank 0 has embedding rank: 0\n",
      "ining-demo/0 [default0]:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "ining-demo/0 [default4]:Setup to simulate a crash if step == 17 and a crash hasn't been simulated before\n",
      "ining-demo/0 [default4]:Setup to simulate a preemption if step == 4\n",
      "ining-demo/0 [default5]:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "ining-demo/0 [default3]:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "ining-demo/0 [default2]:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "ining-demo/0 [default6]:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "ining-demo/0 [default7]:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:distributed_backend=nccl\n",
      "ining-demo/0 [default0]:All distributed processes registered. Starting with 8 processes\n",
      "ining-demo/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default4]:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance dir: /tmp/nemo_run/checkpoints\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 fault_tolerance_callback:311] [FaultToleranceCallback@rank0] Fault tolerance client initialized. Timeouts: HeartbeatTimeouts(initial=1800.00, subsequent=300.00, were_calculated=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 base:44] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 megatron_strategy:327] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 num_microbatches_calculator:228] setting number of microbatches to constant 128\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 megatron_parallel:549]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 54663936\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "ining-demo/0 [default0]:    Params for bucket 1 (54663936 elements):\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.embedding.word_embeddings.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.output_layer.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.final_layernorm.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.weight\n",
      "ining-demo/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:19:56 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0003, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "ining-demo/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "ining-demo/0 [default0]:\n",
      "ining-demo/0 [default0]:  | Name   | Type | Params | Mode \n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:0 | module | DDP  | 54.7 M | train\n",
      "ining-demo/0 [default0]:----------------------------------------\n",
      "ining-demo/0 [default0]:54.7 M    Trainable params\n",
      "ining-demo/0 [default0]:0         Non-trainable params\n",
      "ining-demo/0 [default0]:54.7 M    Total params\n",
      "ining-demo/0 [default0]:218.656   Total estimated model params size (MB)\n",
      "ining-demo/0 [default0]:91        Modules in train mode\n",
      "ining-demo/0 [default0]:0         Modules in eval mode\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:20:05 rerun_state_machine:1088] Implicit initialization of Rerun State Machine!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:20:05 rerun_state_machine:211] RerunStateMachine initialized in mode disabled\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 0/19 | lr: 1.499e-07 | global_batch_size: 512 | global_step: 0 | reduced_train_loss: 11.03 | train_step_timing in s: 9.386\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 1/19 | lr: 2.999e-07 | global_batch_size: 512 | global_step: 1 | reduced_train_loss: 11.03 | train_step_timing in s: 5.622 | consumed_samples: 1024\n",
      "ining-demo/0 [default0]:Training epoch 0, iteration 2/19 | lr: 4.498e-07 | global_batch_size: 512 | global_step: 2 | reduced_train_loss: 11.03 | train_step_timing in s: 5.612 | consumed_samples: 1536\n",
      "ining-demo/0 [default3]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default7]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default1]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:20:22 preemption:87] Received signal 15, initiating graceful stop\n",
      "ining-demo/0 [default6]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default4]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default2]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:20:22 preemption:67] Preemption detected, saving checkpoint and exiting\n",
      "ining-demo/0 [default5]:Simulating preemption by raising a SIGTERM at step 4!\n",
      "ining-demo/0 [default0]:[NeMo W 2025-03-07 00:20:23 validation:389] There is difference in the common state dict in different ranks. The differences are {2: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 3: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 4: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], []), 5: ([], [('optimizer', 0, 'optimizer', 'param_groups', 1, 'step')], [])}\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:20:25 model_checkpoint:497] Scheduled async checkpoint save for /tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=3-consumed_samples=2048.0-last.ckpt\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:20:25 preemption:73] Async checkpointing detected, waiting for it to complete\n",
      "ining-demo/0 [default0]:[NeMo I 2025-03-07 00:20:27 model_checkpoint:522] Async checkpoint save for step 4 (/tmp/nemo_run/checkpoints/resiliency-in-pretraining-demo/checkpoints/model_name=0--val_loss=0.00-step=3-consumed_samples=2048.0-last.ckpt) finalized successfully.\n",
      "ining-demo/0 [2025-03-07 00:20:34,363] [INFO] [ft_launcher@efc34a2bee7c] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "ining-demo/0 [2025-03-07 00:20:34,364] [INFO] [ft_launcher@efc34a2bee7c] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "ining-demo/0 [2025-03-07 00:20:34,364] [INFO] [ft_launcher@efc34a2bee7c] Done waiting for other agents. Elapsed: 0.0005159378051757812 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job resiliency-in-pretraining-demo-f4xc4417506tc finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']</span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo_1741306771\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"resiliency-in-pretraining-demo\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['resiliency-in-pretraining-demo']\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo_1741306771\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mresiliency-in-pretraining-demo\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status resiliency-in-pretraining-demo_1741306771</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs resiliency-in-pretraining-demo_1741306771 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel resiliency-in-pretraining-demo_1741306771 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306771\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306771\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresiliency-in-pretraining-demo_1741306771\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the experiment\n",
    "run_experiment(exp_name, pretrain, executor, run_plugins, dryrun=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
