[NeMo W 2024-04-08 15:44:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
      ret = run_job(
    
[NeMo W 2024-04-08 15:44:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `pytorch_lightning.plugins.precision.MixedPrecision` instead.
    
[NeMo W 2024-04-08 15:44:57 exp_manager:966] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 12. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:57 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: num_query_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: attention_dropout in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: masked_softmax_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: persist_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_margin in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_interval in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_amax_history_len in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_amax_compute_algo in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: rotary_percent in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:1172] The model: MegatronBertEmbeddingModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: num_query_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: attention_dropout in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: masked_softmax_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: persist_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_margin in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_interval in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_amax_history_len in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_amax_compute_algo in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo W 2024-04-08 15:44:58 megatron_base_model:556] The model: MegatronBertEmbeddingModel() does not have field.name: rotary_percent in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
[NeMo E 2024-04-08 15:44:58 common:523] Model instantiation failed!
    Target class:	nemo.collections.nlp.models.language_modeling.megatron_bert_model.MegatronBertModel
    Error(s):	'NoneType' object has no attribute 'module' when instantiating SelfAttention when instantiating TransformerLayerWithPostLNSupport
    Traceback (most recent call last):
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 99, in build_module
        return module(
      File "/opt/megatron-lm/megatron/core/transformer/attention.py", line 375, in __init__
        self.q_layernorm = build_module(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 84, in build_module
        module = import_module(spec_or_module.module)
    AttributeError: 'NoneType' object has no attribute 'module'
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 99, in build_module
        return module(
      File "/opt/NeMo/nemo/collections/nlp/models/language_modeling/megatron/bert/bert_model.py", line 180, in __init__
        super(TransformerLayerWithPostLNSupport, self).__init__(*args, **kwargs)
      File "/opt/megatron-lm/megatron/core/transformer/transformer_layer.py", line 84, in __init__
        self.self_attention = build_module(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 107, in build_module
        raise type(e)(f"{str(e)} when instantiating {module.__name__}").with_traceback(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 99, in build_module
        return module(
      File "/opt/megatron-lm/megatron/core/transformer/attention.py", line 375, in __init__
        self.q_layernorm = build_module(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 84, in build_module
        module = import_module(spec_or_module.module)
    AttributeError: 'NoneType' object has no attribute 'module' when instantiating SelfAttention
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File "/opt/NeMo/nemo/core/classes/common.py", line 502, in from_config_dict
        instance = imported_cls(cfg=config, trainer=trainer)
      File "/opt/NeMo/nemo/collections/nlp/models/information_retrieval/megatron_bert_embedding_model.py", line 81, in __init__
        super().__init__(cfg, trainer=trainer)
      File "/opt/NeMo/nemo/collections/nlp/models/language_modeling/megatron_bert_model.py", line 116, in __init__
        self.model = build_model(
      File "/opt/NeMo/nemo/collections/nlp/modules/common/megatron/build_model.py", line 90, in build_model
        model = model_provider_func(
      File "/opt/NeMo/nemo/collections/nlp/models/information_retrieval/megatron_bert_embedding_model.py", line 95, in model_provider_func
        model = MCoreBertEmbeddingModel(
      File "/opt/NeMo/nemo/collections/nlp/models/information_retrieval/bert_embedding_model.py", line 80, in __init__
        super(MCoreBertEmbeddingModel, self).__init__(*args, **kwargs)
      File "/opt/NeMo/nemo/collections/nlp/models/language_modeling/megatron/bert/bert_model.py", line 329, in __init__
        super(MCoreBertModelWrapperWithPostLNSupport, self).__init__(*args, **kwargs)
      File "/opt/megatron-lm/megatron/core/models/bert/bert_model.py", line 106, in __init__
        self.encoder = TransformerBlock(
      File "/opt/megatron-lm/megatron/core/transformer/transformer_block.py", line 135, in __init__
        self._build_layers()
      File "/opt/megatron-lm/megatron/core/transformer/transformer_block.py", line 150, in _build_layers
        [
      File "/opt/megatron-lm/megatron/core/transformer/transformer_block.py", line 151, in <listcomp>
        build_layer(layer_spec, i + 1)
      File "/opt/megatron-lm/megatron/core/transformer/transformer_block.py", line 146, in build_layer
        return build_module(layer_spec, config=self.config, layer_number=layer_number,)
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 107, in build_module
        raise type(e)(f"{str(e)} when instantiating {module.__name__}").with_traceback(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 99, in build_module
        return module(
      File "/opt/NeMo/nemo/collections/nlp/models/language_modeling/megatron/bert/bert_model.py", line 180, in __init__
        super(TransformerLayerWithPostLNSupport, self).__init__(*args, **kwargs)
      File "/opt/megatron-lm/megatron/core/transformer/transformer_layer.py", line 84, in __init__
        self.self_attention = build_module(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 107, in build_module
        raise type(e)(f"{str(e)} when instantiating {module.__name__}").with_traceback(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 99, in build_module
        return module(
      File "/opt/megatron-lm/megatron/core/transformer/attention.py", line 375, in __init__
        self.q_layernorm = build_module(
      File "/opt/megatron-lm/megatron/core/transformer/spec_utils.py", line 84, in build_module
        module = import_module(spec_or_module.module)
    AttributeError: 'NoneType' object has no attribute 'module' when instantiating SelfAttention when instantiating TransformerLayerWithPostLNSupport
    
