GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Epoch 0, global step 2: 'val_loss' reached 10.86161 (best 10.86161), saving model to 'examples/nlp/language_modeling/gpt_pretrain_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=10.86-step=2-consumed_samples=16.0.ckpt' as top 10
`Trainer.fit` stopped: `max_steps=3` reached.
