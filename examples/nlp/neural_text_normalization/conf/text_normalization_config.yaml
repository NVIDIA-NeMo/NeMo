name: &name NeuralTextNormalization

# Tagger
tagger_pretrained_model: null

tagger_trainer:
  gpus: 1 # the number of gpus, 0 for CPU
  num_nodes: 1

tagger_model:
  transformer: distilbert-base-uncased
  tokenizer: ${tagger_model.transformer}

tagger_exp_manager:
  exp_dir: null  # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
  name: "TextNormalizationTaggerModel"  # The name of your model

# Decoder
decoder_pretrained_model: null

decoder_trainer:
  gpus: 1 # the number of gpus, 0 for CPU
  num_nodes: 1

decoder_model:
  transformer: t5-base
  tokenizer: ${decoder_model.transformer}

decoder_exp_manager:
  exp_dir: null  # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
  name: "TextNormalizationDecoderModel"  # The name of your model
