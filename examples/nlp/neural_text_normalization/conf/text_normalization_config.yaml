name: &name NeuralTextNormalization

# Tagger
tagger_pretrained_model: null

tagger_trainer:
  gpus: 1 # the number of gpus, 0 for CPU
  num_nodes: 1

tagger_model:
  transformer: distilbert-base-uncased
  tokenizer: ${tagger_model.transformer}

# Decoder
decoder_pretrained_model: null

decoder_trainer:
  gpus: 1 # the number of gpus, 0 for CPU
  num_nodes: 1

decoder_model:
  transformer: t5-base
  tokenizer: ${decoder_model.transformer}

# Inference Parameters
inference:
  batch_size: 64

# Data
data:
  base_dir: /NeMo/google_en # /path/to/data

  train_ds:
    data_path: ${data.base_dir}/train.tsv

  validation_ds:
    data_path: ${data.base_dir}/dev.tsv

  test_ds:
    data_path: ${data.base_dir}/test.tsv
