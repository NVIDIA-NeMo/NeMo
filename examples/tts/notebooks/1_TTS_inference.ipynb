{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS Inference\n",
    "\n",
    "This notebook can be used to generate audio samples using either NeMo's pretrained models or after training NeMo TTS models. This script currently uses a two step inference procedure. First, a model is used to generate a mel spectrogram from text. Second, a model is used to generate audio from a mel spectrogram.\n",
    "\n",
    "Currently supported models are:\n",
    "Mel Spectrogram Generators:\n",
    "- Tacotron 2\n",
    "- Glow-TTS\n",
    "\n",
    "Audio Generators\n",
    "- Grifflin-Lim\n",
    "- WaveGlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Licence\n",
    "\n",
    "> Copyright 2020 NVIDIA. All Rights Reserved.\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "> you may not use this file except in compliance with the License.\n",
    "> You may obtain a copy of the License at\n",
    "> \n",
    ">     http://www.apache.org/licenses/LICENSE-2.0\n",
    "> \n",
    "> Unless required by applicable law or agreed to in writing, software\n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "> See the License for the specific language governing permissions and\n",
    "> limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\\nInstructions for setting up Colab are as follows:\\n1. Open a new Python 3 notebook.\\n2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\\n3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\\n4. Run this cell to set up dependencies.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "Instructions for setting up Colab are as follows:\n",
    "1. Open a new Python 3 notebook.\n",
    "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
    "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
    "4. Run this cell to set up dependencies.\n",
    "\"\"\"\n",
    "# If you're using Google Colab and not running locally, uncomment and run this cell.\n",
    "# !pip install wget\n",
    "# !apt-get install sox libsndfile1 ffmpeg\n",
    "# !pip install unidecode\n",
    "# !pip install nemo_toolkit[tts]\n",
    "\n",
    "# !mkdir configs\n",
    "# !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/candidate/examples/tts/conf/tacotron2.yaml\n",
    "# !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/candidate/examples/tts/conf/waveglow.yaml\n",
    "# !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/candidate/examples/tts/conf/glow_tts.yaml\n",
    "# CONFIG_PATH = \"conf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one of the following spectrogram generators:\n",
      "['tacotron2', 'glow_tts']\n",
      "Choose one of the following audio generators:\n",
      "['waveglow']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try: CONFIG_PATH\n",
    "except NameError: CONFIG_PATH = Path(\"..\") / \"conf\"\n",
    "    \n",
    "supported_spec_gen = [\"tacotron2\", \"glow_tts\"]\n",
    "# supported_audio_gen = [\"grifflin-lim\", \"waveglow\"]\n",
    "supported_audio_gen = [\"waveglow\"]\n",
    "supported_audio_gen_req_checkpoint = [\"waveglow\"]\n",
    "\n",
    "print(\"Choose one of the following spectrogram generators:\")\n",
    "print([model for model in supported_spec_gen])\n",
    "# spectrogram_generator = input()\n",
    "print(\"Choose one of the following audio generators:\")\n",
    "print([model for model in supported_audio_gen])\n",
    "# audio_generator = input()\n",
    "\n",
    "# TODO\n",
    "spectrogram_generator = \"glow_tts\"\n",
    "audio_generator = \"waveglow\"\n",
    "\n",
    "assert spectrogram_generator in supported_spec_gen\n",
    "assert audio_generator in supported_audio_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download pre-trained checkpoints\n",
    "\n",
    "TODO: Enable downloading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram_generator_checkpoint_path = input(f\"Input the path to the {spectrogram_generator} checkpoint: \")\n",
    "# if audio_generator in supported_audio_gen_req_checkpoint:\n",
    "#     audio_generator_checkpoint_path = input(f\"Input the path to the {audio_generator} checkpoint: \")\n",
    "\n",
    "# TODO\n",
    "audio_generator_checkpoint_path = Path.home()/\"nemo/NeMo/examples/tts/experiments/1374354-Waveglow_O2_LJS_V1b/WaveGlow/2020-07-27_18-54-10/checkpoints/WaveGlow--last.ckpt\"\n",
    "# spectrogram_generator_checkpoint_path = Path.home()/\"nemo/NeMo/examples/tts/experiments/1325283-Tacotron_O0_LJS_V1b/Tacotron 2/2020-07-24_21-39-14/checkpoints/Tacotron 2--last.ckpt\"\n",
    "spectrogram_generator_checkpoint_path = Path.home()/\"nemo/NeMo/examples/tts/experiments/Glow_TTS/1500.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-08-21 12:13:24 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "    Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "      from numba.decorators import jit as optional_jit\n",
      "    \n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioLabelDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text._TarredAudioToTextDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.models.classification_models.MatchboxNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.losses.ctc.CTCLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.JasperNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.QuartzNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_label.AudioToSpeechLabelDataSet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.models.label_models.EncDecSpeakerLabelModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.modules.audio_preprocessing.AudioToMFCCPreprocessor'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASREncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoderClassification'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.losses.glow_tts_loss.GlowTTSLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.modules.glow_tts.TextEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.modules.glow_tts.FlowSpecDecoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Encoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Decoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Postnet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.modules.waveglow.WaveGlowModule'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.models.glow_tts.GlowTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.models.tacotron2.Tacotron2Model'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 experimental:28] Module <class 'nemo.collections.tts.models.waveglow.WaveGlowModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-08-21 12:13:25 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/hydra/_internal/utils.py:638: UserWarning: \n",
      "    Config key 'model.parser.cls' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Use '_target_' instead of 'cls'.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(message=msg, category=UserWarning)\n",
      "    \n",
      "[NeMo W 2020-08-21 12:13:25 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/hydra/_internal/utils.py:584: UserWarning: \n",
      "    Field 'params' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Inline the content of params directly at the containing node.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(category=UserWarning, message=msg)\n",
      "    \n",
      "[NeMo W 2020-08-21 12:13:25 glow_tts:225] Could not load dataset as `manifest_filepath` was None. Provided config : {'manifest_filepath': None, 'sample_rate': 22050, 'batch_size': 1, 'max_duration': None, 'min_duration': 0.1, 'trim': False, 'shuffle': False, 'num_workers': 8, 'cmu_dict_path': None}\n",
      "[NeMo W 2020-08-21 12:13:25 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/hydra/_internal/utils.py:638: UserWarning: \n",
      "    Config key 'preprocessor.cls' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Use '_target_' instead of 'cls'.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(message=msg, category=UserWarning)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-08-21 12:13:25 features:186] PADDING: 16\n",
      "[NeMo I 2020-08-21 12:13:25 features:194] STFT using conv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-08-21 12:13:25 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/hydra/_internal/utils.py:638: UserWarning: \n",
      "    Config key 'encoder.cls' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Use '_target_' instead of 'cls'.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(message=msg, category=UserWarning)\n",
      "    \n",
      "[NeMo W 2020-08-21 12:13:25 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/hydra/_internal/utils.py:638: UserWarning: \n",
      "    Config key 'decoder.cls' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Use '_target_' instead of 'cls'.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(message=msg, category=UserWarning)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-08-21 12:13:26 features:186] PADDING: 16\n",
      "[NeMo I 2020-08-21 12:13:26 features:194] STFT using conv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-08-21 12:13:26 nemo_logging:349] /home/jasoli/ptl_venv/lib/python3.6/site-packages/hydra/_internal/utils.py:638: UserWarning: \n",
      "    Config key 'waveglow.cls' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Use '_target_' instead of 'cls'.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(message=msg, category=UserWarning)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from ruamel.yaml import YAML\n",
    "from nemo.collections.asr.parts import parsers\n",
    "\n",
    "def load_spectrogram_model():\n",
    "    if spectrogram_generator == \"tacotron2\":\n",
    "        from nemo.collections.tts.models import Tacotron2Model as SpecModel\n",
    "        cfg_file = Path(CONFIG_PATH) / \"tacotron2.yaml\"\n",
    "    elif spectrogram_generator == \"glow_tts\":\n",
    "        from nemo.collections.tts.models import GlowTTSModel as SpecModel\n",
    "        cfg_file = Path(CONFIG_PATH) / \"glow_tts.yaml\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    with open(cfg_file) as file:\n",
    "        cfg = OmegaConf.load(file)\n",
    "    del cfg.model[\"train_ds\"]\n",
    "    del cfg.model[\"validation_ds\"]\n",
    "    del cfg.model[\"optim\"]\n",
    "    return SpecModel(cfg=cfg.model)\n",
    "\n",
    "def load_vocoder_model():\n",
    "    if audio_generator == \"waveglow\":\n",
    "        from nemo.collections.tts.models import WaveGlowModel as VocoderModel\n",
    "        cfg_file = Path(CONFIG_PATH) / \"waveglow.yaml\"\n",
    "    elif audio_generator == \"grifflin-lim\":\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    with open(cfg_file) as file:\n",
    "        cfg = OmegaConf.load(file)\n",
    "    del cfg.model[\"train_ds\"]\n",
    "    del cfg.model[\"validation_ds\"]\n",
    "    del cfg.model[\"optim\"]\n",
    "    return VocoderModel(cfg=cfg.model)\n",
    "\n",
    "spec_gen = load_spectrogram_model()\n",
    "vocoder = load_vocoder_model()\n",
    "\n",
    "spec_gen.load_state_dict(torch.load(spectrogram_generator_checkpoint_path)[\"state_dict\"])\n",
    "vocoder.load_state_dict(torch.load(audio_generator_checkpoint_path)[\"state_dict\"])\n",
    "\n",
    "spec_gen = spec_gen.cuda()\n",
    "vocoder = vocoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(spec_gen_model, vocder_model, str_input):\n",
    "    with torch.no_grad():\n",
    "        parsed = spec_gen.parse(text_to_generate)\n",
    "        spectrogram = spec_gen.generate_spectrogram(tokens=parsed)\n",
    "        audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "    return spectrogram, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input what you want the model to say: testing one two three\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'speaker_embed' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fb43e32bc862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_to_generate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input what you want the model to say: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_to_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-69232419b622>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(spec_gen_model, vocder_model, str_input)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_spectrogram_to_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nemo/NeMo/nemo/collections/tts/models/glow_tts.py\u001b[0m in \u001b[0;36mgenerate_spectrogram\u001b[0;34m(self, tokens, noise_scale, length_scale)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mtoken_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ptl_venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nemo/NeMo/nemo/core/classes/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# Call the method - this can be forward, or any other callable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_and_validate_output_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nemo/NeMo/nemo/collections/tts/models/glow_tts.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_lengths, y, y_lengths, gen, noise_scale, length_scale)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             return self.glow_tts.generate_spect(\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             )\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nemo/NeMo/nemo/core/classes/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# Call the method - this can be forward, or any other callable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_and_validate_output_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nemo/NeMo/nemo/collections/tts/modules/glow_tts.py\u001b[0m in \u001b[0;36mgenerate_spect\u001b[0;34m(self, text, text_lengths, speaker, noise_scale, length_scale)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         x_m, x_logs, log_durs_predicted, x_mask = self.encoder(\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeaker_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         )\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'speaker_embed' referenced before assignment"
     ]
    }
   ],
   "source": [
    "text_to_generate = input(\"Input what you want the model to say: \")\n",
    "spec, audio = infer(spec_gen, vocoder, text_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "ipd.Audio(audio.detach().cpu().numpy(), rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "imshow(spec.detach().cpu().numpy()[0], origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
