{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 NVIDIA. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import nemo.collections.tts as nemo_tts\n",
    "import nemo.utils.argparse as nm_argparse\n",
    "from nemo.collections.tts import (\n",
    "    tacotron2_eval_log_to_tb_func,\n",
    "    tacotron2_log_to_tb_func,\n",
    "    tacotron2_process_eval_batch,\n",
    "    tacotron2_process_final_eval,\n",
    ")\n",
    "\n",
    "logging = nemo.logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download config files\n",
    "config_path = '../configs/tacotron2.yaml'\n",
    "\n",
    "\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(config_path) as file:\n",
    "    tacotron2_config = yaml.load(file)\n",
    "    labels = tacotron2_config[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_NMs(tacotron2_config, labels, decoder_infer=False, decoder_force=False):\n",
    "    data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n",
    "        **tacotron2_config['AudioToMelSpectrogramPreprocessor']['init_params']\n",
    "    )\n",
    "    text_embedding = nemo_tts.TextEmbedding.import_from_config(\n",
    "        tacotron2_config_file, \"TextEmbedding\", overwrite_params={\"n_symbols\": len(labels) + 3}\n",
    "    )\n",
    "    t2_enc = nemo_tts.Tacotron2Encoder.import_from_config(tacotron2_config_file, \"Tacotron2Encoder\")\n",
    "    if decoder_infer:\n",
    "        t2_dec = nemo_tts.Tacotron2DecoderInfer.import_from_config(tacotron2_config_file, \"Tacotron2DecoderInfer\")\n",
    "    else:\n",
    "        t2_dec = nemo_tts.Tacotron2Decoder.import_from_config(\n",
    "            tacotron2_config_file, \"Tacotron2Decoder\", overwrite_params={\"force\": decoder_force}\n",
    "        )\n",
    "    t2_postnet = nemo_tts.Tacotron2Postnet.import_from_config(tacotron2_config_file, \"Tacotron2Postnet\")\n",
    "    t2_loss = nemo_tts.Tacotron2Loss.import_from_config(tacotron2_config_file, \"Tacotron2Loss\")\n",
    "    makegatetarget = nemo_tts.MakeGate()\n",
    "\n",
    "    total_weights = text_embedding.num_weights + t2_enc.num_weights + t2_dec.num_weights + t2_postnet.num_weights\n",
    "\n",
    "    logging.info('================================')\n",
    "    logging.info(f\"Total number of parameters: {total_weights}\")\n",
    "    logging.info('================================')\n",
    "\n",
    "    return (\n",
    "        data_preprocessor,\n",
    "        text_embedding,\n",
    "        t2_enc,\n",
    "        t2_dec,\n",
    "        t2_postnet,\n",
    "        t2_loss,\n",
    "        makegatetarget,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'placement'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c97829da6961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneural_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_NMs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtacotron2_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_infer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-8f4693d3296a>\u001b[0m in \u001b[0;36mcreate_NMs\u001b[0;34m(tacotron2_config, labels, decoder_infer, decoder_force)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_NMs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtacotron2_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_infer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_force\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mtacotron2_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AudioToMelSpectrogramPreprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m     text_embedding = nemo_tts.TextEmbedding.import_from_config(\n",
      "\u001b[0;32m~/PycharmProjects/NeMo-som/nemo/collections/asr/audio_preprocessing.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sample_rate, window_size, window_stride, n_window_size, n_window_stride, window, normalize, n_fft, preemph, features, lowfreq, highfreq, log, log_zero_guard_type, log_zero_guard_value, dither, pad_to, frame_splicing, stft_conv, pad_value, mag_power)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mn_window_stride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_stride\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_window_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_window_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         self.featurizer = FilterbankFeatures(\n",
      "\u001b[0;32m~/PycharmProjects/NeMo-som/nemo/collections/asr/audio_preprocessing.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, win_length, hop_length)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwin_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo-som/nemo/backends/pytorch/nm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNonTrainableNM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mNeuralModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# For NeuralModule API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo-som/nemo/core/neural_modules.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Set module properties from factory else use defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;31m# If one needs to change that should override it manually.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'placement'"
     ]
    }
   ],
   "source": [
    "neural_modules = create_NMs(tacotron2_config, labels, decoder_infer=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create inference dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnemo_tts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTacotron2Decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mel_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_frames_per_step\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoder_embedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgate_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprenet_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_decoder_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_rnn_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mp_decoder_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mp_attention_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattention_rnn_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattention_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattention_location_n_filters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattention_location_kernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprenet_p_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Tacotron2Decoder implements the attention, decoder, and prenet parts of\n",
       "Tacotron 2. It takes the encoded text and produces mel spectrograms. The\n",
       "decoder contains two rnns, one is called the decoder rnn and the other is\n",
       "called the attention rnn.\n",
       "\n",
       "Args:\n",
       "    n_mel_channels (int): The size or dimensionality of the mel spectrogram\n",
       "    n_frames_per_step (int): The number of frames we predict at each\n",
       "        decoder time step. Defaults to 1\n",
       "    encoder_embedding_dim (int): The size of the encoded text.\n",
       "        Defaults to 512.\n",
       "    gate_threshold (float): A number in [0, 1). When teacher forcing is\n",
       "        not used, the model predict a stopping value at each model time\n",
       "        step. The model will stop if the value is greater than\n",
       "        gate_threshold. Defaults to 0.5.\n",
       "    prenet_dim (int): The hidden dimension of the prenet. Defaults to 256.\n",
       "    max_decoder_steps (int): When not teacher forcing, the maximum number\n",
       "        of frames to predict. Defaults to 1000.\n",
       "    decoder_rnn_dim (int): The hidden dimension of the decoder rnn.\n",
       "        Defaults to 1024.\n",
       "    p_decoder_dropout (float): Dropout probability for the decoder rnn.\n",
       "        Defaults to 0.1.\n",
       "    p_attention_dropout (float): Dropout probability for the attention rnn.\n",
       "        Defaults to 0.1.\n",
       "    attention_rnn_dim (int): The hidden dimension of the attention rnn.\n",
       "        Defaults to 1024.\n",
       "    attention_dim (int): The hidden dimension of the attention mechanism.\n",
       "        Defaults to 128.\n",
       "    attention_location_n_filters (int): The number of convolution filters\n",
       "        for the location part of the attention mechanism.\n",
       "        Defaults to 32.\n",
       "    attention_location_kernel_size (int): The kernel size of the\n",
       "        convolution for the location part of the attention mechanism.\n",
       "        Defaults to 31.\n",
       "\u001b[0;31mInit docstring:\u001b[0m Constructor. Creates a \"shortcut\" to the application state.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/PycharmProjects/NeMo-som/nemo/collections/tts/tacotron2_modules.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Tacotron2DecoderInfer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(_, text_embedding, t2_enc, t2_dec, t2_postnet, _, _) = neural_modules\n",
    "\n",
    "data_layer = nemo_asr.TranscriptDataLayer(\n",
    "    path=infer_dataset,\n",
    "    labels=labels,\n",
    "    batch_size=infer_batch_size,\n",
    "    num_workers=cpu_per_dl,\n",
    "    # load_audio=False,\n",
    "    bos_id=len(labels),\n",
    "    eos_id=len(labels) + 1,\n",
    "    pad_id=len(labels) + 2,\n",
    "    shuffle=False,\n",
    ")\n",
    "transcript, transcript_len = data_layer()\n",
    "\n",
    "transcript_embedded = text_embedding(char_phone=transcript)\n",
    "\n",
    "transcript_encoded = t2_enc(char_phone_embeddings=transcript_embedded, embedding_length=transcript_len,)\n",
    "\n",
    "mel_decoder, gate, alignments, mel_len = t2_dec(\n",
    "    char_phone_encoded=transcript_encoded, encoded_length=transcript_len,\n",
    ")\n",
    "\n",
    "mel_postnet = t2_postnet(mel_input=mel_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('NeMo': conda)",
   "language": "python",
   "name": "python37664bitnemoconda43f94a748a2e4953b0129556ecdf4f62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
