{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitpy36condade6bc17c0cdd4e2d8c72d4203452925a",
   "display_name": "Python 3.6.10 64-bit ('py36': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace these macros accordingly\n",
    "ROOT = '/home/vincliu/vocoder/NeMo'\n",
    "os.chdir(ROOT)\n",
    "\n",
    "CHECKPOINT = os.path.join('nemo_experiments', 'SqueezeWave', '2020-08-30_12-13-34', 'checkpoints', 'SqueezeWave--last.ckpt')\n",
    "CONFIG = os.path.join('examples', 'tts', 'conf', 'squeezewave.yaml')\n",
    "DATA_MANIFEST = os.path.join('data', 'nvidia_ljspeech_test.json')\n",
    "OUT_FOLDER = os.path.join('samples')\n",
    "if not os.path.isdir(OUT_FOLDER):\n",
    "    os.makedirs(OUT_FOLDER)\n",
    "\n",
    "N_SAMPLES = 100             # number of samples to run validation/inference on\n",
    "MAX_WAV_VALUE = 32768.      # max wav value for scaling audio for writing to disk\n",
    "DENOISER_STRENGTH = 0.01    # strength of denoiser to remove model bias\n",
    "SIGMA = 0.6                 # std dev of gaussian distribution to sample from\n",
    "NORMALIZE = True            # whether to normalize generated audio\n",
    "SAMPLE_RATE = 22050         # sampling rate of all LJ-Speech audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[NeMo W 2020-08-31 14:17:40 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:40 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:40 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioLabelDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:40 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text._TarredAudioToTextDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:40 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:40 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.models.classification_models.MatchboxNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.losses.ctc.CTCLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.JasperNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.QuartzNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_label.AudioToSpeechLabelDataSet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.models.label_models.EncDecSpeakerLabelModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.modules.audio_preprocessing.AudioToMFCCPreprocessor'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASREncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoderClassification'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.losses.glow_tts_loss.GlowTTSLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.glow_tts.TextEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.glow_tts.FlowSpecDecoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.squeezewave.SqueezeWaveModule'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Encoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Decoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Postnet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.modules.waveglow.WaveGlowModule'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.models.glow_tts.GlowTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.models.squeezewave.SqueezeWaveModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.models.tacotron2.Tacotron2Model'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-31 14:17:41 experimental:28] Module <class 'nemo.collections.tts.models.waveglow.WaveGlowModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo I 2020-08-31 14:17:41 features:236] PADDING: 1\n[NeMo I 2020-08-31 14:17:41 features:245] STFT using exact pad\nNumber of trainable parameters: 23665184\n"
    }
   ],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nemo.collections.tts.helpers.helpers import remove_weightnorm\n",
    "from nemo.collections.tts.modules.squeezewave import OperationMode\n",
    "from nemo.collections.tts.models.squeezewave import SqueezeWaveModel\n",
    "\n",
    "# Load model with its config\n",
    "def load_squeezewave_model(cfg):\n",
    "    with open(cfg) as f:\n",
    "        config = OmegaConf.load(f)\n",
    "    del config.model['train_ds']\n",
    "    del config.model['validation_ds']\n",
    "    del config.model['optim']\n",
    "    model = SqueezeWaveModel(cfg=config['model'])\n",
    "    print('Number of trainable parameters:', model.num_weights)\n",
    "    return model\n",
    "\n",
    "# Load weights and prepare model for inference\n",
    "model = load_squeezewave_model(CONFIG)\n",
    "checkpoint = torch.load(CHECKPOINT)['state_dict']\n",
    "model.load_state_dict(checkpoint, strict=True)\n",
    "\n",
    "model.squeezewave = remove_weightnorm(model.squeezewave)\n",
    "model = model.eval()\n",
    "model.mode = OperationMode.validation\n",
    "model.squeezewave.mode = OperationMode.validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[NeMo I 2020-08-31 14:17:46 collections:171] Dataset loaded with 500 files totalling 0.91 hours\n[NeMo I 2020-08-31 14:17:46 collections:172] 0 files were filtered totalling 0.00 hours\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nemo.collections.tts.losses.waveglowloss import WaveGlowLoss\n",
    "from nemo.collections.tts.data.datalayers import AudioDataset\n",
    "from nemo.collections.tts.modules.denoiser import SqueezeWaveDenoiser\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    AudioDataset(DATA_MANIFEST, n_segments=-1, truncate_to=4096), 1,\n",
    "    shuffle=False, pin_memory=True, drop_last=False, num_workers=4,\n",
    ")\n",
    "\n",
    "loss_fn = WaveGlowLoss()\n",
    "\n",
    "if DENOISER_STRENGTH > 0:\n",
    "    denoiser = SqueezeWaveDenoiser(\n",
    "        model, n_mel=80, filter_length=1024, hop_length=512, win_length=1024, window='hann',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[audio_0.wav] loss: -5.88563 stoi: 0.96898\n[audio_1.wav] loss: -6.07639 stoi: 0.97734\n[audio_2.wav] loss: -6.20760 stoi: 0.97059\n[audio_3.wav] loss: -6.47904 stoi: 0.97270\n[audio_4.wav] loss: -6.14631 stoi: 0.97634\n[audio_5.wav] loss: -5.89166 stoi: 0.97234\n[audio_6.wav] loss: -6.03365 stoi: 0.97227\n[audio_7.wav] loss: -6.02054 stoi: 0.97181\n[audio_8.wav] loss: -5.90490 stoi: 0.96592\n[audio_9.wav] loss: -6.27257 stoi: 0.96852\n[audio_10.wav] loss: -6.33750 stoi: 0.96953\n[audio_11.wav] loss: -5.98078 stoi: 0.96732\n[audio_12.wav] loss: -6.07245 stoi: 0.96794\n[audio_13.wav] loss: -5.96641 stoi: 0.96922\n[audio_14.wav] loss: -6.10163 stoi: 0.97090\n[audio_15.wav] loss: -5.77293 stoi: 0.96386\n[audio_16.wav] loss: -6.27294 stoi: 0.96726\n[audio_17.wav] loss: -6.22984 stoi: 0.97070\n[audio_18.wav] loss: -6.31492 stoi: 0.96074\n[audio_19.wav] loss: -6.01833 stoi: 0.97529\n[audio_20.wav] loss: -6.20214 stoi: 0.97651\n[audio_21.wav] loss: -5.95097 stoi: 0.97590\n[audio_22.wav] loss: -5.87310 stoi: 0.97839\n[audio_23.wav] loss: -6.06598 stoi: 0.97077\n[audio_24.wav] loss: -5.60408 stoi: 0.96737\n[audio_25.wav] loss: -5.56294 stoi: 0.96110\n[audio_26.wav] loss: -5.76256 stoi: 0.97213\n[audio_27.wav] loss: -5.91339 stoi: 0.97118\n[audio_28.wav] loss: -6.01722 stoi: 0.97050\n[audio_29.wav] loss: -5.97668 stoi: 0.96520\n[audio_30.wav] loss: -6.10989 stoi: 0.96956\n[audio_31.wav] loss: -6.04631 stoi: 0.96579\n[audio_32.wav] loss: -6.19848 stoi: 0.96280\n[audio_33.wav] loss: -6.18442 stoi: 0.96883\n[audio_34.wav] loss: -5.93374 stoi: 0.97530\n[audio_35.wav] loss: -5.64810 stoi: 0.97547\n[audio_36.wav] loss: -6.37919 stoi: 0.96674\n[audio_37.wav] loss: -6.25417 stoi: 0.97540\n[audio_38.wav] loss: -5.72790 stoi: 0.96416\n[audio_39.wav] loss: -5.91674 stoi: 0.96277\n[audio_40.wav] loss: -6.05089 stoi: 0.96853\n[audio_41.wav] loss: -6.52564 stoi: 0.97234\n[audio_42.wav] loss: -5.88789 stoi: 0.97152\n[audio_43.wav] loss: -6.01970 stoi: 0.97047\n[audio_44.wav] loss: -6.11214 stoi: 0.96988\n[audio_45.wav] loss: -6.05987 stoi: 0.95748\n[audio_46.wav] loss: -5.69466 stoi: 0.97220\n[audio_47.wav] loss: -6.31362 stoi: 0.97440\n[audio_48.wav] loss: -6.23511 stoi: 0.96932\n[audio_49.wav] loss: -5.83576 stoi: 0.95934\n[audio_50.wav] loss: -5.47266 stoi: 0.96589\n[audio_51.wav] loss: -5.54336 stoi: 0.97369\n[audio_52.wav] loss: -5.93482 stoi: 0.97261\n[audio_53.wav] loss: -6.11070 stoi: 0.95894\n[audio_54.wav] loss: -5.39220 stoi: 0.97579\n[audio_55.wav] loss: -5.75802 stoi: 0.97111\n[audio_56.wav] loss: -6.14847 stoi: 0.97147\n[audio_57.wav] loss: -6.18500 stoi: 0.97206\n[audio_58.wav] loss: -6.34578 stoi: 0.96646\n[audio_59.wav] loss: -5.89415 stoi: 0.96389\n[audio_60.wav] loss: -5.70798 stoi: 0.97474\n[audio_61.wav] loss: -6.22555 stoi: 0.97787\n[audio_62.wav] loss: -5.88709 stoi: 0.96443\n[audio_63.wav] loss: -6.10001 stoi: 0.97132\n[audio_64.wav] loss: -6.10373 stoi: 0.97097\n[audio_65.wav] loss: -6.09429 stoi: 0.96590\n[audio_66.wav] loss: -6.40251 stoi: 0.96782\n[audio_67.wav] loss: -5.91219 stoi: 0.97186\n[audio_68.wav] loss: -5.73844 stoi: 0.97278\n[audio_69.wav] loss: -5.78052 stoi: 0.96563\n[audio_70.wav] loss: -6.15295 stoi: 0.97380\n[audio_71.wav] loss: -5.77092 stoi: 0.97202\n[audio_72.wav] loss: -6.24503 stoi: 0.97326\n[audio_73.wav] loss: -5.93122 stoi: 0.97315\n[audio_74.wav] loss: -5.93751 stoi: 0.96867\n[audio_75.wav] loss: -6.12343 stoi: 0.97041\n[audio_76.wav] loss: -6.24727 stoi: 0.97450\n[audio_77.wav] loss: -6.14389 stoi: 0.96750\n[audio_78.wav] loss: -5.85577 stoi: 0.97263\n[audio_79.wav] loss: -6.12250 stoi: 0.97495\n[audio_80.wav] loss: -6.16111 stoi: 0.96809\n[audio_81.wav] loss: -5.78109 stoi: 0.97298\n[audio_82.wav] loss: -6.60174 stoi: 0.97099\n[audio_83.wav] loss: -6.20123 stoi: 0.97220\n[audio_84.wav] loss: -6.29550 stoi: 0.97207\n[audio_85.wav] loss: -6.09806 stoi: 0.97002\n[audio_86.wav] loss: -6.09892 stoi: 0.96416\n[audio_87.wav] loss: -5.90034 stoi: 0.97065\n[audio_88.wav] loss: -6.15491 stoi: 0.97119\n[audio_89.wav] loss: -6.56313 stoi: 0.96856\n[audio_90.wav] loss: -5.71190 stoi: 0.96960\n[audio_91.wav] loss: -6.06728 stoi: 0.97419\n[audio_92.wav] loss: -6.26379 stoi: 0.96737\n[audio_93.wav] loss: -5.84908 stoi: 0.97034\n[audio_94.wav] loss: -6.14812 stoi: 0.96841\n[audio_95.wav] loss: -6.07837 stoi: 0.96481\n[audio_96.wav] loss: -6.17625 stoi: 0.95721\n[audio_97.wav] loss: -6.16591 stoi: 0.97431\n[audio_98.wav] loss: -5.86693 stoi: 0.96915\n[audio_99.wav] loss: -5.64973 stoi: 0.97250\nTraceback (most recent call last):\n  File \"/home/vincliu/anaconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n    send_bytes(obj)\n  File \"/home/vincliu/anaconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/home/vincliu/anaconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/home/vincliu/anaconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\n"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "from pystoi import stoi\n",
    "from maracas.maracas import asl_meter   # requires numba==0.44 for autojit (librosa usually installs numba==0.48)\n",
    "\n",
    "from nemo.collections.asr.parts.features import FilterbankFeatures\n",
    "\n",
    "for i, (audio, audio_len) in enumerate(dataloader):\n",
    "    if i == N_SAMPLES: break\n",
    "\n",
    "    # Get loss and audio reconstruction\n",
    "    with torch.no_grad():\n",
    "        spect, spect_len = model.audio_to_melspec_precessor(audio, audio_len)\n",
    "        z, log_s_list, log_det_W_list, audio_pred, *_ = model.squeezewave(\n",
    "            spect=spect, audio=audio, run_inverse=True, sigma=SIGMA,\n",
    "        )\n",
    "        loss = loss_fn(\n",
    "            z=z, log_s_list=log_s_list, log_det_W_list=log_det_W_list, sigma=model.sigma,\n",
    "        )\n",
    "\n",
    "    # Remove model bias\n",
    "    if DENOISER_STRENGTH > 0:\n",
    "        audio_pred = denoiser(audio_pred, strength=DENOISER_STRENGTH)\n",
    "    \n",
    "    audio_pred = audio_pred.detach().cpu().numpy().squeeze()\n",
    "    audio = audio.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # Normalize active speech levels (asl)\n",
    "    if NORMALIZE:\n",
    "        asl_level = -26\n",
    "        audio_pred = audio_pred / 10 ** (asl_meter(audio_pred, SAMPLE_RATE) / 20) * 10 ** (asl_level / 20)\n",
    "\n",
    "    # Compute stoi (short-time objective intelligibility)\n",
    "    stoi_score = stoi(audio, audio_pred, SAMPLE_RATE, extended=False)\n",
    "\n",
    "    # Save original and synthesized audio to disk\n",
    "    filename = 'audio_{}.wav'.format(i)\n",
    "    audio_pred = (audio_pred * MAX_WAV_VALUE).astype('int16')\n",
    "    sf.write(os.path.join(OUT_FOLDER, 'synth_' + filename), audio_pred, samplerate=SAMPLE_RATE)\n",
    "    audio = (audio * MAX_WAV_VALUE).astype('int16')\n",
    "    sf.write(os.path.join(OUT_FOLDER, 'orig_' + filename), audio, samplerate=SAMPLE_RATE)\n",
    "\n",
    "    print('[{}] loss: {:.5f} stoi: {:.5f}'.format(filename, loss.item(), stoi_score.item()))"
   ]
  }
 ]
}