{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitpy36condade6bc17c0cdd4e2d8c72d4203452925a",
   "display_name": "Python 3.6.10 64-bit ('py36': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace these macros accordingly\n",
    "ROOT = '/home/vincliu/vocoder/NeMo'\n",
    "os.chdir(ROOT)\n",
    "\n",
    "CHECKPOINT = os.path.join('nemo_experiments', 'SqueezeWave', '2020-08-26_13-36-50', 'checkpoints', 'SqueezeWave--last.ckpt')\n",
    "CONFIG = os.path.join('examples', 'tts', 'conf', 'squeezewave.yaml')\n",
    "DATA_MANIFEST = os.path.join('data', 'nvidia_ljspeech_test.json')\n",
    "OUT_FOLDER = os.path.join('samples')\n",
    "if not os.path.isdir(OUT_FOLDER):\n",
    "    os.makedirs(OUT_FOLDER)\n",
    "\n",
    "N_SAMPLES = 10\n",
    "MAX_WAV_VALUE = 32768.\n",
    "DENOISER_STRENGTH = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioLabelDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text._TarredAudioToTextDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.models.classification_models.MatchboxNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.losses.ctc.CTCLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.JasperNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.models.ctc_models.QuartzNet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_label.AudioToSpeechLabelDataSet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.models.label_models.EncDecSpeakerLabelModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.modules.audio_preprocessing.AudioToMFCCPreprocessor'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASREncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoderClassification'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.squeezewave.SqueezeWaveModule'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.glow_tts.TextEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.glow_tts.FlowSpecDecoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Encoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Decoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.tacotron2.Postnet'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.modules.waveglow.WaveGlowModule'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.models.squeezewave.SqueezeWaveModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.losses.glow_tts_loss.GlowTTSLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.models.glow_tts.GlowTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.models.tacotron2.Tacotron2Model'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo W 2020-08-26 16:27:18 experimental:28] Module <class 'nemo.collections.tts.models.waveglow.WaveGlowModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n[NeMo I 2020-08-26 16:27:18 features:233] PADDING: 1\n[NeMo I 2020-08-26 16:27:18 features:242] STFT using exact pad\n23665184\n"
    }
   ],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nemo.collections.tts.modules.squeezewave import OperationMode\n",
    "from nemo.collections.tts.models.squeezewave import SqueezeWaveModel\n",
    "\n",
    "# Remove all weight norm reparameterizations\n",
    "def remove_weightnorm(model):\n",
    "    squeezewave = model.squeezewave\n",
    "    assert hasattr(squeezewave, 'wavenet')\n",
    "    for i in range(len(squeezewave.wavenet)):\n",
    "        wavenet = squeezewave.wavenet[i]\n",
    "        wavenet.start = torch.nn.utils.remove_weight_norm(wavenet.start)\n",
    "        wavenet.cond_layer = torch.nn.utils.remove_weight_norm(wavenet.cond_layer)\n",
    "        for j in range(wavenet.n_layers):\n",
    "            res_skip_layer = wavenet.res_skip_layers[j]\n",
    "            res_skip_layer = torch.nn.utils.remove_weight_norm(res_skip_layer)\n",
    "    return model\n",
    "\n",
    "# Load model with its config\n",
    "def load_squeezewave_model(cfg):\n",
    "    with open(cfg) as f:\n",
    "        config = OmegaConf.load(f)\n",
    "    del config.model['train_ds']\n",
    "    del config.model['validation_ds']\n",
    "    del config.model['optim']\n",
    "    model = SqueezeWaveModel(cfg=config['model'])\n",
    "    print('Number of trainable parameters:', model.num_weights)\n",
    "    return model\n",
    "\n",
    "# Load weights and prepare model for inference\n",
    "model = load_squeezewave_model(CONFIG)\n",
    "checkpoint = torch.load(CHECKPOINT)['state_dict']\n",
    "model.load_state_dict(checkpoint, strict=True)\n",
    "model = remove_weightnorm(model)\n",
    "model = model.eval()\n",
    "model.mode = OperationMode.validation\n",
    "model.squeezewave.mode = OperationMode.validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[NeMo I 2020-08-26 16:27:28 collections:171] Dataset loaded with 500 files totalling 0.91 hours\n[NeMo I 2020-08-26 16:27:28 collections:172] 0 files were filtered totalling 0.00 hours\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nemo.collections.tts.losses.waveglowloss import WaveGlowLoss\n",
    "from nemo.collections.tts.data.datalayers import AudioDataset\n",
    "\n",
    "dataset = AudioDataset(DATA_MANIFEST, n_segments=-1, truncate_to=4096)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "loss_fn = WaveGlowLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo.collections.asr.parts.features import STFTExactPad\n",
    "\n",
    "class Denoiser(torch.nn.Module):\n",
    "    def __init__(self, model, n_mel=80, filter_length=1024, hop_length=512, win_length=None, window='hann'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stft = STFTExactPad(\n",
    "            filter_length=filter_length, hop_length=hop_length, win_length=win_length, window=window,\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mel_input = torch.zeros((n_mel, 88)).to(model.device)\n",
    "            bias_audio = model.convert_spectrogram_to_audio(mel_input, sigma=0.0)\n",
    "            bias_spec, _ = self.stft.transform(bias_audio.unsqueeze(0))\n",
    "            self.bias_spec = bias_spec[:, :, 0][:, :, None]\n",
    "\n",
    "        model.mode = OperationMode.validation\n",
    "        model.squeezewave.mode = OperationMode.validation\n",
    "\n",
    "    def forward(self, audio, strength=0.1):\n",
    "        audio_spec, audio_angles = self.stft.transform(audio)\n",
    "        audio_spec_denoised = audio_spec - self.bias_spec * strength\n",
    "        audio_spec_denoised = torch.clamp(audio_spec_denoised, 0.0)\n",
    "        audio_denoised = self.stft.inverse(audio_spec_denoised, audio_angles)\n",
    "        return audio_denoised\n",
    "\n",
    "if DENOISER_STRENGTH > 0:\n",
    "    denoiser = Denoiser(model, n_mel=80, filter_length=1024, hop_length=512, win_length=None, window='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[audio_0.wav] loss: -5.559649467468262\n[audio_1.wav] loss: -5.758926868438721\n[audio_2.wav] loss: -5.894212245941162\n[audio_3.wav] loss: -6.185265064239502\n[audio_4.wav] loss: -5.8412370681762695\n[audio_5.wav] loss: -5.563751697540283\n[audio_6.wav] loss: -5.731264114379883\n[audio_7.wav] loss: -5.682397842407227\n[audio_8.wav] loss: -5.571674823760986\n[audio_9.wav] loss: -5.983452320098877\n"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "from nemo.collections.asr.parts.features import FilterbankFeatures\n",
    "\n",
    "for i, (audio, audio_len) in enumerate(dataloader):\n",
    "    if i == N_SAMPLES: break\n",
    "    # Get loss and audio reconstruction\n",
    "    with torch.no_grad():\n",
    "        z, log_s_list, log_det_W_list, audio_pred, *_ = model(audio=audio, audio_len=audio_len, run_inverse=True)\n",
    "        loss = loss_fn(z=z, log_s_list=log_s_list, log_det_W_list=log_det_W_list, sigma=model.sigma)\n",
    "\n",
    "    filename = 'audio_{}.wav'.format(i)\n",
    "    print('[{}] loss: {}'.format(filename, loss.detach().cpu().numpy()))\n",
    "\n",
    "    if DENOISER_STRENGTH > 0:\n",
    "        audio_pred = denoiser(audio_pred, strength=DENOISER_STRENGTH)\n",
    "\n",
    "    audio_pred = (audio_pred.detach().cpu().numpy().squeeze() * MAX_WAV_VALUE).astype('int16')\n",
    "    sf.write(os.path.join(OUT_FOLDER, 'synth_' + filename), audio_pred, samplerate=22050)\n",
    "\n",
    "    audio = (audio.detach().cpu().numpy().squeeze() * MAX_WAV_VALUE).astype('int16')\n",
    "    sf.write(os.path.join(OUT_FOLDER, 'orig_' + filename), audio, samplerate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}