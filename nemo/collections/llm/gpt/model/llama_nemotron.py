# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# pylint: disable=C0301
from dataclasses import dataclass
from functools import partial
from pathlib import Path
from typing import TYPE_CHECKING, Annotated, Callable, Optional, Union

import torch
from torch import nn

from nemo.collections.llm import GPTConfig
from nemo.collections.llm.gpt.model.base import GPTModel, torch_dtype_from_mcore_config
from nemo.collections.llm.gpt.model.llama import (
    Llama31Config,
    Llama31Config8B,
    Llama31Config70B,
    Llama31Config405B,
    LlamaConfig,
)
from nemo.collections.llm.utils import Config
from nemo.lightning import OptimizerModule, io, teardown
from nemo.lightning.io.state import TransformFns
from nemo.lightning.pytorch.utils import dtype_from_hf
from nemo.utils import logging
from nemo.utils.import_utils import safe_import

_, HAVE_TE = safe_import("transformer_engine")

if HAVE_TE:
    from megatron.core.models.gpt.heterogeneous.heterogeneous_layer_specs import get_gpt_heterogeneous_layer_spec
    from megatron.core.transformer.heterogeneous.heterogeneous_config import HeterogeneousTransformerConfig
    from megatron.core.transformer.spec_utils import ModuleSpec

if TYPE_CHECKING:
    from transformers import LlamaConfig as HFLlamaConfig
    from transformers import LlamaForCausalLM

    from nemo.collections.common.tokenizers.huggingface.auto_tokenizer import AutoTokenizer
    from nemo.collections.common.tokenizers.tokenizer_spec import TokenizerSpec


@dataclass
class Llama31NemotronNano8BConfig(Llama31Config8B):
    """Configuration for an Llama31-Nemotron-Nano model."""

    kv_channels: int = 128


class Llama31Nemotron70BConfig(Llama31Config70B):
    """Configuration for an Llama31-Nemotron-70B model."""

    kv_channels: int = 128


# Llama-Nemotron Super/Ultra uses heterogeneous architecture
def heterogeneous_layer_spec(config: "GPTConfig") -> ModuleSpec:
    """Determine the most appropriate layer specification based on availability.

    Uses Transformer Engine specs if available, otherwise falls back to local implementation.

    Args:
        config: GPT configuration object

    Returns:
        ModuleSpec: The selected module specification
    """
    return get_gpt_heterogeneous_layer_spec(config, use_te=HAVE_TE)


@dataclass
class Llama33NemotronSuper49BConfig(Llama31Config70B, HeterogeneousTransformerConfig):
    """Configuration for an Llama31-Nemotron-Nano model."""

    hidden_size: int = 8192
    num_attention_heads: int = 64
    num_layers: int = 80
    heterogeneous_layers_config_path: str = None
    heterogeneous_layers_config_encoded_json: str = (
        '{\n  "_name_or_path": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",\n  "architectures": [\n    "DeciLMForCausalLM"\n  ],\n  "attention_bias": false,\n  "attention_dropout": 0.0,\n  "auto_map": {\n    "AutoConfig": "nvidia/Llama-3_3-Nemotron-Super-49B-v1--configuration_decilm.DeciLMConfig",\n    "AutoModelForCausalLM": "nvidia/Llama-3_3-Nemotron-Super-49B-v1--modeling_decilm.DeciLMForCausalLM"\n  },\n  "block_configs": [\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 2.625,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 2.625,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 2.625,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 3.28125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 2.625,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 2.625,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 2.625,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.3125,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 0.5,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 0.5,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 0.5,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 0.5,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 1.0,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 0.5,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": null,\n        "no_op": true,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 0.5,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    },\n    {\n      "attention": {\n        "n_heads_in_group": 8,\n        "no_op": false,\n        "num_sink_tokens": null,\n        "replace_with_linear": false,\n        "sparsify": null,\n        "unshifted_sink": false,\n        "use_prefill_window_in_sink_attention": false,\n        "window_length": null\n      },\n      "ffn": {\n        "ffn_mult": 5.25,\n        "no_op": false,\n        "replace_with_linear": false,\n        "sparsify": null\n      }\n    }\n  ],\n  "bos_token_id": 128000,\n  "eos_token_id": [\n    128001,\n    128008,\n    128009\n  ],\n  "hidden_act": "silu",\n  "hidden_size": 8192,\n  "initializer_range": 0.02,\n  "intermediate_size": null,\n  "max_position_embeddings": 131072,\n  "mlp_bias": false,\n  "model_type": "nemotron-nas",\n  "num_attention_heads": 64,\n  "num_hidden_layers": 80,\n  "num_key_value_heads": null,\n  "pretraining_tp": 1,\n  "rms_norm_eps": 1e-05,\n  "rope_scaling": {\n    "factor": 8.0,\n    "high_freq_factor": 4.0,\n    "low_freq_factor": 1.0,\n    "original_max_position_embeddings": 8192,\n    "rope_type": "llama3"\n  },\n  "rope_theta": 500000.0,\n  "tie_word_embeddings": false,\n  "torch_dtype": "bfloat16",\n  "transformers_version": "4.48.3",\n  "use_cache": true,\n  "vocab_size": 128256\n}\n'  # fmt: off
    )
    transformer_layer_spec: Union[ModuleSpec, Callable[["GPTConfig"], ModuleSpec]] = heterogeneous_layer_spec


@dataclass
class Llama33NemotronUltra253BConfig(Llama31Config405B, HeterogeneousTransformerConfig):
    """Configuration for an Llama31-Nemotron-Nano model."""

    hidden_size: int = 8192
    num_attention_heads: int = 64
    num_layers: int = 126
    heterogeneous_layers_config_path: str = None
    heterogeneous_layers_config_encoded_json: str = (
        '{"_name_or_path":"llama_nemotron_ultra","architectures":["DeciLMForCausalLM"],"attention_bias":false,"attention_dropout":0.0,"auto_map":{"AutoConfig":"configuration_decilm.DeciLMConfig","AutoModelForCausalLM":"modeling_decilm.DeciLMForCausalLM"},"block_configs":[{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":0.4875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":0.975,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.4625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.4625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.4625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.4625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.4625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.4625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":3.4125,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":3.4125,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":3.4125,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.925,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.925,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":36.5625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":39.0,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":31.40625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":27.5625,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":1.95,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":null,"no_op":true,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":null,"no_op":true,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":3.4125,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":4.875,"no_op":false,"replace_with_linear":false,"sparsify":null}},{"attention":{"n_heads_in_group":16,"no_op":false,"num_sink_tokens":null,"replace_with_linear":false,"sparsify":null,"unshifted_sink":false,"use_prefill_window_in_sink_attention":false,"window_length":null},"ffn":{"ffn_mult":2.4375,"no_op":false,"replace_with_linear":false,"sparsify":null}}],"bos_token_id":128000,"eos_token_id":[128001,128008,128009],"hidden_act":"silu","hidden_size":16384,"initializer_range":0.02,"intermediate_size":null,"max_position_embeddings":131072,"mlp_bias":false,"model_type":"nemotron-nas","num_attention_heads":128,"num_hidden_layers":162,"num_key_value_heads":null,"pretraining_tp":1,"rms_norm_eps":1e-05,"rope_scaling":{"factor":16.0,"high_freq_factor":4.0,"low_freq_factor":1.0,"original_max_position_embeddings":8192,"rope_type":"llama3"},"rope_theta":500000.0,"tie_word_embeddings":false,"torch_dtype":"bfloat16","transformers_version":"4.45.1","use_cache":true,"vocab_size":128256}'
    )
    transformer_layer_spec: Union[ModuleSpec, Callable[["GPTConfig"], ModuleSpec]] = heterogeneous_layer_spec


class LlamaNemotronModel(GPTModel):
    """Llama-Nemotron model implementation based on the GPT model architecture.

    This class provides a high-level interface for Llama-Nemotron models,
    implementing the specific architecture and settings needed for Llama-Nemotron models.
    """

    def __init__(
        self,
        config: Annotated[Optional[LlamaConfig], Config[LlamaConfig]] = None,
        optim: Optional[OptimizerModule] = None,
        tokenizer: Optional["TokenizerSpec"] = None,
        model_transform: Optional[Callable[[nn.Module], nn.Module]] = None,
    ):
        super().__init__(
            config or Llama31NemotronNano8BConfig(), optim=optim, tokenizer=tokenizer, model_transform=model_transform
        )


@io.model_importer(LlamaNemotronModel, "hf")
class HFLlamaNemotronImporter(io.ModelConnector["LlamaForCausalLM", LlamaNemotronModel]):
    """Importer for converting Hugging Face Llama-Nemotron models to NeMo format.

    This class handles the conversion of Hugging Face's LlamaForCausalLM models
    to NeMo's LlamaNemotronModel format, including weight mapping and configuration translation.
    """

    def init(self) -> LlamaNemotronModel:
        """Initialize a NeMo LlamaModel instance.

        Returns:
            LlamaModel: Initialized NeMo Llama model with the appropriate configuration
                        and tokenizer.
        """
        return LlamaNemotronModel(self.config, tokenizer=self.tokenizer)

    def apply(self, output_path: Path) -> Path:
        """Apply the conversion from HF to NeMo format.

        Args:
            output_path: Path where the converted model will be saved

        Returns:
            Path: Path to the saved NeMo model
        """
        from transformers import AutoModelForCausalLM, LlamaForCausalLM

        logging.info(f'Load HF model {str(self)}')
        if 'Nano' in str(self):
            source = LlamaForCausalLM.from_pretrained(str(self), torch_dtype='auto')
        else:
            source = AutoModelForCausalLM.from_pretrained(str(self), trust_remote_code=True, torch_dtype='auto')
        logging.info('Initialize NeMo Nemotron-Llama model')
        target = self.init()
        trainer = self.nemo_setup(target)
        self.convert_state(source, target)
        self.nemo_save(output_path, trainer)

        print(f"Converted Llama-Nemotron model to Nemo, model saved to {output_path} in {source.dtype}.")

        teardown(trainer, target)
        del trainer, target

        return output_path

    def convert_state(self, source, target):
        """Convert state dict from HF format to NeMo format.

        Maps the weights from the HF model to the NeMo model according to
        the appropriate mapping scheme.

        Args:
            source: Source HF model
            target: Target NeMo model

        Returns:
            The result of applying the transforms
        """
        mapping = {
            "model.embed_tokens.weight": "embedding.word_embeddings.weight",
            "model.layers.*.self_attn.o_proj.weight": "decoder.layers.*.self_attention.linear_proj.weight",
            "model.layers.*.mlp.down_proj.weight": "decoder.layers.*.mlp.linear_fc2.weight",
            "model.layers.*.input_layernorm.weight": "decoder.layers.*.self_attention.linear_qkv.layer_norm_weight",
            "model.layers.*.post_attention_layernorm.weight": "decoder.layers.*.mlp.linear_fc1.layer_norm_weight",
            "model.norm.weight": "decoder.final_layernorm.weight",
            "lm_head.weight": "output_layer.weight",
        }
        if getattr(source.config, "tie_word_embeddings", False):
            del mapping["lm_head.weight"]

        transforms = [
            io.state_transform(
                source_key=(
                    "model.layers.*.self_attn.q_proj.weight",
                    "model.layers.*.self_attn.k_proj.weight",
                    "model.layers.*.self_attn.v_proj.weight",
                ),
                target_key="decoder.layers.*.self_attention.linear_qkv.weight",
                fn=TransformFns.merge_qkv,
            ),
            io.state_transform(
                source_key=("model.layers.*.mlp.gate_proj.weight", "model.layers.*.mlp.up_proj.weight"),
                target_key="decoder.layers.*.mlp.linear_fc1.weight",
                fn=TransformFns.merge_fc1,
            ),
        ]
        return io.apply_transforms(source, target, mapping=mapping, transforms=transforms)

    @property
    def tokenizer(self) -> "AutoTokenizer":
        """Get the tokenizer for the HF model.

        Returns:
            AutoTokenizer: Tokenizer instance initialized from the HF model's tokenizer
        """
        from nemo.collections.common.tokenizers.huggingface.auto_tokenizer import AutoTokenizer

        return AutoTokenizer(self.save_hf_tokenizer_assets(str(self)), trust_remote_code=True)

    @property
    def config(self) -> LlamaConfig:
        """Create a NeMo LlamaNemotronConfig from the HF model config.

        Translates the HF configuration parameters to the equivalent NeMo
        configuration.

        Returns:
            LlamaConfig: NeMo configuration for Llama models
        """
        from transformers import AutoConfig, GenerationConfig

        source = AutoConfig.from_pretrained(str(self), trust_remote_code=True)
        try:
            generation_config = GenerationConfig.from_pretrained(str(self))
        except Exception:
            generation_config = None

        def make_vocab_size_divisible_by(vocab_size):
            base = 128
            while vocab_size % base != 0:
                base //= 2
            return base

        assert getattr(source, 'rope_scaling', None), 'Llama-Nemotron model should have rope scaling'
        if getattr(source, 'block_configs') is not None:
            # Convert heterogeneous model (Llama-Nemotron Super/Ultra)
            target_class = (
                Llama33NemotronSuper49BConfig if source.num_hidden_layers == 80 else Llama33NemotronUltra253BConfig
            )
            cls = partial(
                target_class,
                heterogeneous_layers_config_encoded_json=source.to_json_string(),
                heterogeneous_layers_config_path=None,  # We directly load the block config as json
                scale_factor=source.rope_scaling.get("factor", 8.0),
                # For heterogeneous model, GQA is defined in each block config.
                # Llama-Nemotron has the same GQA across all non no-op attention layers.
                # We expose it to config.num_query_groups to make the merge_qkv work.
                # Here we assume block 0 is non no-ops for the attention
                num_query_groups=source.num_attention_heads // source.block_configs[0].attention.n_heads_in_group,
            )
        else:
            # Convert homogeneous model (Llama-Nemotron Nano/70B)
            target_class = Llama31NemotronNano8BConfig if source.num_hidden_layers == 32 else Llama31Nemotron70BConfig
            cls = partial(target_class, num_query_groups=source.num_key_value_heads)

        output = cls(
            num_layers=source.num_hidden_layers,
            hidden_size=source.hidden_size,
            ffn_hidden_size=source.intermediate_size,
            num_attention_heads=source.num_attention_heads,
            kv_channels=getattr(source, "head_dim", None),
            scale_factor=source.rope_scaling.get('factor', 8.0),
            init_method_std=source.initializer_range,
            layernorm_epsilon=source.rms_norm_eps,
            seq_length=source.max_position_embeddings,
            rotary_base=source.rope_theta,
            gated_linear_unit=True,
            make_vocab_size_divisible_by=make_vocab_size_divisible_by(source.vocab_size),
            share_embeddings_and_output_weights=getattr(source, "tie_word_embeddings", False),
            fp16=(dtype_from_hf(source) == torch.float16),
            bf16=(dtype_from_hf(source) == torch.bfloat16),
            params_dtype=dtype_from_hf(source),
            generation_config=generation_config,
        )

        return output


@io.model_exporter(LlamaNemotronModel, "hf")
class HFLlamaNemotronExporter(io.ModelConnector[LlamaNemotronModel, "LlamaForCausalLM"]):
    """Exporter for converting NeMo Llama-Nemotron models to Hugging Face format.

    This class handles the conversion of NeMo's LlamaNemotronModel to Hugging Face's
    LlamaForCausalLM format, including weight mapping and configuration translation.
    """

    def init(self, dtype=torch.bfloat16, model_name=None) -> "LlamaForCausalLM":
        """Initialize a HF LlamaForCausalLM instance.

        Args:
            dtype: Data type for model parameters

        Returns:
            LlamaForCausalLM: Initialized HF Llama model
        """
        from transformers import AutoModelForCausalLM
        from transformers.modeling_utils import no_init_weights

        with no_init_weights(True):
            if model_name is None:
                # Llama-Nemotron Nano / Llama31Nemotron70BConfig
                return AutoModelForCausalLM.from_config(self.config, torch_dtype=dtype)
            # Llama-Nemotron Super/Ultra
            hf_model = AutoModelForCausalLM.from_pretrained(
                model_name,
                trust_remote_code=True,
                torch_dtype=dtype,
            )
            # Register the AutoModel Hook so that the custom modeling files are saved during save_pretrained()
            type(hf_model).register_for_auto_class("AutoModelForCausalLM")
            return hf_model

    def apply(self, output_path: Path, target_model_name=None) -> Path:
        """Apply the conversion from NeMo to HF format.

        Args:
            output_path: Path where the converted model will be saved

        Returns:
            Path: Path to the saved HF model
        """
        logging.info("Loading Llama-Nemotron NeMo checkpoint..")
        source, _ = self.nemo_load(str(self))
        if target_model_name is None:
            # Llama-Nemotron Super/Ultra uses customize modeling class
            is_heterogeneous = isinstance(source.config, HeterogeneousTransformerConfig)
            if is_heterogeneous:
                num_layers = source.config.num_layers
                if num_layers == 80:
                    target_model_name = 'nvidia/Llama-3_3-Nemotron-Super-49B-v1'
                elif num_layers == 162:
                    target_model_name = 'nvidia/Llama-3_1-Nemotron-Ultra-253B-v1'
                else:
                    raise ValueError(
                        'Unknown target model. Currently only support exporting Llama-Nemotron Nano/Super/Ultra models.'
                    )

        target = self.init(torch_dtype_from_mcore_config(source.config), target_model_name)
        target = self.convert_state(source, target)

        target = target.cpu()
        target.save_pretrained(output_path)
        self.tokenizer.tokenizer.save_pretrained(output_path)

        return output_path

    def convert_state(self, source, target):
        """Convert state dict from NeMo format to HF format.

        Maps the weights from the NeMo model to the HF model according to
        the appropriate mapping scheme.

        Args:
            source: Source NeMo model
            target: Target HF model

        Returns:
            The target model with weights transferred from source
        """
        mapping = {
            "decoder.layers.*.self_attention.linear_proj.weight": "model.layers.*.self_attn.o_proj.weight",
            "decoder.layers.*.mlp.linear_fc2.weight": "model.layers.*.mlp.down_proj.weight",
            "decoder.layers.*.self_attention.linear_qkv.layer_norm_weight": "model.layers.*.input_layernorm.weight",
            "decoder.layers.*.mlp.linear_fc1.layer_norm_weight": "model.layers.*.post_attention_layernorm.weight",
            "decoder.final_layernorm.weight": "model.norm.weight",
        }

        transforms = [
            io.state_transform(
                source_key="decoder.layers.*.self_attention.linear_qkv.weight",
                target_key=(
                    "model.layers.*.self_attn.q_proj.weight",
                    "model.layers.*.self_attn.k_proj.weight",
                    "model.layers.*.self_attn.v_proj.weight",
                ),
                fn=TransformFns.split_qkv,
            ),
            io.state_transform(
                source_key="decoder.layers.*.mlp.linear_fc1.weight",
                target_key=("model.layers.*.mlp.gate_proj.weight", "model.layers.*.mlp.up_proj.weight"),
                fn=TransformFns.split_fc1,
            ),
            io.state_transform(
                source_key="embedding.word_embeddings.weight",
                target_key="model.embed_tokens.weight",
                fn=TransformFns.prune_padding,
            ),
            io.state_transform(
                source_key="output_layer.weight",
                target_key="lm_head.weight",
                fn=TransformFns.prune_padding,
            ),
        ]

        return io.apply_transforms(
            source,
            target,
            mapping=mapping,
            transforms=transforms,
        )

    @property
    def tokenizer(self) -> "TokenizerSpec":
        """Get the tokenizer from the NeMo model.

        Returns:
            TokenizerSpec: Tokenizer from the NeMo model
        """
        return io.load_context(str(self), subpath="model").tokenizer

    @property
    def config(self) -> "HFLlamaConfig":
        """Create a HF LlamaConfig from the NeMo model config.
        This function should only be invoked for Non-heterogeneous transformers (i.e. Nano).

        Translates the NeMo configuration parameters to the equivalent HF
        configuration.

        Returns:
            HFLlamaConfig: HF configuration for Llama models
        """

        source: LlamaConfig = io.load_context(str(self), subpath="model.config")
        assert not isinstance(source, HeterogeneousTransformerConfig)

        from transformers import LlamaConfig as HFLlamaConfig

        rope_scaling = None
        # For Llama 3.1 and Llama 3.2, rope_scaling is used and thus needed to parsed to the config
        if isinstance(source, Llama31Config):
            rope_scaling = {
                'factor': source.scale_factor,
                'low_freq_factor': source.low_freq_factor,
                'high_freq_factor': source.high_freq_factor,
                'original_max_position_embeddings': source.old_context_len,
                'rope_type': 'llama3',
            }
        return HFLlamaConfig(
            num_hidden_layers=source.num_layers,
            hidden_size=source.hidden_size,
            intermediate_size=source.ffn_hidden_size,
            num_attention_heads=source.num_attention_heads,
            head_dim=source.kv_channels,
            max_position_embeddings=source.seq_length,
            initializer_range=source.init_method_std,
            rms_norm_eps=source.layernorm_epsilon,
            num_key_value_heads=source.num_query_groups,
            rope_theta=source.rotary_base,
            vocab_size=self.tokenizer.vocab_size,
            tie_word_embeddings=source.share_embeddings_and_output_weights,
            rope_scaling=rope_scaling,
            bos_token_id=self.tokenizer.bos_id,
            eos_token_id=self.tokenizer.eos_id,
        )


__all__ = [
    "LlamaNemotronModel",
    "Llama31NemotronNano8BConfig",
    "Llama33NemotronSuper49BConfig",
    "Llama33NemotronUltra253BConfig",
    "Llama31Nemotron70BConfig",
]
