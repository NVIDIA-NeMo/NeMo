## NeMo NLP/LLM Collection

The NeMo NLP/LLM Collection is designed to provide comprehensive support for on-demand large language community models as well as Nvidia's top LLM offerings. Leveraging the constantly evolving Megatron Core and Transformer Engine libraries, our LLM collection is highly optimized, enabling NeMo users to perform foundation model training across thousands of GPUs and fine-tuning LLMs with SFT and PEFT. Additionally, we prioritize supporting TRTLLM export for the released models, which can accelerate inference by 2-3x depending on the model size. Here's a detailed list of the models currently supported within the LLM collection:

- **Bert**
- **GPT-style models**
- **Falcon**
- **code-llama 7B**
- **Mixtral**

Our documentation offers comprehensive insights into each supported model, facilitating seamless integration and utilization within your projects.
