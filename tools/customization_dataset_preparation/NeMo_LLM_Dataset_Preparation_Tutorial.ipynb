{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf6m_oTwDwOd"
      },
      "source": [
        "# Customization Dataset Preparation\n",
        "\n",
        "NeMo LLM Customization service requires data to be in the form of .jsonl file with each line having only two fields (namely prompt and completion).\n",
        "\n",
        "However, you might not have your data readily in this format (or even filetype).\n",
        "\n",
        "This tutorial will help you to convert from what you have to what you will need quickly and easily.\n",
        "\n",
        "What you will need:\n",
        "\n",
        "\n",
        "1.   NeMo LLM Python Client\n",
        "2.   Your datafile (in the form of a .jsonl, .json, .csv, .tsv or .xlsx). Each row should contain one sample. Make sure that the directory your file is in is readable and writeable, otherwise, please change it using chmod. Don't worry, we will not overwrite your existing file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxAKz1TSGCvI"
      },
      "source": [
        "# Proof-read/validate data already in prompt-and-completion format\n",
        "\n",
        "If you have your dataset in the prompt and completion format, you can use this tool to check that the way your dataset is prepared is suitable for the  Customization service. \n",
        "\n",
        "With close to a dozen consideration factors that makes training optimal, there might just be something you overlook (we all do!). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vapPZo8DsId"
      },
      "outputs": [],
      "source": [
        "#cd to the directory containing dataset_validation.py\n",
        "\n",
        "!python dataset_validation.py --filename <filename>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiJ-6ZpiHSIm"
      },
      "source": [
        "# Making changes following tool recommendations\n",
        "\n",
        "After running this code, you see a list of suggestions to use under ACTIONABLE MESSAGES as well as some insights into your dataset under INFORMATIONAL MESSAGES.\n",
        "\n",
        "We suggest you prioritize changes suggested under ACTIONABLE MESSAGES but also have a look at the INFORMATIONAL MESSAGES to ensure that changes are done in an expected manner.\n",
        "\n",
        "Many ACTIONABLE MESSAGES will include an additional you can add to previous command such as `--drop_duplicates` or `--long_seq_model`\n",
        "\n",
        "For instance, if you would like to drop duplicate samples, run\n",
        "\n",
        "```\n",
        "!python dataset_validation.py --filename <filename> --drop_duplicates\n",
        "```\n",
        "\n",
        "There will also be recommendations that have to be done outside of the functionality of this tool. For instance, if you have too few datapoints, you might need to add a few more.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks6FbS4SJJ0P"
      },
      "source": [
        "# Formatting data into Prompt/Completion\n",
        "\n",
        "If you have data that is not already in Prompt/Completion format, we can also help.\n",
        "\n",
        "For instances, if you are working on a Question Answering Task, you would typically have the columns `context`, `question` and `answer`\n",
        "\n",
        "To format context and question into a prompt, we can use the flag \n",
        "\n",
        "```\n",
        "--prompt_template \"Context: {context} Question: {question} Answer:\"\n",
        "```\n",
        "\n",
        "This tool will make use of this template to convert your data into a prompt field\n",
        "\n",
        "Similarly, this can work for the completion template\n",
        "\n",
        "```\n",
        "--completion_template \"{answer}\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm_SVyUOHS5D"
      },
      "outputs": [],
      "source": [
        "!python dataset_validation.py --filename <filename> --prompt_template \"Context: {context} Question: {question} Answer:\" --completion_template \"{answer}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qsi5OpSIkKk"
      },
      "source": [
        "# Additional Methods included in this tool\n",
        "\n",
        "\n",
        "1.   `--long_seq_model` :Use this flag to allow the preparation tool to allow a higher max sequence length (from 10000 chars to 40000 chars)\n",
        "2.   `--drop_duplicates` : Use this flag to drop rows that are exactly the same for both prompt and completion\n",
        "3.   `--split_train_validation` : Use this flag to split one file into separate train and validation files.\n",
        "4.   `--val_proportion 0.1`: Use a float (default 0.1) between 0 and 1 to control how much of the dataset to allocate to the validation set and the remaining for the train dataset.\n",
        "      \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
