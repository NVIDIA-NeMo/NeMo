env:
    cuda: null
    random_seed: 42
#     commit: 

asr_eval:    
#     model_path: "/data/lad_mandarin/checkpoints_zh_main_baseline_hainan1215_n32_800/checkpoints/zh_main_baseline_hainan1215_n32_800-averaged.nemo"
#     model_path:  "/data/lad_mandarin/checkpoints_hainan_baseline/checkpoints/baseline-averaged.nemo"
#     model_path: "/data/lad_mandarin/checkpoints_zh_main_baseline_hainan1212/zh_main_baseline_hainan1212-averaged.nemo"
    model_path: null
    pretrained_name: "stt_zh_conformer_transducer_large"
#     pretrained_name: null

    inference_mode: 
        mode: offline # choose from offline, chunked or offline_by_chunked
        chunk_len_in_secs: 20 #1.6 #null # Need to specify if use buffered inference (default for offline_by_chunkedis 20)
        total_buffer_in_secs: 22 #4 #null # Need to specify if use buffered inference (default for offline_by_chunked is 22)
        model_stride: 4 #null  # Model downsampling factor, 8 for Citrinet models and 4 for Conformer models",
    
    test_ds:
        manifest_filepath: "/data/mandarin/aishell2/evaluation/aishell/manifests/test_mic.json"
#         manifest_filepath: "/data/mandarin/aishell2/evaluation/aishell/manifests/test_android.json"
#         manifest_filepath: "/data/mandarin/aishell2/evaluation/aishell/manifests/dev_ios.json"
#         manifest_filepath: "/home/fjia/data/chris.json" #"/home/fjia/code/5_syn/english_test_single-sample.json"
        sample_rate: 16000
        batch_size: 32 #1
#         shuffle: False
#         num_workers: 8
#         pin_memory: true
#         test_loss_idx: 0
        
#         augmentor:
#           silence:
#             prob: 1.0
#             min_start_silence_secs: 0
#             max_start_silence_secs: 5
#             min_end_silence_secs: 0
#             max_end_silence_secs: 5

    output_filename: null
    
    
#     neural_vad_options: 
#         vad_model: null


    #     P&C:
analyst:
    metric_calculator:
        clean_groundtruth_text: False
        output_filename: null
        use_cer: True
        
    #     output_filename: "stt_en_conformer_transducer_large-chris-offlineB4C1.6.json" #null
#         output_filename: "/home/fjia/data/fake.json"

    metadata:
        duration: 
            exec: True
            slot: [[0,2],[2,5],[5,10],[10,20],[20,100000]]
#             slot: [[0,61],[61,63],[63,100000]]
            wer_each_class: False #True # whether to save wer for each class.
            
        gender:
            exec: False
            slot: [["m"]]
            wer_each_class: True
            
        speaker:
            exec: False
            wer_each_class: False
            
        age:
            exec: False
            slot: null
            wer_each_class: False
            
        emotion: 
            exec: False
            slot: [['happy','laugh'],['neural'],['sad','cry']]
            wer_each_class: False
                 
writer:
    report_filename: null
    
    
       
       
    