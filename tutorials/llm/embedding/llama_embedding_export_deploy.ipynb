{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9d27250020aba6",
   "metadata": {},
   "source": [
    "# Exporting Llama 3.2 Model into Embedding Model To ONNX and TensorRT\n",
    "\n",
    "## Goal\n",
    "\n",
    "Once the finetuning the LLaMA 3.2 Model into an Embedding Model, you need to export the model to ONNX and TensorRT for fast inference. Please follow the steps below in order to generate ONNX and TensorRT models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0f1b96249be78",
   "metadata": {},
   "source": [
    "# NeMo Tools and Resources\n",
    "\n",
    "* [NeMo Framework](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html)\n",
    "\n",
    "# Software Requirements\n",
    "\n",
    "* Access to latest NeMo Framework NGC Containers\n",
    "\n",
    "\n",
    "# Hardware Requirements\n",
    "\n",
    "* This playbook has been tested on the following hardware: Single A6000, Single H100, 2xA6000, 8xH100. It can be scaled to multiple GPUs as well as multiple nodes by modifying the appropriate parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87846682e01e1a50",
   "metadata": {},
   "source": [
    "#### Launch the NeMo Framework container as follows: \n",
    "\n",
    "Depending on the number of gpus, `--gpus` might need to adjust accordingly:\n",
    "```\n",
    "docker run -it -p 8080:8080 -p 8088:8088 --rm --gpus '\"device=0,1\"' --ipc=host --network host -v $(pwd):/workspace nvcr.io/nvidia/nemo:25.02\n",
    "```\n",
    "\n",
    "#### Launch Jupyter Notebook as follows: \n",
    "```\n",
    "jupyter notebook --allow-root --ip 0.0.0.0 --port 8088 --no-browser --NotebookApp.token=''\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f0670-319d-4983-b4cc-4e8bd379b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from typing import Literal, Optional, Union\n",
    "from nemo.collections.llm.gpt.model import get_llama_bidirectional_hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cfd71-225b-4874-9fa9-c45a6d6dc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "hf_model_path = \"/opt/checkpoints/llama-3.2-nv-embedqa-1b-v2/\"\n",
    "quantization_calibration_data = \"/opt/checkpoints/question_doc_pairs_500.json\"\n",
    "\n",
    "# HF model parameters\n",
    "pooling_mode = \"avg\"\n",
    "normalize = False\n",
    "\n",
    "# ONNX params\n",
    "opset = 17\n",
    "onnx_export_path = \"/opt/checkpoints/llama_embedding_onnx/\"\n",
    "export_dtype = \"fp32\"\n",
    "use_dimension_arg = False\n",
    "\n",
    "# TRT params\n",
    "trt_model_path = Path(\"/opt/checkpoints/llama_embedding_trt/model.plan\")\n",
    "override_layers_to_fp32 = [\"/model/norm/\", \"/pooling_module\", \"/ReduceL2\", \"/Div\", ]\n",
    "override_layernorm_precision_to_fp32 = True\n",
    "profiling_verbosity = \"layer_names_only\"\n",
    "export_to_trt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539a33a-fea9-4168-a179-c277120767fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the model first\n",
    "model, tokenizer = get_llama_bidirectional_hf_model(\n",
    "    model_name_or_path=hf_model_path,\n",
    "    normalize=normalize,\n",
    "    pooling_mode=pooling_mode,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd98f4-1cd4-4c0b-8b92-7bb79991de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.export.onnx_llm_exporter import OnnxLLMExporter\n",
    "\n",
    "if use_dimension_arg:\n",
    "    input_names = [\"input_ids\", \"attention_mask\", \"dimensions\"]\n",
    "    dynamic_axes_input = {\"input_ids\": {0: \"batch_size\", 1: \"seq_length\"},\n",
    "                            \"attention_mask\": {0: \"batch_size\", 1: \"seq_length\"}, \"dimensions\": {0: \"batch_size\"}}\n",
    "else:\n",
    "    input_names = [\"input_ids\", \"attention_mask\"]\n",
    "    dynamic_axes_input = {\"input_ids\": {0: \"batch_size\", 1: \"seq_length\"},\n",
    "                            \"attention_mask\": {0: \"batch_size\", 1: \"seq_length\"}}\n",
    "\n",
    "output_names = [\"embeddings\"]\n",
    "dynamic_axes_output = {\"embeddings\": {0: \"batch_size\", 1: \"embedding_dim\"}}\n",
    "\n",
    "onnx_exporter = OnnxLLMExporter(\n",
    "    onnx_model_dir=onnx_export_path, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "onnx_exporter.export(    \n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset=opset,\n",
    "    dynamic_axes_input=dynamic_axes_input,\n",
    "    dynamic_axes_output=dynamic_axes_output,\n",
    "    export_dtype=\"fp32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aab9b9-97d0-485c-8d86-dbd21b9a6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_to_trt:\n",
    "    if use_dimension_arg:\n",
    "        input_profiles = [{\"input_ids\": [[1, 3], [16, 128], [64, 256]], \"attention_mask\": [[1, 3], [16, 128], [64, 256]],\n",
    "                            \"dimensions\": [[1], [16], [64]]}]\n",
    "    else:\n",
    "        input_profiles = [{\"input_ids\": [[1, 3], [16, 128], [64, 256]], \"attention_mask\": [[1, 3], [16, 128], [64, 256]]}]\n",
    "\n",
    "    onnx_exporter.export_onnx_to_trt(\n",
    "        trt_model_path=Path(trt_model_path),\n",
    "        profiles=input_profiles,\n",
    "        override_layernorm_precision_to_fp32=override_layernorm_precision_to_fp32,\n",
    "        override_layers_to_fp32=override_layers_to_fp32,\n",
    "        profiling_verbosity=profiling_verbosity,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051200b7-6eba-44db-b223-059f1dfb60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"hello\", \"world\"]\n",
    "\n",
    "if use_dimension_arg:\n",
    "    prompt = onnx_exporter.get_tokenizer(prompt)\n",
    "    prompt[\"dimensions\"] = [[2]]\n",
    "\n",
    "print(onnx_exporter.forward(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767092f4-47aa-4d04-9105-558d0a7eded8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
