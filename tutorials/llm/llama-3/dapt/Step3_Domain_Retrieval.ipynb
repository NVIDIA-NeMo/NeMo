{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3. Domain Adapted Retrieval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index==0.10\n",
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Convert HF model to .nemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_ENCODER_MODEL = \"intfloat/e5-small-unsupervised\"\n",
    "HF_LLM_MODEL = \"meta-llama/Llama-3.1-8B\"\n",
    "DATA_ROOT_DIR = \"/work/Data\"\n",
    "MODEL_ROOT_DIR = \"/work/Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_nemo_path = \"/work/Models/e5-small.nemo\"\n",
    "\n",
    "!python /opt/NeMo/scripts/checkpoint_converters/convert_bert_hf_to_nemo.py \\\n",
    "       --input_name_or_path $HF_ENCODER_MODEL \\\n",
    "       --output_path $embed_nemo_path \\\n",
    "       --mcore True \\\n",
    "       --precision bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_nemo_path = \"/work/Models/llama3-tiny.nemo\"\n",
    "precision = \"bf16\"\n",
    "\n",
    "# Convert HF Model to NeMo\n",
    "!python /opt/NeMo/scripts/checkpoint_converters/convert_llama_hf_to_nemo.py --input_name_or_path $HF_LLM_MODEL --output_path $llm_nemo_path --precision $precision --llama31 True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Auto-Generated Domain-specific Retrieval Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dir = f\"{DATA_ROOT_DIR}/index\"\n",
    "data_dir = f\"{DATA_ROOT_DIR}/docs\"\n",
    "\n",
    "!python /opt/NeMo/examples/nlp/rag/rag_indexing.py \\\n",
    "        trainer.devices=1 \\\n",
    "        trainer.precision='bf16-mixed' \\\n",
    "        indexing.embedder.model_path=$embed_nemo_path \\\n",
    "        indexing.embedder.embed_batch_size=128 \\\n",
    "        indexing.data.data_path=$data_dir \\\n",
    "        indexing.data.chunk_size=256 \\\n",
    "        indexing.data.chunk_overlap=10 \\\n",
    "        indexing.index_path=$vector_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{DATA_ROOT_DIR}/retrieval\"\n",
    "\n",
    "!python /opt/NeMo/tutorials/llm/llama-3/dapt/code/rag_auto_generate_sample.py \\\n",
    "    --config-path=/opt/NeMo/examples/nlp/rag/conf \\\n",
    "    --config-name=rag_generating \\\n",
    "    indexing.index_path=$vector_dir \\\n",
    "    indexing.embedder.model_path=$embed_nemo_path \\\n",
    "    generating.llm.model_path=$llm_nemo_path \\\n",
    "    ++generating.top_k=4 \\\n",
    "    ++generating.num_random=4 \\\n",
    "    ++generating.output_dir=$data_dir \\\n",
    "    ++generating.num_sample=3000 \\\n",
    "    ++generating.prefix=\"train\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Finetuning Retrieval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = data_dir + \"/train_data.json\"\n",
    "\n",
    "!python /opt/NeMo/examples/nlp/information_retrieval/megatron_bert_embedding_finetuning.py \\\n",
    "    exp_manager.exp_dir=/work/log/retrieval \\\n",
    "    restore_from_path=$embed_nemo_path \\\n",
    "    trainer.devices=8 \\\n",
    "    trainer.precision=bf16 \\\n",
    "    trainer.max_epochs=1 \\\n",
    "    trainer.max_steps=-1 \\\n",
    "    trainer.val_check_interval=2 \\\n",
    "    trainer.limit_val_batches=8 \\\n",
    "    trainer.limit_test_batches=8 \\\n",
    "    model.micro_batch_size=1 \\\n",
    "    model.global_batch_size=64 \\\n",
    "    model.data.data_impl=jsonl \\\n",
    "    model.hidden_size=384 \\\n",
    "    model.num_layers=12 \\\n",
    "    model.ffn_hidden_size=1536 \\\n",
    "    model.data.data_train=$data_file"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
