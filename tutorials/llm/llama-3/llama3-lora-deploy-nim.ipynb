{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e56fcb",
   "metadata": {},
   "source": [
    "# Multi-LoRA inference with NVIDIA NIM\n",
    "\n",
    "This is a demonstration of deploying multiple LoRA adapters with NVIDIA NIM. NIM supports LoRA adapters in .nemo (from NeMo Framework), and Hugging Face model formats. \n",
    "\n",
    "We will deploy the PubMedQA LoRA adapter from previous notebook, alongside two other previously trained LoRA adapters (GSM8K, SQuAD) that are available on NVIDIA NGC as examples.\n",
    "\n",
    "`NOTE`: While it's not necessary to complete the LoRA training and obtain the adapter from the previous notebook (\"Creating a LoRA adapter with NeMo Framework\") to follow along with this one, it is recommended if possible. You can still learn about LoRA deployment with NIM using the other adapters downloaded from NGC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09747b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Step-by-step instructions\n",
    "This notebook includes instructions to send an inference call to NVIDIA NIM using the Python `requests` library.\n",
    "\n",
    "\n",
    "### Check available LoRA models\n",
    "\n",
    "Once the NIM server is up and running, we can check the available models as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4489179d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"object\": \"list\",\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"id\": \"meta/llama3-8b-instruct\",\n",
      "            \"object\": \"model\",\n",
      "            \"created\": 1717145235,\n",
      "            \"owned_by\": \"system\",\n",
      "            \"root\": \"meta/llama3-8b-instruct\",\n",
      "            \"parent\": null,\n",
      "            \"permission\": [\n",
      "                {\n",
      "                    \"id\": \"modelperm-f6bac02e9ca747d5abca4603113865a2\",\n",
      "                    \"object\": \"model_permission\",\n",
      "                    \"created\": 1717145235,\n",
      "                    \"allow_create_engine\": false,\n",
      "                    \"allow_sampling\": true,\n",
      "                    \"allow_logprobs\": true,\n",
      "                    \"allow_search_indices\": false,\n",
      "                    \"allow_view\": true,\n",
      "                    \"allow_fine_tuning\": false,\n",
      "                    \"organization\": \"*\",\n",
      "                    \"group\": null,\n",
      "                    \"is_blocking\": false\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"llama3-8b-pubmed-qa\",\n",
      "            \"object\": \"model\",\n",
      "            \"created\": 1717145235,\n",
      "            \"owned_by\": \"system\",\n",
      "            \"root\": \"meta/llama3-8b-instruct\",\n",
      "            \"parent\": null,\n",
      "            \"permission\": [\n",
      "                {\n",
      "                    \"id\": \"modelperm-242edeac9a974917aac0fcf917edae6f\",\n",
      "                    \"object\": \"model_permission\",\n",
      "                    \"created\": 1717145235,\n",
      "                    \"allow_create_engine\": false,\n",
      "                    \"allow_sampling\": true,\n",
      "                    \"allow_logprobs\": true,\n",
      "                    \"allow_search_indices\": false,\n",
      "                    \"allow_view\": true,\n",
      "                    \"allow_fine_tuning\": false,\n",
      "                    \"organization\": \"*\",\n",
      "                    \"group\": null,\n",
      "                    \"is_blocking\": false\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"llama3-8b-instruct-lora_vnemo-math-v1\",\n",
      "            \"object\": \"model\",\n",
      "            \"created\": 1717145235,\n",
      "            \"owned_by\": \"system\",\n",
      "            \"root\": \"meta/llama3-8b-instruct\",\n",
      "            \"parent\": null,\n",
      "            \"permission\": [\n",
      "                {\n",
      "                    \"id\": \"modelperm-716a1e2a229c465c94475668a88f6567\",\n",
      "                    \"object\": \"model_permission\",\n",
      "                    \"created\": 1717145235,\n",
      "                    \"allow_create_engine\": false,\n",
      "                    \"allow_sampling\": true,\n",
      "                    \"allow_logprobs\": true,\n",
      "                    \"allow_search_indices\": false,\n",
      "                    \"allow_view\": true,\n",
      "                    \"allow_fine_tuning\": false,\n",
      "                    \"organization\": \"*\",\n",
      "                    \"group\": null,\n",
      "                    \"is_blocking\": false\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"llama3-8b-instruct-lora_vnemo-squad-v1\",\n",
      "            \"object\": \"model\",\n",
      "            \"created\": 1717145235,\n",
      "            \"owned_by\": \"system\",\n",
      "            \"root\": \"meta/llama3-8b-instruct\",\n",
      "            \"parent\": null,\n",
      "            \"permission\": [\n",
      "                {\n",
      "                    \"id\": \"modelperm-f19e0f3915f44c3cba9b483c670f45af\",\n",
      "                    \"object\": \"model_permission\",\n",
      "                    \"created\": 1717145235,\n",
      "                    \"allow_create_engine\": false,\n",
      "                    \"allow_sampling\": true,\n",
      "                    \"allow_logprobs\": true,\n",
      "                    \"allow_search_indices\": false,\n",
      "                    \"allow_view\": true,\n",
      "                    \"allow_fine_tuning\": false,\n",
      "                    \"organization\": \"*\",\n",
      "                    \"group\": null,\n",
      "                    \"is_blocking\": false\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://0.0.0.0:8000/v1/models'\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e8efd",
   "metadata": {},
   "source": [
    "### Inference on a single prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfd2083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"cmpl-95616581ca314d789e687af9c756f87c\",\n",
      "    \"object\": \"text_completion\",\n",
      "    \"created\": 1717145241,\n",
      "    \"model\": \"llama3-8b-pubmed-qa\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"index\": 0,\n",
      "            \"text\": \" <<< yes >>>\",\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"stop_reason\": null\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 318,\n",
      "        \"total_tokens\": 322,\n",
      "        \"completion_tokens\": 4\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://0.0.0.0:8000/v1/completions'\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "prompt=\"AIMS: Dyschesia can be provoked by inappropriate defecation movements. The aim of this prospective study was to demonstrate dysfunction of the anal sphincter and/or the musculus (m.) puborectalis in patients with dyschesia using anorectal endosonography.\\nMETHODS: Twenty consecutive patients with a medical history of dyschesia and a control group of 20 healthy subjects underwent linear anorectal endosonography (Toshiba models IUV 5060 and PVL-625 RT). In both groups, the dimensions of the anal sphincter and the m. puborectalis were measured at rest, and during voluntary squeezing and straining. Statistical analysis was performed within and between the two groups.\\nRESULTS: The anal sphincter became paradoxically shorter and/or thicker during straining (versus the resting state) in 85% of patients but in only 35% of control subjects. Changes in sphincter length were statistically significantly different (p<0.01, chi(2) test) in patients compared with control subjects. The m. puborectalis became paradoxically shorter and/or thicker during straining in 80% of patients but in only 30% of controls. Both the changes in length and thickness of the m. puborectalis were significantly different (p<0.01, chi(2) test) in patients versus control subjects.\\nQUESTION: Is anorectal endosonography valuable in dyschesia?\\n ### ANSWER (yes|no|maybe):\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"llama3-8b-pubmed-qa\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 128\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "response_data = response.json()\n",
    "\n",
    "print(json.dumps(response_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65afd7a",
   "metadata": {},
   "source": [
    "## Step 3: Testing the accuracy of NIM inference\n",
    "\n",
    "This step can be continued within the Nemo FW training container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406aa5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_test = json.load(open(\"./pubmedqa/data/test_set.json\",'rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7516c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl (fname):\n",
    "    obj = []\n",
    "    with open(fname, 'rt') as f:\n",
    "        st = f.readline()\n",
    "        while st:\n",
    "            obj.append(json.loads(st))\n",
    "            st = f.readline()\n",
    "    return obj\n",
    "\n",
    "prepared_test = read_jsonl(\"./pubmedqa/data/pubmedqa_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68511ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def infer(prompt):\n",
    "\n",
    "    url = 'http://0.0.0.0:8000/v1/completions'\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llama3-8b-pubmed-qa\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 128\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_data = response.json()\n",
    "\n",
    "    return(response_data[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f44cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:45, 10.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = {}\n",
    "sample_id = list(data_test.keys())\n",
    "\n",
    "for i, key in tqdm(enumerate(sample_id)):\n",
    "    answer = infer(prepared_test[i]['input'].strip())\n",
    "    answer = answer.lower()\n",
    "    if 'yes' in answer:\n",
    "        results[key] = 'yes'\n",
    "    elif 'no' in answer:\n",
    "        results[key] = 'no'\n",
    "    elif 'maybe' in answer:\n",
    "        results[key] = 'maybe'\n",
    "    else:\n",
    "        print(\"Malformed answer: \", answer)\n",
    "        results[key] = 'maybe'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee9de08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <<< yes >>>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9942a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.786000\n",
      "Macro-F1 0.584112\n"
     ]
    }
   ],
   "source": [
    "# dump results\n",
    "FILENAME=\"pubmedqa-llama-3-8b-lora-NIM.json\"\n",
    "with(open(FILENAME, \"w\")) as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Evaluation\n",
    "!cp $FILENAME ./pubmedqa/\n",
    "!cd ./pubmedqa/ && python evaluation.py $FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d014d79",
   "metadata": {},
   "source": [
    "We can verify that in this case, NIM inference should provide comparable accuracy to NeMo inference.\n",
    "\n",
    "```\n",
    "Accuracy 0.786000\n",
    "Macro-F1 0.584112\n",
    "```\n",
    "\n",
    "Note that each individual answer also conform to the format we specified, i.e. `<<< {answer} >>>`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
