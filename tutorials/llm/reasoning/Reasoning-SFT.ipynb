{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4d51a3-4b0b-40d0-b84d-34e23a523468",
   "metadata": {},
   "source": [
    "# Train your Reasoning Model using NeMo 2.0\n",
    "\n",
    "This tutorial shows how to fine-tune Meta’s LLaMA 3–8B Instruct model using NVIDIA NeMo and supervised fine-tuning (SFT). You'll train the model on complex instruction-following and reasoning tasks using the[Llama-Nemotron-Post-Training-Data](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset)\n",
    "\n",
    "### ✅ What You'll Learn\n",
    "1. Load and preprocess a reasoning-focused instruction dataset.\n",
    "2. Apply SFT with NeMo 2.0.\n",
    "3. Train using NeMo's distributed, mixed-precision trainer.\n",
    "4. Save a fine-tuned checkpoint ready for evaluation or deployment.\n",
    "\n",
    "### 🚀 Ideal For\n",
    "1. Multi-turn reasoning (e.g., chain-of-thought)\n",
    "2. Domain-specific instruction following\n",
    "3. Question answering, dialogue systems, and agentic behaviors\n",
    "\n",
    "\n",
    "### NeMo Tools and Resources\n",
    "[NeMo Framework](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html)\n",
    "\n",
    "### Software Requirements\n",
    "* Access to latest NeMo Framework NGC Containers\n",
    "* This playbook has been tested on: nvcr.io/nvidia/nemo:25.02. It is expected to work similarly on other environments.\n",
    "\n",
    "\n",
    "#### Launch the NeMo Framework container as follows:\n",
    "```docker run -it -p 8080:8080 -p 8088:8088 --rm --gpus '\"device=0,1,2,3\"' --ipc=host --network host -v $(pwd):/workspace nvcr.io/nvidia/nemo:25.02```\n",
    "\n",
    "#### Launch Jupyter Notebook as follows:\n",
    "```jupyter notebook --allow-root --ip 0.0.0.0 --port 8088 --no-browser --NotebookApp.token=''```\n",
    "\n",
    "### Hardware Requirements\n",
    "This playbook has been tested on 4xA100 80G but can be scaled to multiple GPUs as well as multiple nodes by modifying the appropriate parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd940e9-0c80-4021-966b-3917d6650fe7",
   "metadata": {},
   "source": [
    "## Step 1. Convert HuggingFace Checkpoint to NeMo Format\n",
    "\n",
    "Before training, we need to convert the HuggingFace LLaMA 3–8B Instruct checkpoint into NeMo format. NeMo provides a built-in utility ```llm.import_ckpt()``` to handle this conversion.\n",
    "\n",
    "### ⚠️ This step only needs to be run once per model.\n",
    "After conversion, the model can be loaded and fine-tuned using NeMo APIs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013764ee-95ed-44fa-85b9-4296d37e7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo_run as run\n",
    "from nemo import lightning as nl\n",
    "from nemo.collections import llm\n",
    "from megatron.core.optimizer import OptimizerConfig\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from nemo.collections.llm.recipes.precision.mixed_precision import bf16_mixed\n",
    "from nemo.lightning.pytorch.optim import CosineAnnealingScheduler, MegatronOptimizerModule, PytorchOptimizerModule\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure the import from HuggingFace format to NeMo format\n",
    "def configure_checkpoint_conversion():\n",
    "    return run.Partial(\n",
    "        llm.import_ckpt,\n",
    "        model=llm.llama3_8b.model(),  # Predefined LLaMA 3 8B model structure\n",
    "        source=\"hf:///workspace/Meta-Llama-3-8B-Instruct\",  # Path to HF checkpoint (local or HF hub)\n",
    "        overwrite=False,  # Set to True if you want to overwrite an existing NeMo checkpoint\n",
    "    )\n",
    "\n",
    "# Create the configured import task\n",
    "import_ckpt = configure_checkpoint_conversion()\n",
    "\n",
    "# Define the local executor (single-node)\n",
    "local_executor = run.LocalExecutor()\n",
    "\n",
    "# Execute the checkpoint conversion\n",
    "run.run(import_ckpt, executor=local_executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148354c-af20-44f0-bbda-bf1362fd2c24",
   "metadata": {},
   "source": [
    "✓ Checkpoint imported to /root/.cache/nemo/models/Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1492948-5608-4596-b571-f141ec6bde9e",
   "metadata": {},
   "source": [
    "## Step 2. Prepare Data\n",
    "\n",
    "In this section, we define the configuration for loading and preprocessing an instruction-tuning dataset using NeMo’s FineTuningDataModule. The dataset is expected to be in a structured format (e.g. JSONL), stored locally as ```training.jsonl```.\n",
    "\n",
    "The training-related parameters like batch size, number of workers, memory mapping, and device count can be modified based on the size of the model, dataset size and compute resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01f0bc-fdaa-4023-97cb-c5a26f0840a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "from nemo.collections.llm.gpt.data.core import get_dataset_root\n",
    "from nemo.collections.llm.gpt.data.fine_tuning import FineTuningDataModule\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.collections import llm\n",
    "from nemo.lightning.io.mixin import IOMixin\n",
    "from nemo.utils import logging\n",
    "\n",
    "N_DEVICES = 4\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "experiment_name = \"baseline-8GPUs-all-data-cleaned-shuffle-no-distrib-sampler-500k-2-workers\"\n",
    "\n",
    "# Define fine-tuning dataset configuration\n",
    "finetune_config = run.Config(\n",
    "    llm.FineTuningDataModule,\n",
    "    dataset_root=\"/workspace\",       # Path to your preprocessed dataset (JSONL, etc.)\n",
    "    seq_length=8192,                 # Max sequence length for input tokens\n",
    "    micro_batch_size=1,              # Per-device batch size\n",
    "    global_batch_size=256,           # Total batch size across all devices\n",
    "    seed=1234,                       # Seed for reproducibility\n",
    "    memmap_workers=1,                # Use memory-mapped dataset format for performance\n",
    "    num_workers=8,                   # DataLoader worker threads\n",
    "    pin_memory=True,                 # Optimize data transfer to GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4d9d6-0b90-4562-a9b8-7ac947ba851f",
   "metadata": {},
   "source": [
    "## Step 3. Configure SFT with the NeMo 2.0 API\n",
    "\n",
    "In this step, we'll use the modular NeMo 2.0 API to configure:\n",
    "\n",
    "* The distributed trainer\n",
    "\n",
    "* Logging and checkpointing\n",
    "\n",
    "* Optimizer with cosine annealing scheduler\n",
    "\n",
    "* Model definition and resume behavior\n",
    "\n",
    "* Final recipe assembly for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214912f1-2cd3-4db2-a295-9efb8612a043",
   "metadata": {},
   "source": [
    "### ⚙️ 3.1 Configure the Trainer\n",
    "We define the training strategy with Megatron's Distributed Training strategy using tensor model parallelism and enabling mixed precision with bf16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe9b85-a9b6-418a-b013-ed5459a1e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer() -> run.Config[nl.Trainer]:\n",
    "    strategy = run.Config(\n",
    "        nl.MegatronStrategy,\n",
    "        tensor_model_parallel_size=4,\n",
    "        optimizer_cpu_offload=True\n",
    "    )\n",
    "    trainer = run.Config(\n",
    "        nl.Trainer,\n",
    "        devices=4,\n",
    "        num_nodes=1,\n",
    "        max_steps=100,\n",
    "        accelerator=\"gpu\",\n",
    "        strategy=strategy,\n",
    "        plugins=bf16_mixed(),\n",
    "        log_every_n_steps=50,\n",
    "        limit_val_batches=0,\n",
    "        val_check_interval=0,\n",
    "        num_sanity_val_steps=0,\n",
    "        use_distributed_sampler=False,\n",
    "    )\n",
    "    return trainer    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88dd49-314f-42fb-a4fb-30ad3d4b490d",
   "metadata": {},
   "source": [
    "### 📝 3.2 Configure Logging and Checkpointing\n",
    "Logs metrics and periodically saves model checkpoints during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802508e1-8051-431f-bd54-44ffe4d292d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger() -> run.Config[nl.NeMoLogger]:\n",
    "    ckpt = run.Config(\n",
    "        nl.ModelCheckpoint,\n",
    "        save_last=True,\n",
    "        every_n_train_steps=10,\n",
    "        monitor=\"reduced_train_loss\",\n",
    "        save_top_k=1,\n",
    "        save_on_train_epoch_end=True,\n",
    "        save_optim_on_train_end=True,\n",
    "    )\n",
    "\n",
    "    return run.Config(\n",
    "        nl.NeMoLogger,\n",
    "        name=f\"trained-model-checkpoints\",\n",
    "        log_dir=f\"./results-{timestamp}-{N_DEVICES}-devices-{experiment_name}\",\n",
    "        use_datetime_version=True,\n",
    "        ckpt=ckpt,\n",
    "        wandb=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489a8ab-be37-406b-a11e-b6a597604614",
   "metadata": {},
   "source": [
    "### 📈 3.3 Configure Optimizer with Cosine Annealing\n",
    "Uses the Adam optimizer with gradient clipping, distributed optimizer support, and a cosine annealing learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8badf059-c275-436c-ab5e-5db2d6c32839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.core.optimizer import OptimizerConfig\n",
    "\n",
    "def lr_scheduler():\n",
    "    return run.Config(\n",
    "        CosineAnnealingScheduler,\n",
    "        warmup_steps=100,        \n",
    "        constant_steps=1000,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "    \n",
    "def adam_with_cosine_annealing() -> run.Config[nl.OptimizerModule]:\n",
    "    opt_cfg = run.Config(\n",
    "        OptimizerConfig,\n",
    "        optimizer=\"adam\",\n",
    "        lr=1e-4,\n",
    "        weight_decay=0.001,\n",
    "        use_distributed_optimizer=True,\n",
    "        clip_grad=1.0,\n",
    "        bf16=True,\n",
    "    )\n",
    "    \n",
    "    return run.Config(\n",
    "        nl.MegatronOptimizerModule,\n",
    "        config=opt_cfg,\n",
    "        lr_scheduler=lr_scheduler(), \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17225cf-6fa1-48ef-95e8-54b57efcf967",
   "metadata": {},
   "source": [
    "### 🧠 3.4 Define the Base Model and Resume Logic\n",
    "We use the built-in LLaMA 3 8B config from NeMo and optionally resume from a previously saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a003f8c-4947-49b8-bd24-8712fcf87532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3_8b() -> run.Config[pl.LightningModule]:\n",
    "    return run.Config(llm.LlamaModel, config=run.Config(llm.Llama3Config8B))\n",
    "\n",
    "def resume() -> run.Config[nl.AutoResume]:\n",
    "    return run.Config(\n",
    "        nl.AutoResume,\n",
    "        restore_config=run.Config(\n",
    "            nl.RestoreConfig,\n",
    "            path=\"nemo://Meta-Llama-3-8B-Instruct\",  # Change to local path if needed\n",
    "        ),\n",
    "        resume_if_exists=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe4c09-ea6d-4dd0-9953-cbdd797225ac",
   "metadata": {},
   "source": [
    "### 📦 3.5 Assemble the Fine-Tuning Recipe\n",
    "This ties together the model, trainer, dataset config, optimizer, and logger into a single training recipe using NeMo’s run.Partial system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c175cd8-c4fd-4f24-a206-435a79965131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_finetuning_recipe():\n",
    "    return run.Partial(\n",
    "        llm.finetune,\n",
    "        model=llama3_8b(),\n",
    "        trainer=trainer(),\n",
    "        data=finetune_config,  # From earlier step\n",
    "        log=logger(),\n",
    "        optim=adam_with_cosine_annealing(),\n",
    "        resume=resume(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5592c-abfb-4489-b8a2-67b4164346b5",
   "metadata": {},
   "source": [
    "## ▶️ Step 4: Run Supervised Fine-Tuning (SFT) with NeMo 2.0 and nemo-run\n",
    "Now that everything is configured (model, trainer, optimizer, logging, and data), it's time to launch the training job using nemo-run's LocalExecutor.\n",
    "\n",
    "This will:\n",
    "\n",
    "* Use torchrun to launch a multi-GPU job\n",
    "\n",
    "* Set environment variables for optimized NCCL behavior\n",
    "\n",
    "* Kick off the training loop with your full configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837f7c7-ad01-4bee-87ba-2e52f919a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_executor_torchrun(nodes: int = 1, devices: int = 4) -> run.LocalExecutor:\n",
    "    # Environment variables to optimize distributed training\n",
    "    env_vars = {\n",
    "        \"TORCH_NCCL_AVOID_RECORD_STREAMS\": \"1\",\n",
    "        \"NCCL_NVLS_ENABLE\": \"0\",\n",
    "    }\n",
    "\n",
    "    return run.LocalExecutor(\n",
    "        ntasks_per_node=devices,\n",
    "        launcher=\"torchrun\",\n",
    "        env_vars=env_vars,\n",
    "    )\n",
    "\n",
    "# Execute the training run\n",
    "if __name__ == '__main__':\n",
    "    run.run(\n",
    "        configure_finetuning_recipe(),\n",
    "        executor=local_executor_torchrun()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0a1b3-c5f8-447e-ac0c-73a75eb1912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58635c3-08a9-4cec-9fe0-edd0b94036a8",
   "metadata": {},
   "source": [
    "## 🎉 Tada! You Just Trained Your First Reasoning Model!\n",
    "Congratulations — you've successfully fine-tuned LLaMA 3–8B Instruct into a domain-adapted reasoning model using NVIDIA NeMo 2.0!\n",
    "\n",
    "Your model is now ready to:\n",
    "\n",
    "* Answer questions more effectively\n",
    "* Follow domain-specific instructions\n",
    "* Support chain-of-thought reasoning in real-world applications\n",
    "\n",
    "### 🚀 Next Steps\n",
    "* 🧪 Evaluate your model on reasoning benchmarks (e.g., MMLU, GSM8K)\n",
    "* 🪄 Add LoRA or QLoRA for even more efficient adaptation\n",
    "* ☁️ Package the model for deployment or inference with Triton or vLLM\n",
    "* 📤 Optionally, upload it to HuggingFace or NGC to share with the world"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
