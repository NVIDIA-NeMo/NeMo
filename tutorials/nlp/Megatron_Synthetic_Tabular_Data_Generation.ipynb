{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "c3217a15",
            "metadata": {},
            "source": [
                "# Synthetic Tabular Data Generation by NeMo GPT\n",
                "\n",
                "Big data, new algorithms and fast computers are the 3 main factors that make the modern AI revolution possible. Data poses a big challenge for enterprises for various reasons: difficulty  of data labeling, strong data governance, limited data availability etc. Synthetic data generation is proposed as a solution to the data problem as it directly addresses the data challenges. Two popular generative models like  Variational Auto-Encoder [VAE](https://en.wikipedia.org/wiki/Variational_autoencoder) and Generative Adversarial Network [GAN](https://en.wikipedia.org/wiki/Generative_adversarial_network) models have achieved some success in the past. However, a good generative model should generate the data following the same distribution as the training data. There are some known flaws with the VAE and GAN models for synthetic data generation. Most prominently, the [mode collapse problem](https://developers.google.com/machine-learning/gan/problems) in the GAN model causes the generated data to miss some modes in the training data distribution. While the VAE has the difficulty of generating sharp data points due to the non-autoregressive loss.\n",
                "\n",
                "Recently, [Transformer models](https://arxiv.org/abs/1706.03762) achieved huge success in the natural language processing domain.  The self-attention encoding and decoding architecture of the transformer model is proven to be accurate in modeling the data distribution and scalable to large datasets. [OpenAI’s GPT3](https://openai.com/blog/gpt-3-apps/) uses the decoder part of the transformer model and has 175B parameters. It has been widely used across varying categories and industries, from productivity and education to creativity and games. GPT3 turns out to be a superior generative model. In this tutorial, we are interested in exploring the ideas of applying the GPT model for synthetic data generation. \n",
                "\n",
                "Unlike typical neural networks, GPT models are usually large in size. It is challenging to fit a large GPT model into a single GPU. Luckily, [NeMo](https://github.com/NVIDIA/NeMo) is an open source tool that is capable of efficiently training very large (hundreds of billions of parameters) language models with both model and data parallelism.  It is easy to use too. In the following sections, we will show how to train a GPT model step by step to generate synthetic credit card data.\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "8c72dc42",
            "metadata": {},
            "source": [
                "### Get the Credit Card Transaction Data \n",
                "\n",
                "The synthetic credit card transaction dataset is provided at [IBM TabFormer Github repo](https://github.com/IBM/TabFormer). Go ahead to download it at this [direct link](https://ibm.box.com/v/tabformer-data). Put the downloaded and decompressed `card_transaction.v1.csv` file at the same directory as this this notebook."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "79154a9e",
            "metadata": {},
            "source": [
                "### Data Cleaning and Formatting\n",
                "\n",
                "First let's import the necessary Python libraries for the tutorial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c4a08689",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from nemo.collections.common.tokenizers.column_coder import ColumnCodes\n",
                "from omegaconf import OmegaConf\n",
                "import pickle\n",
                "from pandas.api.types import is_string_dtype\n",
                "from nemo.collections.common.tokenizers.tabular_tokenizer import TabularTokenizer\n",
                "import json\n",
                "import wget\n",
                "import requests\n",
                "import json\n",
                "import functools\n",
                "from multiprocessing import Pool"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "abaa1f80",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "./card_transaction.v1.csv ./checkpoints ./credit_card_coder.pickle ./credit_card.jn\n"
                    ]
                }
            ],
            "source": [
                "BRANCH = 'r1.23.0'\n",
                "DATA_PATH='.'\n",
                "TRANSACTIONS=DATA_PATH+'/card_transaction.v1.csv'\n",
                "#CHECKPOINTS='/chk_points'\n",
                "CHECKPOINTS=DATA_PATH+'/checkpoints'\n",
                "CC_OUTPUT_P=DATA_PATH+'/credit_card_coder.pickle'\n",
                "CC_OUTPUT_J=DATA_PATH+'/credit_card.jn'\n",
                "print (TRANSACTIONS, CHECKPOINTS, CC_OUTPUT_P, CC_OUTPUT_J)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "7e0bbc89",
            "metadata": {},
            "source": [
                "After decompressing the tar file,  we load the dataset into pandas dataframe and examine the top few rows."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "8aa48317",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>User</th>\n",
                            "      <th>Card</th>\n",
                            "      <th>Year</th>\n",
                            "      <th>Month</th>\n",
                            "      <th>Day</th>\n",
                            "      <th>Time</th>\n",
                            "      <th>Amount</th>\n",
                            "      <th>Use Chip</th>\n",
                            "      <th>Merchant Name</th>\n",
                            "      <th>Merchant City</th>\n",
                            "      <th>Merchant State</th>\n",
                            "      <th>Zip</th>\n",
                            "      <th>MCC</th>\n",
                            "      <th>Errors?</th>\n",
                            "      <th>Is Fraud?</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>1</td>\n",
                            "      <td>06:21</td>\n",
                            "      <td>$134.09</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>3527213246127876953</td>\n",
                            "      <td>La Verne</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91750.0</td>\n",
                            "      <td>5300</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>1</td>\n",
                            "      <td>06:42</td>\n",
                            "      <td>$38.48</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>-727612092139916043</td>\n",
                            "      <td>Monterey Park</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91754.0</td>\n",
                            "      <td>5411</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2</td>\n",
                            "      <td>06:22</td>\n",
                            "      <td>$120.34</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>-727612092139916043</td>\n",
                            "      <td>Monterey Park</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91754.0</td>\n",
                            "      <td>5411</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2</td>\n",
                            "      <td>17:45</td>\n",
                            "      <td>$128.95</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>3414527459579106770</td>\n",
                            "      <td>Monterey Park</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91754.0</td>\n",
                            "      <td>5651</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>3</td>\n",
                            "      <td>06:23</td>\n",
                            "      <td>$104.71</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>5817218446178736267</td>\n",
                            "      <td>La Verne</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91750.0</td>\n",
                            "      <td>5912</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   User  Card  Year  Month  Day   Time   Amount           Use Chip  \\\n",
                            "0     0     0  2002      9    1  06:21  $134.09  Swipe Transaction   \n",
                            "1     0     0  2002      9    1  06:42   $38.48  Swipe Transaction   \n",
                            "2     0     0  2002      9    2  06:22  $120.34  Swipe Transaction   \n",
                            "3     0     0  2002      9    2  17:45  $128.95  Swipe Transaction   \n",
                            "4     0     0  2002      9    3  06:23  $104.71  Swipe Transaction   \n",
                            "\n",
                            "         Merchant Name  Merchant City Merchant State      Zip   MCC Errors?  \\\n",
                            "0  3527213246127876953       La Verne             CA  91750.0  5300     NaN   \n",
                            "1  -727612092139916043  Monterey Park             CA  91754.0  5411     NaN   \n",
                            "2  -727612092139916043  Monterey Park             CA  91754.0  5411     NaN   \n",
                            "3  3414527459579106770  Monterey Park             CA  91754.0  5651     NaN   \n",
                            "4  5817218446178736267       La Verne             CA  91750.0  5912     NaN   \n",
                            "\n",
                            "  Is Fraud?  \n",
                            "0        No  \n",
                            "1        No  \n",
                            "2        No  \n",
                            "3        No  \n",
                            "4        No  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv(TRANSACTIONS)\n",
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1ff1d46f",
            "metadata": {},
            "source": [
                "In the following data cleaning step, we fix the `Amount` column that is not a number, convert the `Time` column into `hour` and `minutes` and replace the `,` character with space so we can use `,` as delimiter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "33980221",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[NeMo W 2024-02-26 22:41:54 nemo_logging:349] /tmp/ipykernel_45614/528401009.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
                        "      df['Amount'] = df['Amount'].str.replace('$', '').astype('float')\n",
                        "    \n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>User</th>\n",
                            "      <th>Year</th>\n",
                            "      <th>Month</th>\n",
                            "      <th>Day</th>\n",
                            "      <th>Hour</th>\n",
                            "      <th>Minute</th>\n",
                            "      <th>Card</th>\n",
                            "      <th>Amount</th>\n",
                            "      <th>Use Chip</th>\n",
                            "      <th>Merchant Name</th>\n",
                            "      <th>Merchant City</th>\n",
                            "      <th>Merchant State</th>\n",
                            "      <th>Zip</th>\n",
                            "      <th>MCC</th>\n",
                            "      <th>Errors?</th>\n",
                            "      <th>Is Fraud?</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>1</td>\n",
                            "      <td>06</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0</td>\n",
                            "      <td>134.09</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>3527213246127876953</td>\n",
                            "      <td>La Verne</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91750</td>\n",
                            "      <td>5300</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>1</td>\n",
                            "      <td>06</td>\n",
                            "      <td>42</td>\n",
                            "      <td>0</td>\n",
                            "      <td>38.48</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>-727612092139916043</td>\n",
                            "      <td>Monterey Park</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91754</td>\n",
                            "      <td>5411</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2</td>\n",
                            "      <td>06</td>\n",
                            "      <td>22</td>\n",
                            "      <td>0</td>\n",
                            "      <td>120.34</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>-727612092139916043</td>\n",
                            "      <td>Monterey Park</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91754</td>\n",
                            "      <td>5411</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2</td>\n",
                            "      <td>17</td>\n",
                            "      <td>45</td>\n",
                            "      <td>0</td>\n",
                            "      <td>128.95</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>3414527459579106770</td>\n",
                            "      <td>Monterey Park</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91754</td>\n",
                            "      <td>5651</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0</td>\n",
                            "      <td>2002</td>\n",
                            "      <td>9</td>\n",
                            "      <td>3</td>\n",
                            "      <td>06</td>\n",
                            "      <td>23</td>\n",
                            "      <td>0</td>\n",
                            "      <td>104.71</td>\n",
                            "      <td>Swipe Transaction</td>\n",
                            "      <td>5817218446178736267</td>\n",
                            "      <td>La Verne</td>\n",
                            "      <td>CA</td>\n",
                            "      <td>91750</td>\n",
                            "      <td>5912</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>No</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   User  Year  Month  Day Hour Minute  Card  Amount           Use Chip  \\\n",
                            "0     0  2002      9    1   06     21     0  134.09  Swipe Transaction   \n",
                            "1     0  2002      9    1   06     42     0   38.48  Swipe Transaction   \n",
                            "2     0  2002      9    2   06     22     0  120.34  Swipe Transaction   \n",
                            "3     0  2002      9    2   17     45     0  128.95  Swipe Transaction   \n",
                            "4     0  2002      9    3   06     23     0  104.71  Swipe Transaction   \n",
                            "\n",
                            "         Merchant Name  Merchant City Merchant State    Zip   MCC Errors?  \\\n",
                            "0  3527213246127876953       La Verne             CA  91750  5300     NaN   \n",
                            "1  -727612092139916043  Monterey Park             CA  91754  5411     NaN   \n",
                            "2  -727612092139916043  Monterey Park             CA  91754  5411     NaN   \n",
                            "3  3414527459579106770  Monterey Park             CA  91754  5651     NaN   \n",
                            "4  5817218446178736267       La Verne             CA  91750  5912     NaN   \n",
                            "\n",
                            "  Is Fraud?  \n",
                            "0        No  \n",
                            "1        No  \n",
                            "2        No  \n",
                            "3        No  \n",
                            "4        No  "
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# remove the dollar string and convert amount to float\n",
                "df['Amount'] = df['Amount'].str.replace('$', '').astype('float')\n",
                "# fix the zip column\n",
                "df['Zip'] = pd.array([None if pd.isna(x) else int(x) for x in df['Zip']])\n",
                "\n",
                "# parse the time into minute and second\n",
                "df['Hour'] = df['Time'].str[0:2]\n",
                "df['Minute'] = df['Time'].str[-2:]\n",
                "# remove the 'Time' Column once it is parsed\n",
                "del df['Time']\n",
                "# all the columns used for later processing \n",
                "all_columns = ['User', 'Year', 'Month', 'Day', 'Hour', 'Minute', 'Card', 'Amount', 'Use Chip',\n",
                "           'Merchant Name', 'Merchant City', 'Merchant State', 'Zip', 'MCC',\n",
                "           'Errors?', 'Is Fraud?']\n",
                "# these are the columns used to train the model\n",
                "columns = ['Year', 'Month', 'Day', 'Hour', 'Minute', 'Card', 'Amount', 'Use Chip',\n",
                "           'Merchant Name', 'Merchant City', 'Merchant State', 'Zip', 'MCC',\n",
                "           'Errors?', 'Is Fraud?']\n",
                "\n",
                "float_columns = ['Amount']\n",
                "category_columns = ['Year', 'Month', 'Day', 'Hour', 'Minute', 'Card', 'Use Chip',\n",
                "                    'Merchant Name', 'Merchant City', 'Merchant State', 'MCC',\n",
                "                    'Errors?', 'Is Fraud?']\n",
                "integer_columns = ['Zip']\n",
                "\n",
                "for col in category_columns:\n",
                "    if is_string_dtype(df[col].dtype):\n",
                "        df[col] = df[col].str.replace(',', ' ')\n",
                "\n",
                "# after preprocessing\n",
                "df = df[all_columns]\n",
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "aa356012",
            "metadata": {},
            "source": [
                "There are 24M records with 12 fields. We need to convert the structured tabular data into a format that NeMo GPT can consume. The NeMo GPT uses training data in a loose json format, with one json containing a text sample per line. For example:\n",
                "```json\n",
                "{\"text\": \"The quick brown fox\"}\n",
                "{\"text\": \"jumps over the lazy dog\"}\n",
                "```\n",
                "We can concat each fields of the transactions together like:\n",
                "```json\n",
                "{\"text\": \"0,0,2002,9,1,06:21,$134.09,Swipe Transaction,3527213246127876953,La Verne,CA,91750.0,5300,NaN,No\\n0,0,2002,9,1,06:42,$38.48,Swipe,Transaction,-727612092139916043,Monterey Park,CA,91754.0,5411,NaN,No...\"}\n",
                "...\n",
                "```\n",
                "In this way, the tabular data is converted into NLP text corpus. \n",
                "\n",
                "### NeMo GPT Workflow\n",
                "```\n",
                "                       +-----------+\n",
                "      +--------------->|Tokenizer  |\n",
                "      |                +-----+-----+\n",
                "      |                      |\n",
                "+-----+-----+          +-----v--------+      +---------+\n",
                "|  Raw Data +--------->| Preprocess   +----->|Pretrain |\n",
                "|           |          |              |      +-----+---+\n",
                "+-----------+          +--------------+            |\n",
                "                                                   |\n",
                "                                           +-------v----------+\n",
                "                                           |  Inference       |\n",
                "                                           | (Text Generation)|\n",
                "                                           +------------------+\n",
                "```\n",
                "As shown in the figure above, it illustrates the steps we are going to take in this tutorial. Having the raw text data ready, we first train a tokenizer to efficiently tokenize the text.  As NeMo only cares about sequences of tokens, a preprocess step is used to convert the raw text data into sequences of token index. It results in one binary file and an index file so data loading in the training step is more efficient.  The next step is the most time consuming pre-training step in which sequences of tokens are fed into the NeMo GPT to predict the next tokens. The prediction error is used as the loss to train the GPT weights. After training the GPT model, it can be put into an inference mode to generate synthetic data following the same distribution as the training dataset. \n",
                "\n",
                "### Tokenizer training\n",
                "It is natural to select the generic GPT BPE tokenizer to convert the text into tokens. However, there are a few problems of using this approach. When GPT BPE tokenizer splits the text into tokens, the number of tokens are usually not fixed for the same column at different rows, because the number is determined by the occurrence frequencies of the individual sub-tokens. This means the structure information is lost if we use the NLP tokenizer. Another problem with the NLP tokenizer is the long string consists of a large number of tokens, which is wasteful considering the NeMo GPT has limited capacity of modeling the sequences of tokens. For example the \"Merchant Name\" \"3527213246127876953\" need at least 7 tokens to code it ([35][27][213][246][127][876][953]). \n",
                "\n",
                "As shown in the [TabFormer paper](https://arxiv.org/abs/2011.01843), a good solution is to build a specialized tokenizer for the tabular data that considers the table structural information. The TabFormer uses a single token for each of the columns which can cause either accuracy loss if the number of tokens is small for the column, or weak generalization if the number of tokens is too large. We improve it by using multiple tokens to code the columns. For example, the floating number \"134.09\" can be tokenized into multiple integers.\n",
                "\n",
                "The following code trains a special encoder/decoder used in the tokenizer. It uses `float` for the `Amount` column, `int` for the `zip` column and `category` for the rest of the columns. The trained encoder and decoder are saved into a file that can be loaded later. We choose to use 3 tokens to encode the floating and int numbers in this example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "16298d39",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "- name: Year\n",
                        "  code_type: category\n",
                        "- name: Month\n",
                        "  code_type: category\n",
                        "- name: Day\n",
                        "  code_type: category\n",
                        "- name: Hour\n",
                        "  code_type: category\n",
                        "- name: Minute\n",
                        "  code_type: category\n",
                        "- name: Card\n",
                        "  code_type: category\n",
                        "- name: Amount\n",
                        "  code_type: float\n",
                        "  args:\n",
                        "    code_len: 3\n",
                        "    base: 32\n",
                        "    fillall: true\n",
                        "    hasnan: false\n",
                        "    transform: yeo-johnson\n",
                        "- name: Use Chip\n",
                        "  code_type: category\n",
                        "- name: Merchant Name\n",
                        "  code_type: category\n",
                        "- name: Merchant City\n",
                        "  code_type: category\n",
                        "- name: Merchant State\n",
                        "  code_type: category\n",
                        "- name: Zip\n",
                        "  code_type: int\n",
                        "  args:\n",
                        "    code_len: 3\n",
                        "    base: 47\n",
                        "    fillall: true\n",
                        "    hasnan: true\n",
                        "- name: MCC\n",
                        "  code_type: category\n",
                        "- name: Errors?\n",
                        "  code_type: category\n",
                        "- name: Is Fraud?\n",
                        "  code_type: category\n",
                        "\n",
                        "['Year', 'Month', 'Day', 'Hour', 'Minute', 'Card', 'Amount', 'Use Chip', 'Merchant Name', 'Merchant City', 'Merchant State', 'Zip', 'MCC', 'Errors?', 'Is Fraud?']\n",
                        "each row uses 20 tokens\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "tab_structure = []\n",
                "for c in columns:\n",
                "    if c in float_columns:\n",
                "        item = {\n",
                "            \"name\": c,\n",
                "            \"code_type\": \"float\",\n",
                "            \"args\": {\n",
                "                \"code_len\": 3,  # number of tokens used to code the column\n",
                "                \"base\": 32,   # the positional base number. ie. it uses 32 tokens for one digit\n",
                "                \"fillall\": True, # whether to use full base number for each token or derive it from the data.\n",
                "                \"hasnan\": False, # can it handles nan or not\n",
                "                \"transform\": \"yeo-johnson\" # can be ['yeo-johnson', 'quantile', 'robust'], check https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing \n",
                "            }\n",
                "        }\n",
                "    elif c in integer_columns:\n",
                "        item = {\n",
                "            \"name\": c,\n",
                "            \"code_type\": \"int\",\n",
                "            \"args\": {\n",
                "                \"code_len\": 3,  # number of tokens used to code the column\n",
                "                \"base\": 47,   # the positional base number. ie. it uses 32 tokens for one digit\n",
                "                \"fillall\": True, # whether to use full base number for each token or derive it from the data.\n",
                "                \"hasnan\": True, # can it handles nan or not\n",
                "            }\n",
                "        }\n",
                "    else:\n",
                "        item = {\n",
                "            \"name\": c,\n",
                "            \"code_type\": \"category\",\n",
                "        }\n",
                "    tab_structure.append(item)\n",
                "print(OmegaConf.to_yaml(tab_structure))\n",
                "print(columns)\n",
                "\n",
                "example_arrays = {}\n",
                "for col in tab_structure:\n",
                "    col_name = col['name']\n",
                "    if col_name in category_columns:\n",
                "        example_arrays[col_name] = [i.strip() for i in df[col_name].astype(str).unique()]\n",
                "    else:\n",
                "        example_arrays[col_name] = df[col_name].dropna().unique()\n",
                "cc = ColumnCodes.get_column_codes(tab_structure, example_arrays)\n",
                "print('each row uses', sum(cc.sizes)+ 1, 'tokens')\n",
                "with open(CC_OUTPUT_P, 'wb') as handle:\n",
                "    pickle.dump(cc, handle)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "02bff63f",
            "metadata": {},
            "source": [
                "Let's give it a try to play with encoder and decoder for \"Amount\" and \"Merchant City\" columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "ca2f95ba",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "token ids for 134.09 is [234, 225, 172]\n",
                        "recovered Amt for 134.09 is 133.9723\n",
                        "token ids for Monterey Park is [108435]\n",
                        "recovered City for Monterey Park is Monterey Park\n"
                    ]
                }
            ],
            "source": [
                "float_str = '134.09'\n",
                "token_ids = cc.encode('Amount', float_str)\n",
                "print('token ids for {} is {}'.format(float_str, token_ids))\n",
                "amt_str = cc.decode('Amount', token_ids)\n",
                "print('recovered Amt for {} is {}'.format(float_str, amt_str))\n",
                "\n",
                "city_str = 'Monterey Park'\n",
                "token_ids = cc.encode('Merchant City', city_str)\n",
                "print('token ids for {} is {}'.format(city_str, token_ids))\n",
                "amt_str = cc.decode('Merchant City', token_ids)\n",
                "print('recovered City for {} is {}'.format(city_str, amt_str))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "89e1e5b3",
            "metadata": {},
            "source": [
                "Using 3 tokens for the float column `Amount`, this is a tiny loss of accuracy. If better accuracy is needed, more tokens can be used to train the tokenizer. For the categorical column \"Merchant City\", the string \"Monterey Park\" only needs one token to encode it. Once we have the encoder and decoder ready, the tokenizer is easy to implement. We can consider the tabular data structure information to encode each of the columns. The decoding simply counts the number of tokens to infer the tabular structure since the number of the tokens are fixed for each of the columns.\n",
                "\n",
                "There is one more thing that we need to take special care of before generating the loose json file for NeMo. `<|endoftext|>` is a special token that NeMo recognizes to indicate the beginning and end of the document. The attention mask will stop at the boundary of `<|endoftext|>` token so no attention can be applied across it. To model the temporal information in the time series, we want to make sure the `<|endoftext|>` is added between the continuous sections. For example, in this credit card dataset, there are 2000 users. Each user's transactions are one long time series sequence. The `<|endoftext|>` is added at the end of the long sequences. In this way, NeMo applies attention to learn the temporal correlation in the transactions for the user but not across users. \n",
                "\n",
                "We have provided the Python code to convert the CSV file into the loose json format."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "5e9b5727",
            "metadata": {},
            "outputs": [],
            "source": [
                "delimiter = ','\n",
                "eod_str = '<|endoftext|>'\n",
                "int_nan = '<NA>'\n",
                "\n",
                "\n",
                "def get_docs_from_df(one_group):\n",
                "    user_df = one_group[1]\n",
                "    total = []\n",
                "    # sort the rows by time, so the model can learn temporal info\n",
                "    sub_df = user_df.sort_values(['Year', 'Month', 'Day', 'Hour', 'Minute'])[columns]\n",
                "    start_rows = range(0, doc_augements)\n",
                "    full_msgs = []\n",
                "    for start in start_rows:\n",
                "        full_msgs = []\n",
                "        doc_df = sub_df.iloc[start:]\n",
                "        count = 0\n",
                "        df_size = len(doc_df)       \n",
                "        for row in doc_df.iterrows():\n",
                "            count += 1\n",
                "            items = row[1].values\n",
                "            str_items = [str(items[i]).replace(int_nan, 'nan') for i in range(len(items))]\n",
                "            if count == df_size:\n",
                "                # append eod at the end of the doc\n",
                "                full_msgs.append(delimiter.join(str_items)+eod_str)\n",
                "            else:\n",
                "                full_msgs.append(delimiter.join(str_items))\n",
                "        # use end of line to separate rows\n",
                "        text = '\\n'.join(full_msgs)\n",
                "        text_doc = {'text': text}\n",
                "        doc = json.dumps(text_doc)+'\\n'\n",
                "        total.append(doc)\n",
                "    return total\n",
                "\n",
                "\n",
                "def gen_one_doc(user_group, n_cores):\n",
                "    udfs = list(user_group)\n",
                "    pool = Pool(n_cores)\n",
                "    docs = pool.map(get_docs_from_df, udfs)\n",
                "    pool.close()\n",
                "    pool.join()\n",
                "    return functools.reduce(lambda a, b: a + b, docs)\n",
                "\n",
                "# number of document augmentation\n",
                "doc_augements = 2\n",
                "\n",
                "user_group = df.groupby('User')\n",
                "\n",
                "with open(CC_OUTPUT_J, 'w') as f:\n",
                "    docs = gen_one_doc(user_group, 30)\n",
                "    for doc in docs:\n",
                "        f.write(doc)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "05ebadc3",
            "metadata": {},
            "source": [
                "After running the above cell, it converts the CSV file to the loose json format that the NeMo Megatron can use. It generates one document for each user. Each document ends with the `<|endoftext|>` token. We augment the data by shifting it by one transaction so the relative position of the input credit card transaction data is slightly different. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "2fe38a29",
            "metadata": {},
            "source": [
                "Having the loose JSON file ready, we can test the customized Tabular Tokenizer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "1d9d065e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "raw input text\n",
                        " 2002,9,1,06,21,0,134.09,Swipe Transaction,3527213246127876953,La Verne,CA,91750,5300,nan,No\n",
                        "2002,9,1,06,42,0,38.48,Swipe Transaction,-727612092139916043,Monterey Park,CA,91754,5411,nan,No\n",
                        "2002,9,2,06,22,0,120.34,Swipe Transaction,-727612092139916043,Monterey Park,CA,91754,5411,nan,No\n",
                        "2002,9,2,17,45,0,128.95,Swipe Transaction,3414527459579106770,Monterey Park,CA,91754,5651,nan,No\n",
                        "2002,9,3,06,23,0,104.71,Swipe Transaction,5817218446178736267,La Verne,CA,91750,5912,nan,No\n",
                        "tokens\n",
                        " ['2002', '9', '1', '06', '21', '0', '134.09', 'Swipe Transaction', '3527213246127876953', 'La Verne', 'CA', '91750', '5300', 'nan', 'No', '\\n', '2002', '9', '1', '06', '42', '0', '38.48', 'Swipe Transaction', '-727612092139916043', 'Monterey Park', 'CA', '91754', '5411', 'nan', 'No', '\\n', '2002', '9', '2', '06', '22', '0', '120.34', 'Swipe Transaction', '-727612092139916043', 'Monterey Park', 'CA', '91754', '5411', 'nan', 'No', '\\n', '2002', '9', '2', '17', '45', '0', '128.95', 'Swipe Transaction', '3414527459579106770', 'Monterey Park', 'CA', '91754', '5651', 'nan', 'No', '\\n', '2002', '9', '3', '06', '23', '0', '104.71', 'Swipe Transaction', '5817218446178736267', 'La Verne', 'CA']\n",
                        "token ids\n",
                        " [11, 41, 42, 79, 118, 157, 234, 225, 172, 264, 65691, 106882, 114065, 114396, 114322, 114283, 114456, 114535, 114536, 114539, 11, 41, 42, 79, 139, 157, 234, 216, 178, 264, 38139, 108435, 114065, 114396, 114322, 114287, 114459, 114535, 114536, 114539, 11, 41, 53, 79, 119, 157, 234, 223, 197, 264, 38139, 108435, 114065, 114396, 114322, 114287, 114459, 114535, 114536, 114539, 11, 41, 53, 90, 142, 157, 234, 224, 189, 264, 64999, 108435, 114065, 114396, 114322, 114287, 114464, 114535, 114536, 114539, 11, 41, 64, 79, 120, 157, 234, 222, 185, 264, 79550, 106882, 114065, 114396, 114322, 114283, 114477, 114535, 114536, 114539]\n",
                        "decoded tokens\n",
                        " ['2002', '9', '1', '06', '21', '0', '133.9723', 'Swipe Transaction', '3527213246127876953', 'La Verne', 'CA', '91750', '5300', 'nan', 'No', '\\n', '2002', '9', '1', '06', '42', '0', '38.3326', 'Swipe Transaction', '-727612092139916043', 'Monterey Park', 'CA', '91754', '5411', 'nan', 'No', '\\n', '2002', '9', '2', '06', '22', '0', '120.0410', 'Swipe Transaction', '-727612092139916043', 'Monterey Park', 'CA', '91754', '5411', 'nan', 'No', '\\n', '2002', '9', '2', '17', '45', '0', '128.5933', 'Swipe Transaction', '3414527459579106770', 'Monterey Park', 'CA', '91754', '5651', 'nan', 'No', '\\n', '2002', '9', '3', '06', '23', '0', '104.5459', 'Swipe Transaction', '5817218446178736267', 'La Verne', 'CA', '91750', '5912', 'nan', 'No', '\\n', '2002', '9', '3', '13', '53', '0', '85.8889', 'Swipe Transaction', '-7146670748125200898', 'Monterey Park', 'CA', '91755', '5970', 'nan', 'No', '\\n', '2002', '9', '4', '05']\n",
                        "decoded text\n",
                        " 2002,9,1,06,21,0,133.9723,Swipe Transaction,3527213246127876953,La Verne,CA,91750,5300,nan,No\n",
                        "2002,9,1,06,42,0,38.3326,Swipe Transaction,-727612092139916043,Monterey Park,CA,91754,5411,nan,No\n",
                        "2002,9,2,06,22,0,120.0410,Swipe Transaction,-727612092139916043,Monterey Park,CA,91754,5411,nan,No\n",
                        "2002,9,2,17,45,0,128.5933,Swipe Transaction,3414527459579106770,Monterey Park,CA,91754,5651,nan,No\n",
                        "2002,9,3,06,23,0,104.5459,Swipe Transaction,5817218446178736267,La Verne,CA,91750,5912,nan,No\n"
                    ]
                }
            ],
            "source": [
                "tokenizer = TabularTokenizer(CC_OUTPUT_P, delimiter=',')\n",
                "\n",
                "with open(CC_OUTPUT_J, 'r') as f:\n",
                "    for line in f:\n",
                "        break\n",
                "\n",
                "text = json.loads(line)['text']\n",
                "r = tokenizer.text_to_tokens(text)\n",
                "ids = tokenizer.tokens_to_ids(r)\n",
                "tex = tokenizer.ids_to_tokens(ids)\n",
                "decoded_text = tokenizer.ids_to_text(ids)\n",
                "show_num_lines = 5\n",
                "print('raw input text\\n', '\\n'.join(text.split('\\n')[:show_num_lines]))\n",
                "print('tokens\\n', r[:show_num_lines*len(tokenizer.code_column.columns)])\n",
                "print('token ids\\n', ids[:show_num_lines*(sum(tokenizer.code_column.sizes)+1)])\n",
                "print('decoded tokens\\n', tex[:show_num_lines*(sum(tokenizer.code_column.sizes)+1)])\n",
                "print('decoded text\\n', '\\n'.join(decoded_text.split('\\n')[:show_num_lines]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "678f65ef",
            "metadata": {},
            "source": [
                "The TabularTokenizer understands the Table structure so it can convert back and forth between the tabular data text and the token ids.\n",
                "\n",
                "\n",
                "### Model configuration\n",
                "\n",
                "\n",
                "We define the following constants to configure the GPT model "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "97571acc",
            "metadata": {},
            "outputs": [],
            "source": [
                "NUM_LAYERS = 4\n",
                "NUM_GPUS = 1\n",
                "HIDDEN_SIZE = 1024\n",
                "NUM_ATTENTION_HEADS = 16\n",
                "SEQ_LENGTH = 1024\n",
                "TENSOR_MP_SIZE = 1\n",
                "PIPELINE_MP_SIZE = 1"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "8af66b4a",
            "metadata": {},
            "source": [
                "### Preprocess\n",
                "\n",
                "The loose json above is processed into a binary format for training. To convert the json into mmap, cached index file, we use the `preprocess_data_for_megatron.py` script to prepare the data.\n",
                "\n",
                "\n",
                "Download the python file and run the preprocess. Note we use `30` CPU workers for the preprocessing step. Please adjust it according to your compute environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "fccee06c",
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'preprocess_data_for_megatron.py'"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/scripts/nlp_language_modeling/preprocess_data_for_megatron.py')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "79de4531",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[NeMo W 2024-02-26 22:46:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
                        "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
                        "    \n",
                        "Vocab size: 114540\n",
                        "Output prefix: tabular_data\n",
                        "Time to startup: 0.032488107681274414\n",
                        "Processing file ./credit_card.jn 1/1\n",
                        "Processed 100 documents (1.021828932839258 docs/s, 1.223987290363381 MB/s).\n",
                        "Processed 200 documents (2.0070984452758847 docs/s, 2.2554847736165065 MB/s).\n",
                        "Processed 300 documents (2.9509047117804736 docs/s, 3.2471806843266005 MB/s).\n",
                        "Processed 400 documents (3.8698379319961216 docs/s, 4.170088455163126 MB/s).\n",
                        "Processed 500 documents (4.7620744398028725 docs/s, 5.050596277956267 MB/s).\n",
                        "Processed 600 documents (5.610316443121176 docs/s, 5.966976852574457 MB/s).\n",
                        "Processed 700 documents (6.425460216602764 docs/s, 6.957510225382692 MB/s).\n",
                        "Processed 800 documents (5.412526937616991 docs/s, 5.759855272241559 MB/s).\n",
                        "Processed 900 documents (6.011379774852928 docs/s, 6.307352259347958 MB/s).\n",
                        "Processed 1000 documents (6.092682805327401 docs/s, 6.461056384486996 MB/s).\n",
                        "Processed 1100 documents (6.620251250817031 docs/s, 7.097118703236053 MB/s).\n",
                        "Processed 1200 documents (7.153442463699653 docs/s, 7.575642619576489 MB/s).\n",
                        "Processed 1300 documents (7.651523723861652 docs/s, 8.076402245045422 MB/s).\n",
                        "Processed 1400 documents (8.134163363644406 docs/s, 8.58235187168174 MB/s).\n",
                        "Processed 1500 documents (8.649084450031221 docs/s, 8.960426486553073 MB/s).\n",
                        "Processed 1600 documents (7.431839223900767 docs/s, 7.7537888126704635 MB/s).\n",
                        "Processed 1700 documents (6.7639470532187485 docs/s, 7.196306378890284 MB/s).\n",
                        "Processed 1800 documents (7.104690322128365 docs/s, 7.611844766051346 MB/s).\n",
                        "Processed 1900 documents (7.442854269824384 docs/s, 8.003195482633892 MB/s).\n",
                        "Processed 2000 documents (7.769717723458539 docs/s, 8.431453586444412 MB/s).\n",
                        "Processed 2100 documents (8.099359560003952 docs/s, 8.802276989288403 MB/s).\n",
                        "Processed 2200 documents (8.317854372233164 docs/s, 9.08210054705219 MB/s).\n",
                        "Processed 2300 documents (8.558533743101556 docs/s, 9.329151999515103 MB/s).\n",
                        "Processed 2400 documents (8.081246484053372 docs/s, 8.810335815702697 MB/s).\n",
                        "Processed 2500 documents (8.083519023143433 docs/s, 8.872007644189829 MB/s).\n",
                        "Processed 2600 documents (8.167344307868019 docs/s, 8.987885566861598 MB/s).\n",
                        "Processed 2700 documents (8.423140780775027 docs/s, 9.28842870218857 MB/s).\n",
                        "Processed 2800 documents (8.681630080832365 docs/s, 9.570178026338887 MB/s).\n",
                        "Processed 2900 documents (8.65420684348932 docs/s, 9.6058707444686 MB/s).\n",
                        "Processed 3000 documents (8.706606095941996 docs/s, 9.641464499111647 MB/s).\n",
                        "Processed 3100 documents (8.276433044355278 docs/s, 9.152641672919314 MB/s).\n",
                        "Processed 3200 documents (8.453377035173006 docs/s, 9.319502089553728 MB/s).\n",
                        "Processed 3300 documents (8.681399390830236 docs/s, 9.538696778143962 MB/s).\n",
                        "Processed 3400 documents (8.789705557299294 docs/s, 9.653553188002132 MB/s).\n",
                        "Processed 3500 documents (9.013396197478146 docs/s, 9.857321030929638 MB/s).\n",
                        "Processed 3600 documents (8.800001658418756 docs/s, 9.664227669591789 MB/s).\n",
                        "Processed 3700 documents (9.015359438141905 docs/s, 9.838520699024278 MB/s).\n",
                        "Processed 3800 documents (8.406606198758235 docs/s, 9.20432426565419 MB/s).\n",
                        "Processed 3900 documents (8.598151685172512 docs/s, 9.393735634247944 MB/s).\n",
                        "Processed 4000 documents (8.789446041500392 docs/s, 9.578995400752236 MB/s).\n"
                    ]
                }
            ],
            "source": [
                "!python preprocess_data_for_megatron.py \\\n",
                "    --input={CC_OUTPUT_J} \\\n",
                "    --json-keys=text \\\n",
                "    --tokenizer-library=tabular \\\n",
                "    --vocab-file={CC_OUTPUT_P} \\\n",
                "    --tokenizer-type=Tabular \\\n",
                "    --output-prefix=tabular_data \\\n",
                "    --delimiter=, \\\n",
                "    --workers=30\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "4998ebcb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "./tabular_data_text_document.bin  ./tabular_data_text_document.idx\n"
                    ]
                }
            ],
            "source": [
                "!ls $DATA_PATH/tabular*.*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "6ecec681",
            "metadata": {},
            "source": [
                "After running the script, two new files are generated in the current directory: `tabular_data_text_document.bin` and `tabular_data_text_document.idx`. The `bin` file is the `mmap` binary file and the `idx` is the index file to look up the sentences in the binary file. They will be used for the following pre-training step."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "58a3d4fa",
            "metadata": {},
            "source": [
                "### Pretrain\n",
                "\n",
                "We are ready to pretrain the NeMo GPT model. As large models can be quite difficult to train due to memory constraints, NeMo makes it possible by using both Tensor model parallel and Pipeline model parallelism that enables training transformer models with billions of parameters. On top of the model parallelism, we can apply the popular data parallelism to the training to fully utilize all the GPUs in the cluster. In this [paper](https://arxiv.org/pdf/2104.04473.pdf), it provides a few tips about how to setup the model parallelism and data parallelism optimally:\n",
                "\n",
                "1. When considering different forms of model parallelism, tensor model parallelism should generally be used up to degree 𝑔 when using 𝑔-GPU servers, and then pipeline model parallelism can be used to scale up to larger models across server.\n",
                "2. When using data and model parallelism, a total model-parallel size of 𝑀 = 𝑡 · 𝑝 should be used so that the model’s parameters and intermediate metadata fit in GPU memory; data parallelism can be used to scale up training to more GPUs.\n",
                "3. The optimal microbatch size 𝑏 depends on the throughput and memory footprint characteristics of the model, as well as the pipeline depth 𝑝, data-parallel size 𝑑, and batch size 𝐵.\n",
                "\n",
                "In this tutorial, we only concern with training a model that fits into a single GPU. we set the tensor model parallel and pipeline model parallelism parameter to 1. Feel free to adjust it to train a larger model according to the available compute resources. As we know from OpenAI's [scaling law of natural language](https://arxiv.org/abs/2001.08361), the larger the model, the better the performance is.\n",
                "\n",
                "Download and run the pretraining task script below. Note, this is the most time consuming step. It takes days for the task to converge depending on the computation environment, model size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "749fd8df",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'conf/megatron_gpt_config.yaml'"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "!mkdir -p conf\n",
                "wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/language_modeling/megatron_gpt_pretraining.py')\n",
                "wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/language_modeling/conf/megatron_gpt_config.yaml', out='conf')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "c7665cee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[NeMo W 2024-02-26 22:54:24 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
                        "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:54:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
                        "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
                        "      ret = run_job(\n",
                        "    \n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_gpt_pretraining:34] \n",
                        "    \n",
                        "    ************** Experiment configuration ***********\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_gpt_pretraining:35] \n",
                        "    name: megatron_gpt\n",
                        "    restore_from_path: null\n",
                        "    trainer:\n",
                        "      devices: 1\n",
                        "      num_nodes: 1\n",
                        "      accelerator: gpu\n",
                        "      precision: 16\n",
                        "      logger: false\n",
                        "      enable_checkpointing: false\n",
                        "      use_distributed_sampler: false\n",
                        "      max_epochs: -1\n",
                        "      max_steps: 10000\n",
                        "      log_every_n_steps: 100\n",
                        "      val_check_interval: 500\n",
                        "      limit_val_batches: 50\n",
                        "      limit_test_batches: 500\n",
                        "      accumulate_grad_batches: 1\n",
                        "      gradient_clip_val: 1.0\n",
                        "      benchmark: false\n",
                        "      enable_model_summary: false\n",
                        "    exp_manager:\n",
                        "      explicit_log_dir: null\n",
                        "      exp_dir: gpt_creditcard_results\n",
                        "      name: megatron_gpt\n",
                        "      create_wandb_logger: false\n",
                        "      wandb_logger_kwargs:\n",
                        "        project: null\n",
                        "        name: null\n",
                        "      create_neptune_logger: false\n",
                        "      neptune_logger_kwargs:\n",
                        "        project: null\n",
                        "        name: null\n",
                        "        prefix: train\n",
                        "        log_model_checkpoints: false\n",
                        "        tags: null\n",
                        "        description: null\n",
                        "      resume_if_exists: true\n",
                        "      resume_ignore_no_checkpoint: true\n",
                        "      resume_from_checkpoint: ${model.resume_from_checkpoint}\n",
                        "      create_checkpoint_callback: true\n",
                        "      checkpoint_callback_params:\n",
                        "        monitor: val_loss\n",
                        "        save_top_k: 10\n",
                        "        mode: min\n",
                        "        always_save_nemo: false\n",
                        "        save_nemo_on_train_end: false\n",
                        "        filename: megatron_gpt--{val_loss:.2f}-{step}-{consumed_samples}\n",
                        "        model_parallel_size: ${multiply:${model.tensor_model_parallel_size}, ${model.pipeline_model_parallel_size}}\n",
                        "    model:\n",
                        "      mcore_gpt: false\n",
                        "      micro_batch_size: 4\n",
                        "      global_batch_size: 8\n",
                        "      rampup_batch_size: null\n",
                        "      tensor_model_parallel_size: 1\n",
                        "      pipeline_model_parallel_size: 1\n",
                        "      virtual_pipeline_model_parallel_size: null\n",
                        "      encoder_seq_length: 1024\n",
                        "      max_position_embeddings: 1024\n",
                        "      num_layers: 4\n",
                        "      hidden_size: 1024\n",
                        "      ffn_hidden_size: 3072\n",
                        "      num_attention_heads: 16\n",
                        "      init_method_std: 0.02\n",
                        "      use_scaled_init_method: true\n",
                        "      hidden_dropout: 0.1\n",
                        "      attention_dropout: 0.1\n",
                        "      ffn_dropout: 0.0\n",
                        "      kv_channels: null\n",
                        "      apply_query_key_layer_scaling: false\n",
                        "      normalization: layernorm\n",
                        "      layernorm_epsilon: 1.0e-05\n",
                        "      do_layer_norm_weight_decay: false\n",
                        "      make_vocab_size_divisible_by: 128\n",
                        "      pre_process: true\n",
                        "      post_process: true\n",
                        "      persist_layer_norm: true\n",
                        "      bias: true\n",
                        "      activation: gelu\n",
                        "      headscale: false\n",
                        "      transformer_block_type: pre_ln\n",
                        "      openai_gelu: false\n",
                        "      normalize_attention_scores: true\n",
                        "      position_embedding_type: learned_absolute\n",
                        "      rotary_percentage: 1.0\n",
                        "      attention_type: multihead\n",
                        "      share_embeddings_and_output_weights: true\n",
                        "      overlap_p2p_comm: false\n",
                        "      batch_p2p_comm: true\n",
                        "      seq_len_interpolation_factor: null\n",
                        "      num_query_groups: null\n",
                        "      tokenizer:\n",
                        "        library: tabular\n",
                        "        type: Tabular\n",
                        "        model: null\n",
                        "        vocab_file: ./credit_card_coder.pickle\n",
                        "        merge_file: null\n",
                        "        delimiter: ','\n",
                        "        sentencepiece_legacy: false\n",
                        "      native_amp_init_scale: 4294967296\n",
                        "      native_amp_growth_interval: 1000\n",
                        "      hysteresis: 2\n",
                        "      fp32_residual_connection: false\n",
                        "      fp16_lm_cross_entropy: false\n",
                        "      megatron_amp_O2: false\n",
                        "      grad_allreduce_chunk_size_mb: 125\n",
                        "      grad_div_ar_fusion: true\n",
                        "      gradient_accumulation_fusion: false\n",
                        "      bias_activation_fusion: true\n",
                        "      bias_dropout_add_fusion: true\n",
                        "      masked_softmax_fusion: true\n",
                        "      get_attention_mask_from_fusion: true\n",
                        "      seed: 1234\n",
                        "      resume_from_checkpoint: null\n",
                        "      use_cpu_initialization: false\n",
                        "      onnx_safe: false\n",
                        "      apex_transformer_log_level: 30\n",
                        "      gradient_as_bucket_view: true\n",
                        "      sync_batch_comm: false\n",
                        "      nccl_communicator_config_path: null\n",
                        "      fsdp: false\n",
                        "      fsdp_sharding_strategy: full\n",
                        "      fsdp_grad_reduce_dtype: fp32\n",
                        "      fsdp_sharded_checkpoint: false\n",
                        "      activations_checkpoint_granularity: null\n",
                        "      activations_checkpoint_method: block\n",
                        "      activations_checkpoint_num_layers: 1\n",
                        "      num_micro_batches_with_partial_activation_checkpoints: null\n",
                        "      activations_checkpoint_layers_per_pipeline: null\n",
                        "      sequence_parallel: false\n",
                        "      transformer_engine: false\n",
                        "      fp8: false\n",
                        "      fp8_e4m3: false\n",
                        "      fp8_hybrid: true\n",
                        "      fp8_margin: 0\n",
                        "      fp8_interval: 1\n",
                        "      fp8_amax_history_len: 1024\n",
                        "      fp8_amax_compute_algo: max\n",
                        "      reduce_amax: true\n",
                        "      use_emha: false\n",
                        "      ub_tp_comm_overlap: false\n",
                        "      ub_tp_comm_overlap_cfg: null\n",
                        "      use_flash_attention: false\n",
                        "      cpu_offloading: false\n",
                        "      cpu_offloading_num_layers: ${sum:${.num_layers},-1}\n",
                        "      cpu_offloading_activations: true\n",
                        "      cpu_offloading_weights: true\n",
                        "      sharp: false\n",
                        "      enable_megatron_timers: false\n",
                        "      megatron_timer_kwargs:\n",
                        "        log_every_n_steps: 10\n",
                        "        log_mode: minmax\n",
                        "        barrier: false\n",
                        "      data:\n",
                        "        data_prefix:\n",
                        "        - tabular_data_text_document\n",
                        "        index_mapping_dir: null\n",
                        "        data_impl: mmap\n",
                        "        splits_string: 3800,198,2\n",
                        "        seq_length: 1024\n",
                        "        skip_warmup: true\n",
                        "        num_workers: 2\n",
                        "        dataloader_type: single\n",
                        "        reset_position_ids: false\n",
                        "        reset_attention_mask: false\n",
                        "        eod_mask_loss: true\n",
                        "        validation_drop_last: true\n",
                        "        no_seqlen_plus_one_input_tokens: false\n",
                        "        pad_samples_to_global_batch_size: false\n",
                        "        shuffle_documents: true\n",
                        "        exchange_indices_distributed: false\n",
                        "        mock_dataset: false\n",
                        "      nsys_profile:\n",
                        "        enabled: false\n",
                        "        start_step: 10\n",
                        "        end_step: 10\n",
                        "        ranks:\n",
                        "        - 0\n",
                        "        gen_shape: false\n",
                        "      optim:\n",
                        "        name: fused_adam\n",
                        "        lr: 0.0002\n",
                        "        weight_decay: 0.01\n",
                        "        betas:\n",
                        "        - 0.9\n",
                        "        - 0.98\n",
                        "        sched:\n",
                        "          name: CosineAnnealing\n",
                        "          warmup_steps: 2\n",
                        "          constant_steps: 2\n",
                        "          min_lr: 8.0e-05\n",
                        "      gc_interval: 0\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:54:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "[NeMo W 2024-02-26 22:54:25 exp_manager:759] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
                        "[NeMo W 2024-02-26 22:54:25 exp_manager:616] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :gpt_creditcard_results/megatron_gpt/checkpoints. Training from scratch.\n",
                        "[NeMo I 2024-02-26 22:54:25 exp_manager:396] Experiments will be logged at gpt_creditcard_results/megatron_gpt\n",
                        "[NeMo I 2024-02-26 22:54:25 exp_manager:842] TensorboardLogger has been set up\n",
                        "[NeMo W 2024-02-26 22:54:25 exp_manager:952] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 10000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:251] Rank 0 has data parallel group : [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:257] Rank 0 has combined group of data parallel and context parallel : [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:262] All data parallel group ranks with context parallel combined: [[0]]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:265] Ranks 0 has data parallel rank: 0\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:282] Rank 0 has context parallel group: [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:285] All context parallel group ranks: [[0]]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:286] Ranks 0 has context parallel rank: 0\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:297] Rank 0 has model parallel group: [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:298] All model parallel group ranks: [[0]]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:308] Rank 0 has tensor model parallel group: [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:312] All tensor model parallel group ranks: [[0]]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:313] Rank 0 has tensor model parallel rank: 0\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:342] Rank 0 has pipeline model parallel group: [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:354] Rank 0 has embedding group: [0]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:360] All pipeline model parallel group ranks: [[0]]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:361] Rank 0 has pipeline model parallel rank 0\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:362] All embedding group ranks: [[0]]\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_init:363] Rank 0 has embedding rank: 0\n",
                        "24-02-26 22:54:25 - PID:66269 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 2\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 modelPT:258] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
                        "[NeMo I 2024-02-26 22:54:25 megatron_base_model:544] Padded vocab_size: 114560, original vocab_size: 114540, dummy tokens: 20.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:1109] The model: MegatronGPTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: add_qkv_bias in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: rotary_interleaved in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:25 megatron_base_model:516] The model: MegatronGPTModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
                        "[NeMo W 2024-02-26 22:54:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:153: UserWarning: The `batch_idx` argument in `MegatronGPTModel.on_train_batch_start` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:54:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:153: UserWarning: The `batch_idx` argument in `MegatronGPTModel.on_train_batch_end` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
                        "----------------------------------------------------------------------------------------------------\n",
                        "distributed_backend=nccl\n",
                        "All distributed processes registered. Starting with 1 processes\n",
                        "----------------------------------------------------------------------------------------------------\n",
                        "\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1306] Pipeline model parallel rank: 0, Tensor model parallel rank: 0, Number of model parameters on device: 1.60e+08. Total number of model parameters: 1.60e+08.\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1183] Building GPT datasets.\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] mock = False\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] Let split_matrix = [(0, 0.95), (0.95, 0.9994999999999999), (0.9994999999999999, 0.9999999999999999)]\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] Load the _IndexReader from tabular_data_text_document.idx\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tExtract the sequence lengths\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tExtract the sequence pointers\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tExtract the document indices\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of sequences: 4000\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of documents: 4000\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] Build and save the GPTDataset train indices\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the document index to ed66eac4c4024eeafa942d6a7b242797-GPTDataset-document_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the sample index to ed66eac4c4024eeafa942d6a7b242797-GPTDataset-sample_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the shuffle index to ed66eac4c4024eeafa942d6a7b242797-GPTDataset-shuffle_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of samples: 909163\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of epochs: 1\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] Build and save the GPTDataset valid indices\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the document index to a7c7844eef9a8b41dcecae3989dc5176-GPTDataset-document_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the sample index to a7c7844eef9a8b41dcecae3989dc5176-GPTDataset-sample_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the shuffle index to a7c7844eef9a8b41dcecae3989dc5176-GPTDataset-shuffle_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of samples: 43225\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of epochs: 1\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] Build and save the GPTDataset test indices\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the document index to c41adf93fbdb6d0857b02cff9bba5b9d-GPTDataset-document_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the sample index to c41adf93fbdb6d0857b02cff9bba5b9d-GPTDataset-sample_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] \tBuild and save the shuffle index to c41adf93fbdb6d0857b02cff9bba5b9d-GPTDataset-shuffle_index.npy\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of samples: 4091\n",
                        "[NeMo I 2024-02-26 22:54:26 utils:47] > total number of epochs: 22\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1244] Length of train dataset: 909163\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1246] Length of val dataset: 43225\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1248] Length of test dataset: 4091\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1249] Finished building GPT datasets.\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1346] Setting up train dataloader with len(len(self._train_ds)): 909163 and consumed samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1258] Building dataloader with consumed samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 909163 and consumed_samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1354] Setting up validation dataloader with len(len(self._validation_ds)): 43225 and consumed samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1258] Building dataloader with consumed samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 43225 and consumed_samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1374] Setting up test dataloader with len(len(self._test_ds)): 4091 and consumed samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 megatron_gpt_model:1258] Building dataloader with consumed samples: 0\n",
                        "[NeMo I 2024-02-26 22:54:26 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 4091 and consumed_samples: 0\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
                        "[NeMo I 2024-02-26 22:54:26 nlp_overrides:229] Configuring DDP for model parallelism.\n",
                        "[NeMo I 2024-02-26 22:54:26 modelPT:723] Optimizer config = FusedAdam (\n",
                        "    Parameter Group 0\n",
                        "        betas: [0.9, 0.98]\n",
                        "        bias_correction: True\n",
                        "        eps: 1e-08\n",
                        "        lr: 0.0002\n",
                        "        weight_decay: 0.01\n",
                        "    \n",
                        "    Parameter Group 1\n",
                        "        betas: [0.9, 0.98]\n",
                        "        bias_correction: True\n",
                        "        eps: 1e-08\n",
                        "        lr: 0.0002\n",
                        "        weight_decay: 0.0\n",
                        "    )\n",
                        "[NeMo I 2024-02-26 22:54:26 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f54a6813220>\" \n",
                        "    will be used during training (effective maximum steps = 10000) - \n",
                        "    Parameters : \n",
                        "    (warmup_steps: 2\n",
                        "    constant_steps: 2\n",
                        "    min_lr: 8.0e-05\n",
                        "    max_steps: 10000\n",
                        "    )\n",
                        "Sanity Checking: 0it [00:00, ?it/s][NeMo W 2024-02-26 22:54:40 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
                        "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:54:55 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
                        "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:54:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:54:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:148: UserWarning: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "Sanity Checking DataLoader 0: : 5it [00:00,  5.44it/s]                          [NeMo W 2024-02-26 22:54:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
                        "      warning_cache.warn(\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
                        "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
                        "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:27 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:27 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:148: UserWarning: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
                        "      rank_zero_warn(\n",
                        "    \n",
                        "Epoch 0: :   0%|                                            | 0/113645 [00:00<?][NeMo W 2024-02-26 22:55:27 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
                        "      warning_cache.warn(\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:27 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('consumed_samples', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
                        "      warning_cache.warn(\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:27 nemo_logging:349] /home/eharper/NeMo/nemo/collections/nlp/modules/common/megatron/clip_grads.py:86: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)\n",
                        "      dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
                        "    \n",
                        "[NeMo W 2024-02-26 22:55:27 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
                        "      warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
                        "    \n",
                        "Epoch 0: :   0%| | 500/113645 [01:04<4:02:20, v_num=0, reduced_train_loss=1.680,\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 29.03it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:02, 30.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 32.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 33.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.52it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 34.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:00<00:01, 35.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 35.11it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 35.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.42it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.91it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.97it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 36.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 36.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 36.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 36.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 36.11it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 36.12it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 36.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 36.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 36.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 36.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 36.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 36.22it/s]\u001b[A\n",
                        "Epoch 0: :   0%| | 500/113645 [01:06<4:12:40, v_num=0, reduced_train_loss=1.680,\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 500: 'val_loss' reached 1.63137 (best 1.63137), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.63-step=500-consumed_samples=4000.0.ckpt' as top 10\n",
                        "Epoch 0: :   1%| | 1000/113645 [02:16<4:16:15, v_num=0, reduced_train_loss=1.280\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 29.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:02, 30.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 32.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 33.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 34.03it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.41it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.56it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 35.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 35.12it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.27it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.50it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.97it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 36.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 36.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 36.03it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 36.05it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 36.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 36.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 36.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 36.11it/s]\u001b[A\n",
                        "Epoch 0: :   1%| | 1000/113645 [02:19<4:21:25, v_num=0, reduced_train_loss=1.280\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 1000: 'val_loss' reached 1.47296 (best 1.47296), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.47-step=1000-consumed_samples=8000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 22:57:52 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.63-step=500-consumed_samples=4000.0-last.ckpt\n",
                        "Epoch 0: :   1%| | 1500/113645 [03:29<4:20:28, v_num=0, reduced_train_loss=1.260\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 29.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 30.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 31.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 32.97it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 33.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 33.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 33.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:02, 34.13it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 34.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 34.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 34.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 34.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 34.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 34.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.12it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.15it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:02<00:00, 35.31it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.41it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.52it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.56it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.59it/s]\u001b[A\n",
                        "Epoch 0: :   1%| | 1500/113645 [03:31<4:23:57, v_num=0, reduced_train_loss=1.260\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 1500: 'val_loss' reached 1.39456 (best 1.39456), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.39-step=1500-consumed_samples=12000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 22:59:05 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.47-step=1000-consumed_samples=8000.0-last.ckpt\n",
                        "Epoch 0: :   2%| | 2000/113645 [04:41<4:22:07, v_num=0, reduced_train_loss=1.170\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.27it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 30.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 31.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.44it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.98it/s]\u001b[A\n",
                        "Epoch 0: :   2%| | 2000/113645 [04:44<4:24:41, v_num=0, reduced_train_loss=1.170\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 2000: 'val_loss' reached 1.36980 (best 1.36980), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.37-step=2000-consumed_samples=16000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:00:18 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.39-step=1500-consumed_samples=12000.0-last.ckpt\n",
                        "Epoch 0: :   2%| | 2500/113645 [05:54<4:22:49, v_num=0, reduced_train_loss=1.160\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:02, 30.37it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 32.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 33.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 35.05it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.13it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 36.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 36.03it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 36.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 36.06it/s]\u001b[A\n",
                        "Epoch 0: :   2%| | 2500/113645 [05:57<4:24:51, v_num=0, reduced_train_loss=1.160\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 2500: 'val_loss' reached 1.34065 (best 1.34065), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.34-step=2500-consumed_samples=20000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:01:31 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.37-step=2000-consumed_samples=16000.0-last.ckpt\n",
                        "Epoch 0: :   3%| | 3000/113645 [07:07<4:22:46, v_num=0, reduced_train_loss=1.050\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 30.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 31.91it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.30it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.42it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.50it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.91it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.95it/s]\u001b[A\n",
                        "Epoch 0: :   3%| | 3000/113645 [07:10<4:24:28, v_num=0, reduced_train_loss=1.050\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 3000: 'val_loss' reached 1.32304 (best 1.32304), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.32-step=3000-consumed_samples=24000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:02:43 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.34-step=2500-consumed_samples=20000.0-last.ckpt\n",
                        "Epoch 0: :   3%| | 3500/113645 [08:20<4:22:29, v_num=0, reduced_train_loss=1.020\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.31it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 29.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 30.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 31.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 33.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:02, 34.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 34.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.27it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.30it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.44it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.88it/s]\u001b[A\n",
                        "Epoch 0: :   3%| | 3500/113645 [08:23<4:23:56, v_num=0, reduced_train_loss=1.020\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 3500: 'val_loss' reached 1.28716 (best 1.28716), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.29-step=3500-consumed_samples=28000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:03:56 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.32-step=3000-consumed_samples=24000.0-last.ckpt\n",
                        "Epoch 0: :   4%| | 4000/113645 [09:33<4:22:01, v_num=0, reduced_train_loss=1.030\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 30.31it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.30it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 32.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.37it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.93it/s]\u001b[A\n",
                        "Epoch 0: :   4%| | 4000/113645 [09:36<4:23:16, v_num=0, reduced_train_loss=1.030\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 4000: 'val_loss' reached 1.28439 (best 1.28439), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.28-step=4000-consumed_samples=32000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:05:10 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.29-step=3500-consumed_samples=28000.0-last.ckpt\n",
                        "Epoch 0: :   4%| | 4500/113645 [10:46<4:21:24, v_num=0, reduced_train_loss=1.020\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 29.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 30.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 31.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.05it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 33.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.18it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:02, 34.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 34.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 34.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 34.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.13it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.27it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.31it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.42it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:02<00:00, 35.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.78it/s]\u001b[A\n",
                        "Epoch 0: :   4%| | 4500/113645 [10:49<4:22:31, v_num=0, reduced_train_loss=1.020\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 4500: 'val_loss' reached 1.25613 (best 1.25613), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.26-step=4500-consumed_samples=36000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:06:23 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.28-step=4000-consumed_samples=32000.0-last.ckpt\n",
                        "Epoch 0: :   4%| | 5000/113645 [11:59<4:20:41, v_num=0, reduced_train_loss=0.940\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 30.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.30it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 32.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.56it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.05it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.03it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.30it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.50it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.91it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.95it/s]\u001b[A\n",
                        "Epoch 0: :   4%| | 5000/113645 [12:02<4:21:41, v_num=0, reduced_train_loss=0.940\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 5000: 'val_loss' reached 1.24399 (best 1.24399), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.24-step=5000-consumed_samples=40000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:07:36 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.26-step=4500-consumed_samples=36000.0-last.ckpt\n",
                        "Epoch 0: :   5%| | 5500/113645 [13:12<4:19:48, v_num=0, reduced_train_loss=0.909\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 30.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 32.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 34.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:01, 34.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 35.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.95it/s]\u001b[A\n",
                        "Epoch 0: :   5%| | 5500/113645 [13:15<4:20:42, v_num=0, reduced_train_loss=0.909\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 5500: 'val_loss' reached 1.23848 (best 1.23848), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.24-step=5500-consumed_samples=44000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:08:46 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.63-step=500-consumed_samples=4000.0.ckpt\n",
                        "[NeMo I 2024-02-26 23:08:49 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.24-step=5000-consumed_samples=40000.0-last.ckpt\n",
                        "Epoch 0: :   5%| | 6000/113645 [14:25<4:18:56, v_num=0, reduced_train_loss=1.030\n",
                        "Validation: 0it [00:00, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 1/100 [00:00<00:07, 12.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 3/100 [00:00<00:04, 22.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 5/100 [00:00<00:03, 26.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▎                | 7/100 [00:00<00:03, 28.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌                | 9/100 [00:00<00:03, 30.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 11/100 [00:00<00:02, 31.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 13/100 [00:00<00:02, 31.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 15/100 [00:00<00:02, 32.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 17/100 [00:00<00:02, 32.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 19/100 [00:00<00:02, 33.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 21/100 [00:00<00:02, 33.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 23/100 [00:00<00:02, 33.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 25/100 [00:00<00:02, 33.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 27/100 [00:00<00:02, 34.18it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 29/100 [00:00<00:02, 34.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 31/100 [00:00<00:02, 34.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▌           | 33/100 [00:00<00:01, 34.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 35/100 [00:01<00:01, 34.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 37/100 [00:01<00:01, 34.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 39/100 [00:01<00:01, 34.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 41/100 [00:01<00:01, 34.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 43/100 [00:01<00:01, 35.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 45/100 [00:01<00:01, 35.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|███████▉         | 47/100 [00:01<00:01, 35.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 49/100 [00:01<00:01, 35.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 51/100 [00:01<00:01, 35.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|█████████        | 53/100 [00:01<00:01, 35.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 55/100 [00:01<00:01, 35.41it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 57/100 [00:01<00:01, 35.44it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 59/100 [00:01<00:01, 35.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 61/100 [00:01<00:01, 35.52it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 63/100 [00:01<00:01, 35.55it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|███████████      | 65/100 [00:01<00:00, 35.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|███████████▍     | 67/100 [00:01<00:00, 35.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████▋     | 69/100 [00:01<00:00, 35.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|████████████     | 71/100 [00:01<00:00, 35.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|████████████▍    | 73/100 [00:02<00:00, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████▊    | 75/100 [00:02<00:00, 35.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|█████████████    | 77/100 [00:02<00:00, 35.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|█████████████▍   | 79/100 [00:02<00:00, 35.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|█████████████▊   | 81/100 [00:02<00:00, 35.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|██████████████   | 83/100 [00:02<00:00, 35.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|██████████████▍  | 85/100 [00:02<00:00, 35.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|██████████████▊  | 87/100 [00:02<00:00, 35.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|███████████████▏ | 89/100 [00:02<00:00, 35.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|███████████████▍ | 91/100 [00:02<00:00, 35.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|███████████████▊ | 93/100 [00:02<00:00, 35.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|████████████████▏| 95/100 [00:02<00:00, 35.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|████████████████▍| 97/100 [00:02<00:00, 35.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|████████████████▊| 99/100 [00:02<00:00, 35.94it/s]\u001b[A\n",
                        "Epoch 0: :   5%| | 6000/113645 [14:28<4:19:46, v_num=0, reduced_train_loss=1.030\u001b[A\n",
                        "                                                   \u001b[AEpoch 0, global step 6000: 'val_loss' reached 1.22921 (best 1.22921), saving model to 'gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.23-step=6000-consumed_samples=48000.0.ckpt' as top 10\n",
                        "[NeMo I 2024-02-26 23:09:59 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.47-step=1000-consumed_samples=8000.0.ckpt\n",
                        "[NeMo I 2024-02-26 23:10:02 nlp_overrides:465] Removing checkpoint: gpt_creditcard_results/megatron_gpt/checkpoints/megatron_gpt--val_loss=1.24-step=5500-consumed_samples=44000.0-last.ckpt\n",
                        "Epoch 0: :   6%| | 6384/113645 [15:24<4:18:51, v_num=0, reduced_train_loss=0.961^C\n",
                        "Process ForkProcess-32:\n",
                        "Process ForkProcess-7:\n",
                        "Process ForkProcess-10:\n",
                        "Process ForkProcess-20:\n",
                        "Process ForkProcess-23:\n",
                        "Process ForkProcess-3:\n",
                        "Process ForkProcess-16:\n",
                        "Process ForkProcess-28:\n",
                        "Process ForkProcess-2:\n",
                        "Process ForkProcess-30:\n",
                        "Process ForkProcess-27:\n",
                        "Process ForkProcess-31:\n",
                        "Process ForkProcess-8:\n",
                        "Process ForkProcess-12:\n",
                        "Process ForkProcess-15:\n",
                        "Process ForkProcess-31:\n",
                        "Process ForkProcess-19:\n",
                        "Process ForkProcess-22:\n",
                        "Process ForkProcess-23:\n",
                        "Process ForkProcess-8:\n",
                        "Process ForkProcess-27:\n",
                        "Process ForkProcess-32:\n",
                        "Process ForkProcess-26:\n",
                        "Process ForkProcess-4:\n",
                        "Process ForkProcess-29:\n",
                        "Process ForkProcess-10:\n",
                        "Process ForkProcess-24:\n",
                        "Process ForkProcess-14:\n",
                        "Process ForkProcess-21:\n",
                        "Process ForkProcess-20:\n",
                        "Process ForkProcess-30:\n",
                        "Process ForkProcess-17:\n",
                        "Process ForkProcess-7:\n",
                        "Process ForkProcess-18:\n",
                        "Process ForkProcess-25:\n",
                        "Process ForkProcess-31:\n",
                        "Process ForkProcess-25:\n",
                        "Process ForkProcess-16:\n",
                        "Process ForkProcess-17:\n",
                        "Process ForkProcess-13:\n",
                        "Process ForkProcess-29:\n",
                        "Process ForkProcess-1:\n",
                        "Process ForkProcess-22:\n",
                        "Process ForkProcess-15:\n",
                        "Process ForkProcess-9:\n",
                        "Process ForkProcess-6:\n",
                        "Process ForkProcess-11:\n",
                        "Process ForkProcess-7:\n",
                        "Process ForkProcess-3:\n",
                        "Process ForkProcess-1:\n",
                        "Process ForkProcess-11:\n",
                        "Process ForkProcess-8:\n",
                        "Process ForkProcess-6:\n",
                        "Process ForkProcess-19:\n",
                        "Process ForkProcess-6:\n",
                        "Process ForkProcess-5:\n",
                        "Process ForkProcess-5:\n",
                        "Process ForkProcess-18:\n",
                        "Process ForkProcess-4:\n",
                        "Process ForkProcess-2:\n",
                        "Process ForkProcess-6:\n",
                        "Process ForkProcess-28:\n",
                        "Process ForkProcess-5:\n",
                        "Process ForkProcess-6:\n",
                        "Process ForkProcess-5:\n",
                        "Process ForkProcess-21:\n",
                        "Process ForkProcess-10:\n",
                        "Process ForkProcess-31:\n",
                        "Process ForkProcess-24:\n",
                        "Process ForkProcess-5:\n",
                        "Process ForkProcess-20:\n",
                        "Process ForkProcess-14:\n",
                        "Process ForkProcess-9:\n",
                        "Process ForkProcess-25:\n",
                        "Process ForkProcess-3:\n",
                        "[NeMo W 2024-02-26 23:10:51 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
                        "      rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
                        "    \n",
                        "Process ForkProcess-12:\n",
                        "Process ForkProcess-26:\n",
                        "Process ForkProcess-26:\n",
                        "Process ForkProcess-28:\n",
                        "Process ForkProcess-29:\n",
                        "Process ForkProcess-15:\n",
                        "Process ForkProcess-22:\n",
                        "Process ForkProcess-23:\n",
                        "Process ForkProcess-13:\n",
                        "Process ForkProcess-4:\n",
                        "Process ForkProcess-21:\n",
                        "Process ForkProcess-19:\n",
                        "Process ForkProcess-11:\n",
                        "Process ForkProcess-30:\n",
                        "Process ForkProcess-9:\n",
                        "Process ForkProcess-2:\n",
                        "Process ForkProcess-24:\n",
                        "Process ForkProcess-8:\n",
                        "Process ForkProcess-32:\n",
                        "Process ForkProcess-15:\n",
                        "Process ForkProcess-18:\n",
                        "Process ForkProcess-1:\n",
                        "Process ForkProcess-29:\n",
                        "Process ForkProcess-27:\n",
                        "Process ForkProcess-16:\n",
                        "Process ForkProcess-17:\n",
                        "Process ForkProcess-10:\n",
                        "Process ForkProcess-23:\n",
                        "Process ForkProcess-21:\n",
                        "Process ForkProcess-7:\n",
                        "Process ForkProcess-14:\n",
                        "Process ForkProcess-2:\n",
                        "Process ForkProcess-8:\n",
                        "Process ForkProcess-3:\n",
                        "Process ForkProcess-4:\n",
                        "Process ForkProcess-23:\n",
                        "Process ForkProcess-30:\n",
                        "Process ForkProcess-32:\n",
                        "Process ForkProcess-26:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-31:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-14:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-22:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-25:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-12:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-12:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-10:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-20:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-16:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-7:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-13:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-15:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-9:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-18:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-1:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-17:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-24:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-28:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Process ForkProcess-19:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-11:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-3:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Process ForkProcess-32:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-26:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Process ForkProcess-19:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-28:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Process ForkProcess-27:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Process ForkProcess-20:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-4:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-21:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "Process ForkProcess-29:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Process ForkProcess-13:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Process ForkProcess-22:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-17:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Process ForkProcess-11:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-18:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-24:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Process ForkProcess-30:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Process ForkProcess-9:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Process ForkProcess-14:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Process ForkProcess-2:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Process ForkProcess-27:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-25:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "Process ForkProcess-12:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Process ForkProcess-13:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Process ForkProcess-16:\n",
                        "KeyboardInterrupt\n",
                        "Process ForkProcess-1:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
                        "    res = self._recv_bytes()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
                        "    res = self._recv_bytes()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
                        "    buf = self._recv_bytes(maxlength)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
                        "    buf = self._recv_bytes(maxlength)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
                        "    buf = self._recv(4)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
                        "    buf = self._recv(4)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
                        "    chunk = read(handle, remaining)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
                        "    chunk = read(handle, remaining)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "Traceback (most recent call last):\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
                        "    res = self._recv_bytes()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
                        "    buf = self._recv_bytes(maxlength)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
                        "    buf = self._recv(4)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
                        "    chunk = read(handle, remaining)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
                        "    self.run()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
                        "    res = self._recv_bytes()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
                        "    buf = self._recv_bytes(maxlength)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
                        "    buf = self._recv(4)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
                        "    chunk = read(handle, remaining)\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
                        "    res = self._recv_bytes()\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
                        "    buf = self._recv_bytes(maxlength)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
                        "    buf = self._recv(4)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
                        "    chunk = read(handle, remaining)\n",
                        "KeyboardInterrupt\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
                        "    call_item = call_queue.get(block=True)\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
                        "    with self._rlock:\n",
                        "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "KeyboardInterrupt\n",
                        "KeyboardInterrupt\n"
                    ]
                }
            ],
            "source": [
                "    !python megatron_gpt_pretraining.py \\\n",
                "                trainer.devices={NUM_GPUS} \\\n",
                "                trainer.accelerator=gpu \\\n",
                "                trainer.log_every_n_steps=100 \\\n",
                "                trainer.val_check_interval=500 \\\n",
                "                trainer.accumulate_grad_batches=1 \\\n",
                "                trainer.max_steps=10000 \\\n",
                "                trainer.precision=16 \\\n",
                "                trainer.gradient_clip_val=1.0 \\\n",
                "                exp_manager.exp_dir=gpt_creditcard_results \\\n",
                "                model.tensor_model_parallel_size={TENSOR_MP_SIZE} \\\n",
                "                model.pipeline_model_parallel_size={PIPELINE_MP_SIZE} \\\n",
                "                model.optim.name=fused_adam \\\n",
                "                model.optim.lr=2e-4 \\\n",
                "                model.optim.sched.warmup_steps=2 \\\n",
                "                model.optim.sched.constant_steps=2 \\\n",
                "                model.optim.sched.min_lr=8e-5 \\\n",
                "                model.max_position_embeddings={SEQ_LENGTH} \\\n",
                "                model.encoder_seq_length={SEQ_LENGTH} \\\n",
                "                model.data.seq_length={SEQ_LENGTH} \\\n",
                "                model.tokenizer.type=Tabular \\\n",
                "                model.tokenizer.library=tabular \\\n",
                "                model.tokenizer.vocab_file={CC_OUTPUT_P} \\\n",
                "                model.tokenizer.delimiter=\\',\\' \\\n",
                "                model.data.eod_mask_loss=True \\\n",
                "                model.data.splits_string=\\'3800,198,2\\' \\\n",
                "                model.num_layers={NUM_LAYERS} \\\n",
                "                model.hidden_size={HIDDEN_SIZE} \\\n",
                "                model.num_attention_heads={NUM_ATTENTION_HEADS} \\\n",
                "                model.activations_checkpoint_method='block' \\\n",
                "                model.activations_checkpoint_num_layers=1 \\\n",
                "                model.data.data_prefix=[tabular_data_text_document]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "45ac928f",
            "metadata": {},
            "source": [
                "The pretraining will save the checkpoint files periodically at the location specified by `exp_manager.exp_dir`. In this case, it creates a directory called `gpt_creditcard_results`. The number `trainer.val_check_interval` controls the frequency of validation evaluation. We use 500 in this example. The trainer will preserve the checkpoint files which have the top `k` best validation error, by default, `k=10`. \n",
                "While the training job is running, we can use the `tensorboard` to monitor the training. For example, you can run this command and check the learning curves at browser.\n",
                "```bash\n",
                "--logdir gpt_creditcard_results/ --bind_all 0.0.0.0\n",
                "```\n",
                "\n",
                "Once the training converges, we take a checkpoint file which has the smallest validation error."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "158a4bbe",
            "metadata": {},
            "source": [
                "## Convert checkpoint to nemo file\n",
                "\n",
                "NeMo library package the checkpoint file and other model artifacts (like model config file and vocab file) into a single `.nemo` file. It makes the process of loading GPT model and running inference easier. \n",
                "\n",
                "Let's download the script and convert the checkpoint file into `.nemo` file. Make sure to change the checkpoint file name to the correct name. You can find them in the `gpt_creditcard_results/megatron_gpt/checkpoints/ ` directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "46cecf96",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'megatron_ckpt_to_nemo.py'"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/language_modeling/megatron_ckpt_to_nemo.py')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "cd7fd084",
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "cannot assign to expression (2274464726.py, line 1)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    CHECKPONT_FILE_NAME = megatron_gpt--val_loss=1.23-step=6000-consumed_samples=48000.0-last.ckpt # change it to your checkpoint file name\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n"
                    ]
                }
            ],
            "source": [
                "CHECKPONT_FILE_NAME = megatron_gpt--val_loss=1.23-step=6000-consumed_samples=48000.0-last.ckpt # change it to your checkpoint file name\n",
                "!torchrun --nproc_per_node=1 megatron_ckpt_to_nemo.py \\\n",
                "    --checkpoint_folder=gpt_creditcard_results/megatron_gpt/checkpoints/ \\\n",
                "    --checkpoint_name={CHECKPONT_FILE_NAME} \\\n",
                "    --nemo_file_path=tabular.nemo \\\n",
                "    --tensor_model_parallel_size={TENSOR_MP_SIZE} \\\n",
                "    --pipeline_model_parallel_size={PIPELINE_MP_SIZE} \\\n",
                "    --gpus_per_node=1 \\\n",
                "    --model_type=gpt"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fa16378e",
            "metadata": {},
            "source": [
                "After running this script, it creates a `tabular.nemo` file which can be used to generate synthetic credit card transactions. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ed056ec6",
            "metadata": {},
            "source": [
                "### Generate synthetic credit card transactions\n",
                "\n",
                "We come to the last step of this tutorial - generate synthetic credit card transactions!\n",
                "\n",
                "First let's load the trained model weights, put the NeMo GPT in inference mode and start the text generation server. All of these can be done by running the `megatron_gpt_eval.py` script. \n",
                "\n",
                "Let's download the script and configuration file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59ab7c9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/language_modeling/megatron_gpt_eval.py')\n",
                "wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/language_modeling/conf/megatron_gpt_inference.yaml', out='conf')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a62b48dc",
            "metadata": {},
            "source": [
                "Open another Jupyter notebook or terminal, and run the following in a cell. \n",
                "```python\n",
                "!python megatron_gpt_eval.py \\\n",
                "    gpt_model_file=tabular.nemo \\\n",
                "    prompts=[\\'\\',\\'\\'] \\\n",
                "    server=True\n",
                "```\n",
                "The text generation server accepts REST API request to send the generated text in the response. Let's use the following Python code to generate some transactions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ebd6f637",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(CC_OUTPUT_P, 'rb') as handle:\n",
                "        cc: ColumnCodes = pickle.load(handle)\n",
                "\n",
                "token_per_rows = sum(cc.sizes) + 1\n",
                "\n",
                "batch_size = 4\n",
                "port_num = 5555\n",
                "num_of_rows = 10\n",
                "headers = {\"Content-Type\": \"application/json\"}\n",
                "\n",
                "\n",
                "def request_data(data):\n",
                "    resp = requests.put('http://localhost:{}/generate'.format(port_num),\n",
                "                        data=json.dumps(data), headers=headers)\n",
                "    sentences = resp.json()['sentences']\n",
                "    return sentences\n",
                "\n",
                "\n",
                "# generate the initial transactions \n",
                "data = {\n",
                "    \"sentences\": [\"\"] * batch_size,\n",
                "    \"tokens_to_generate\": num_of_rows * token_per_rows,\n",
                "    \"temperature\": 1.0,\n",
                "    \"add_BOS\": True\n",
                "}\n",
                "\n",
                "sentences = request_data(data)\n",
                "\n",
                "for i in range(batch_size):\n",
                "    s = sentences[i]\n",
                "    print(s)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "cccd54d9",
            "metadata": {},
            "source": [
                "The above code only generate `num_of_rows` of transactions starting from the beginning. If longer sequence is needed, we can run the inference conditioned on the past transactions in a sliding window fashion. For example, first it generates [A, B, C, D, E] transactions conditioned on `<|endoftext|>` token. Then, it conditions on [D, E] and generates [D, E, F, G, H]. Once the long sequence comes to the end indicated by `<|endoftext|>`, it will keep generating new transactions for a different user. For example, after generating [X, Y, Z, <|endoftext|>] in the last run, it will generate [Z, <|endoftext|>, A', B', C'] in the next time, where A', B', C' are transactions for a different user and they are not depending on the other users transaction Z.  \n",
                "\n",
                "The following code implements the idea above and can be used to generate massive number of transactions in long sequences. The `history_rows` specifies the number of rows of transactions used as conditional context and `num_of_rows` specify the number of rows of transactions to be generated at a time. It saves all the synthetic credit card transactions in the text files whose file names starts with prefix `synthetic`. You can adjust `number_of_blocks`, `batch_size` parameters to generate more transactions.  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e4b80ab0",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(CC_OUTPUT_P, 'rb') as handle:\n",
                "        cc: ColumnCodes = pickle.load(handle)\n",
                "\n",
                "batch_size = 4\n",
                "num_of_rows = 50\n",
                "token_per_rows = sum(cc.sizes) + 1\n",
                "history_rows = 40\n",
                "num_of_blocks = 100\n",
                "\n",
                "port_num = 5555\n",
                "headers = {\"Content-Type\": \"application/json\"}\n",
                "\n",
                "prefix_name = 'synthetic'\n",
                "files = []\n",
                "\n",
                "\n",
                "for i in range(batch_size):\n",
                "    files.append(open(\"{}_{}.txt\".format(prefix_name, i), 'w'))\n",
                "\n",
                "\n",
                "def request_data(data):\n",
                "    resp = requests.put('http://localhost:{}/generate'.format(port_num),\n",
                "                        data=json.dumps(data), headers=headers)\n",
                "    sentences = resp.json()['sentences']\n",
                "    return sentences\n",
                "\n",
                "\n",
                "def get_condition_text(sentences, history_rows):\n",
                "    condition_text = ['\\n'.join([ss for ss in s.split(\n",
                "        '\\n')[-(history_rows+1):]]) for s in sentences]\n",
                "    return condition_text\n",
                "\n",
                "\n",
                "def get_extra_text(sentences, history_rows):\n",
                "    extra_text = ['\\n'.join([ss for ss in s.split(\n",
                "        '\\n')[history_rows:]]) for s in sentences]\n",
                "    return extra_text\n",
                "\n",
                "# generate the initial transactions \n",
                "data = {\n",
                "    \"sentences\": [\"\"] * batch_size,\n",
                "    \"tokens_to_generate\": num_of_rows * token_per_rows,\n",
                "    \"temperature\": 1.0,\n",
                "    \"add_BOS\": True\n",
                "}\n",
                "\n",
                "sentences = request_data(data)\n",
                "\n",
                "for i in range(batch_size):\n",
                "    s = sentences[i]\n",
                "    files[i].write(s.replace('<|endoftext|>', '\\n'))\n",
                "\n",
                "# generate the transactions conditioned on the previous ones\n",
                "for block in range(num_of_blocks):\n",
                "    print(\"block id: {}\".format(block))\n",
                "    condition_text = get_condition_text(sentences, history_rows)\n",
                "    data = {\n",
                "        \"sentences\": condition_text,\n",
                "        \"tokens_to_generate\": num_of_rows * token_per_rows,\n",
                "        \"temperature\": 1.0,\n",
                "        \"add_BOS\": False\n",
                "    }\n",
                "\n",
                "    sentences = request_data(data)\n",
                "\n",
                "    extra_text = get_extra_text(sentences, history_rows)\n",
                "\n",
                "    for i in range(batch_size):\n",
                "        s = extra_text[i]\n",
                "        files[i].write(s.replace('<|endoftext|>', '\\n---------------\\n'))\n",
                "        files[i].flush()\n",
                "\n",
                "\n",
                "for i in range(batch_size):\n",
                "    files[i].close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "79c1ee03",
            "metadata": {},
            "outputs": [],
            "source": [
                "# check the generated creditcard transaction files\n",
                "!ls synthetic*.txt"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "0f2f6e3a",
            "metadata": {},
            "source": [
                "That's it! In this tutorial, you have learned how to train a NeMo GPT model to generate synthetic data. Go ahead and apply it for your own data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb9fa86d",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
