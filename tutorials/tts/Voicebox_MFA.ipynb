{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voicebox Data Preparation with Montreal Forced Aligner (MFA)\n",
    "This is the tutorial of preparing manifests of training/validation dataset.\n",
    "\n",
    "Since Voicebox requires frame-level alignment with phonemes as input, we need to prepare alignments for each utterance in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environment\n",
    "**We recommand [install MFA environment with conda](https://montreal-forced-aligner.readthedocs.io/en/latest/installation.html#general-installation) inside the NeMo docker**.\n",
    "The reason is, we need to use both NeMo environment and MFA simultaneously for speech editing, so it is required to make sure both environments are accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install [Miniconda](https://docs.anaconda.com/miniconda/#quick-command-line-install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install miniconda from source\n",
    "!mkdir -p ~/miniconda3\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "!bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "!rm ~/miniconda3/miniconda.sh\n",
    "\n",
    "# Add conda to shell initialization (choose your shell)\n",
    "!~/miniconda3/bin/conda init bash\n",
    "!~/miniconda3/bin/conda init zsh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the shell environment (reload window if using vscode) to enable the conda command, then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin:/root/.local/bin:/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/bin/remote-cli:/root/miniconda3/bin:/root/miniconda3/condabin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin:/usr/local/cmake/bin:/usr/local/cmake/bin:/usr/local/cmake/bin:/usr/local/cmake/bin:/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/bin/remote-cli:/root/miniconda3/bin:/root/miniconda3/condabin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin:/usr/local/cmake/bin:/usr/local/cmake/bin:/usr/local/cmake/bin:/usr/local/cmake/bin:/usr/local/cmake/bin\n"
     ]
    }
   ],
   "source": [
    "! source ~/.bashrc\n",
    "! echo $PATH\n",
    "\n",
    "# Set default conda activation to false, so that it doesn't interfere with the NeMo docker environment\n",
    "!conda config --set auto_activate_base false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install MFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create new conda environment and install montreal forced aligner\n",
    "!conda create -n aligner -c conda-forge montreal-forced-aligner -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following command, if you failed running in the jupyter notebook (e.g. with `CondaError: Run 'conda init' before 'conda activate'`), please run it in the terminal by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n",
      "/bin/bash: line 1: mfa: command not found\n",
      "/bin/bash: line 1: mfa: command not found\n",
      "/bin/bash: line 1: mfa: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda deactivate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# activate conda environment\n",
    "!conda activate aligner\n",
    "\n",
    "# download pre-trained MFA models\n",
    "!mfa model download g2p english_us_arpa\n",
    "!mfa model download acoustic english_us_arpa\n",
    "!mfa model download dictionary english_us_arpa\n",
    "!conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we use \"aligner\" as the environment name throughout the Voicebox project. Please don't use your customized name at this point, unless you know how to fix the code accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Other Pip Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# check if torchaudio is installed\n",
    "! pip list | grep 'torchaudio'\n",
    "# if not, run the following commands\n",
    "!./scripts/installers/install_torchaudio_latest.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess LibriLight w/ LibriHeavy\n",
    "- LibriLight is an audio dataset consists of audiobooks.\n",
    "- LibriHeavy is a transcripted version of LibriLight, which is a manifest consists of LibriLight's utterances' transcripts.\n",
    "- In this section, we need to cut the audiobook chapter audios into utterances according to LibriHeavy's provided transcripts, such that MFA can align each utterance with its transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from functools import partial\n",
    "import lhotse\n",
    "from lhotse.recipes.utils import manifests_exist\n",
    "from lhotse.cut import CutSet, Cut\n",
    "from lhotse.serialization import load_manifest_lazy_or_eager, load_manifest\n",
    "\n",
    "from scripts.dataset_processing.tts.libriheavy.mfa_prepare import get_subset_audio, change_prefix, save_texts_and_audios\n",
    "\n",
    "old_prefix = \"download/librilight\"  # prefix to replace in libriheavy manifest\n",
    "librilight_dir = \"data/download/LibriLight\" # directory with librilight audio data\n",
    "libriheavy_dir = \"data/download/LibriHeavy\" # directory with libriheavy manifest data\n",
    "audio_cuts_dir = \"data/aligned/LibriHeavy/raw_data_cuts\" # directory to save processed audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download LibriLight Audios\n",
    "LibriHeavy repo: https://github.com/k2-fsa/libriheavy/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage -1: Downloading audio file.\n",
      "Skipping download, small subset exists.\n",
      "Skipping download, medium subset exists.\n",
      "Skipping download, large subset exists.\n"
     ]
    }
   ],
   "source": [
    "# download librilight\n",
    "\n",
    "dataset_parts = [\"small\", \"medium\", \"large\"]\n",
    "target_dir = librilight_dir\n",
    "\n",
    "print(\"Stage -1: Downloading audio file.\")\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "for subset in dataset_parts:\n",
    "    logging.info(\"Downloading ${subset} subset.\")\n",
    "    if not os.path.exists(f\"{target_dir}/{subset}\"):\n",
    "        os.system(f\"wget -P {target_dir} -c https://dl.fbaipublicfiles.com/librilight/data/{subset}.tar\")\n",
    "        os.system(f\"tar xf {target_dir}/{subset}.tar -C {target_dir}\")\n",
    "    else:\n",
    "        print(f\"Skipping download, {subset} subset exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download LibriHeavy Manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p data/download/LibriHeavy\n",
      "Skipping download, small subset exists.\n",
      "Skipping download, medium subset exists.\n",
      "Skipping download, large subset exists.\n",
      "Skipping download, dev subset exists.\n",
      "Skipping download, test_clean subset exists.\n",
      "Skipping download, test_other subset exists.\n",
      "Skipping download, test_clean_large subset exists.\n",
      "Skipping download, test_other_large subset exists.\n"
     ]
    }
   ],
   "source": [
    "# download libriheavy manifests\n",
    "\n",
    "dataset_parts = [\"small\", \"medium\", \"large\", \"dev\", \"test_clean\", \"test_other\", \"test_clean_large\", \"test_other_large\"]\n",
    "target_dir = libriheavy_dir\n",
    "\n",
    "print(f\"mkdir -p {target_dir}\")\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "for subset in dataset_parts:\n",
    "    if not manifests_exist(subset, target_dir, [\"cuts\"], \"libriheavy\"):\n",
    "        print(f\"Downloading {subset} subset.\")\n",
    "        os.system(f\"wget -P {target_dir} -c https://huggingface.co/datasets/pkufool/libriheavy/resolve/main/libriheavy_cuts_{subset}.jsonl.gz\")\n",
    "    else:\n",
    "        print(f\"Skipping download, {subset} subset exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process for MFA\n",
    "Cut LibriLight audios according to LibriHeavy transcripts, then store them with MFA-required corpus formats and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process libriheavy manifests for MFA\n",
    "\n",
    "subsets = [\"small\", \"dev\", \"test_clean\", \"test_other\"]\n",
    "# subsets = [\"medium\"]\n",
    "# subsets = [\"large\", \"test_clean_large\", \"test_other_large\"]\n",
    "\n",
    "for subset in subsets:\n",
    "    # can not lazily split with progress bar\n",
    "    cuts: CutSet = load_manifest_lazy_or_eager(f\"{libriheavy_dir}/libriheavy_cuts_{subset}.jsonl.gz\", CutSet)\n",
    "    cuts = cuts.filter(lambda c: ',' not in c.id)\n",
    "    cuts = cuts.map(partial(change_prefix, old_prefix=old_prefix, new_prefix=librilight_dir))\n",
    "\n",
    "    storage_path=f\"{audio_cuts_dir}/{subset}\"\n",
    "    cuts = cuts.to_eager()\n",
    "    save_texts_and_audios(cuts=cuts, storage_path=storage_path, num_jobs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFA align LibriHeavy\n",
    "Run the following in your terminal by yourself if any conda error occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! mkdir -p data/aligned/LibriHeavy/textgrids\n",
    "\n",
    "# change the subsets according to the processed subsets you want to align\n",
    "! subsets=\"small dev test_clean test_other\"\n",
    "\n",
    "! conda activate aligner\n",
    "! for subset in small dev test_clean test_other; do echo $subset; corpus_dir=data/aligned/LibriHeavy/raw_data_cuts/$subset/; textgrid_dir=data/aligned/LibriHeavy/textgrids/$subset/; mfa align $corpus_dir english_us_arpa english_us_arpa $textgrid_dir --config_path scripts/dataset_processing/tts/libriheavy/mfa_config.yaml --clean True -j 16; done\n",
    "! conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess GigaSpeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download GigaSpeech\n",
    "GigaSpeech is downloaded from [huggingface ESB datasets](https://huggingface.co/datasets/esb/datasets) with its `datasets` api. Remember to grant access through the webpage beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets\n",
    "import os\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "\n",
    "# change and modify the following variables\n",
    "subsets = [\"xs\", \"s\", \"m\", \"l\", \"xl\"]\n",
    "token = \"your huggingface token\"\n",
    "\n",
    "def has_valid_audio(ex):\n",
    "    try:\n",
    "        sf.read(ex[\"audio\"][\"path\"])\n",
    "    except Exception:\n",
    "        print(ex[\"audio\"][\"path\"])\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "for subset in tqdm(subsets, desc=\"subset\"):\n",
    "    ds = load_dataset(\n",
    "        \"esb/datasets\", \"gigaspeech\", subconfig=subset,\n",
    "        download_config=datasets.DownloadConfig(resume_download=True),\n",
    "        num_proc=8,\n",
    "    )\n",
    "    print(ds)\n",
    "    ds = ds.cast_column(\"audio\", datasets.Audio(decode=False))\n",
    "    ds = ds.filter(has_valid_audio)\n",
    "    ds = ds.cast_column(\"audio\", datasets.Audio(decode=True))\n",
    "    print(ds)\n",
    "    for data in ds[\"train\"]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFA align GigaSpeech\n",
    "Run the following in your terminal by yourself if any conda error occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! ln -s ~/.cache/huggingface/datasets/ data/download/GigaSpeech/\n",
    "! conda activate aligner\n",
    "! mfa align data/download/GigaSpeech/downloads/extracted/ english_us_arpa english_us_arpa data/download/GigaSpeech/downloads/MFA/ --config_path scripts/dataset_processing/tts/libriheavy/mfa_config.yaml --clean True -j 16\n",
    "! conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After MFA\n",
    "After you've aligned your training dataset, please follow [tutorials/tts/Voicebox_Training.ipynb](Voicebox_Training.ipynb) for further training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
